{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tP3HsDS7PeP_VHD-bZBBqePxgzjQ6jXE",
      "authorship_tag": "ABX9TyNvvA7MUrI/ojt+g9MFF1XJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giramos/Machine-Learning/blob/master/EjerciciosPreparatorios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esxzNlFONMvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación Cuestionario 💣\n",
        "Ejercicios propuestos para preparación a un futuro cuestionario. Son ejemplos de lo visto en prácticas\n",
        "\n",
        "## 1. Ejemplo\n",
        "En este ejercicio se proporciona el conjunto de datos de\n",
        "entrenamiento datos_entrenamiento_ssii.csv sobre el cual\n",
        "ya se han aplicado todas las fases de preprocesamiento\n",
        "necesarias. Utiliza este conjunto de datos para entrenar\n",
        "modelos usando el algoritmo de los vecinos de cercanos\n",
        "probando distintas combinaciones de números de vecinos\n",
        "y distancias. En concreto, prueba todas las posibles\n",
        "combinaciones formadas con los números de vecinos 3, 7,\n",
        "y 11 y las distancias Manhattan y Euclídea. Para cada\n",
        "combinación de parámetros utiliza GridSearchCV para\n",
        "obtener los resultados de la accuracy en validación cruzada\n",
        "empleando 10 cajas. Observa los resultados del modelo\n",
        "entrenado con 3 vecinos y la distancia Manhattan: ¿Cuál es\n",
        "el valor de la accuracy obtenida al validar el modelo\n",
        "utilizando la caja con id 8 y el resto de cajas para entrenar?"
      ],
      "metadata": {
        "id": "IrSTn7gvNSY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "SKTSF6q4kCyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Cargar los datos (se asume que el dataset está preprocesado y listo para usar)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "\n",
        "# Separar las variables predictoras (X) y las etiquetas (y)\n",
        "#X = df.drop(columns=[\"Etiqueta\"])  # Reemplaza \"Etiqueta\" con el nombre de la columna de etiquetas\n",
        "#y = df[\"Etiqueta\"]\n",
        "X = df.drop(columns=[\"Clase\"])  # Reemplaza \"Etiqueta\" con el nombre de la columna de etiquetas\n",
        "y = df[\"Clase\"]\n",
        "\n",
        "# Configuración de parámetros para KNN\n",
        "param_grid = {\n",
        "    \"n_neighbors\": [3, 7, 11],\n",
        "    \"metric\": [\"manhattan\", \"euclidean\"]\n",
        "}\n",
        "\n",
        "# Crear el modelo\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Configurar GridSearchCV con validación cruzada de 10 folds\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=cv, scoring=\"accuracy\", return_train_score=True)\n",
        "\n",
        "# Entrenar y realizar validación cruzada\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Mostrar los resultados generales del GridSearchCV\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "print(\"Resultados de GridSearchCV:\")\n",
        "print(results[[\"param_n_neighbors\", \"param_metric\", \"mean_test_score\", \"std_test_score\"]])\n",
        "\n",
        "# Analizar el modelo con 3 vecinos y distancia Manhattan\n",
        "specific_model = results[\n",
        "    (results[\"param_n_neighbors\"] == 3) & (results[\"param_metric\"] == \"manhattan\")\n",
        "]\n",
        "\n",
        "# Mostrar las métricas de validación cruzada\n",
        "print(\"\\nResultados del modelo con 3 vecinos y distancia Manhattan:\")\n",
        "print(specific_model[[\"mean_test_score\", \"std_test_score\"]])\n",
        "\n",
        "# Extraer resultados por fold usando StratifiedKFold\n",
        "cv_split = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracy_fold = []\n",
        "\n",
        "for train_index, test_index in cv_split.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Entrenar con los datos de entrenamiento\n",
        "    model = KNeighborsClassifier(n_neighbors=3, metric=\"manhattan\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluar con los datos de test (fold específico)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_fold.append(accuracy)\n",
        "\n",
        "# Mostrar el resultado del fold con ID 8\n",
        "print(f\"\\nAccuracy en el fold 8: {accuracy_fold[7]:.4f}\")  # Recordar que los índices comienzan en 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27LK8OiEkGoT",
        "outputId": "19fa6cc5-825c-4b5e-dc72-b5d4cad90f10"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de GridSearchCV:\n",
            "   param_n_neighbors param_metric  mean_test_score  std_test_score\n",
            "0                  3    manhattan         0.823077        0.070115\n",
            "1                  7    manhattan         0.879487        0.066974\n",
            "2                 11    manhattan         0.807692        0.083383\n",
            "3                  3    euclidean         0.864103        0.069739\n",
            "4                  7    euclidean         0.871154        0.041390\n",
            "5                 11    euclidean         0.855769        0.061968\n",
            "\n",
            "Resultados del modelo con 3 vecinos y distancia Manhattan:\n",
            "   mean_test_score  std_test_score\n",
            "0         0.823077        0.070115\n",
            "\n",
            "Accuracy en el fold 8: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "QerX1cd7Yyl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 1. Carga el conjunto de datos y define los parámetros:\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "X = data.drop('Clase', axis=1)\n",
        "y = data['Clase']\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 7, 11],  # Valores de vecinos\n",
        "    'p': [1, 2]  # Distancias Manhattan (1) y Euclídea (2)\n",
        "}\n",
        "\n",
        "# 2. Divide el conjunto de datos en entrenamiento y prueba:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 3. Crea un modelo KNN e inicializa GridSearchCV:\n",
        "knn_model = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "# 4. Entrena el modelo y observa los resultados:\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 5. Encuentra el valor de la accuracy para la caja 8:\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "accuracy_split8 = results_df[\n",
        "    (results_df['param_n_neighbors'] == 3) & (results_df['param_p'] == 1)\n",
        "]['split8_test_score'].values[0]\n",
        "\n",
        "print(f\"La accuracy en la caja 8 con 3 vecinos y distancia Manhattan es: {accuracy_split8:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmx0BJtZOQqS",
        "outputId": "abf523bd-3b1d-4141-8fec-1abe0c397e2c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La accuracy en la caja 8 con 3 vecinos y distancia Manhattan es: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`NoteBook Solución`**\n"
      ],
      "metadata": {
        "id": "B56d_ZZ4O744"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Carga el conjunto de datos y define los parámetros:\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "X = data.drop('Clase', axis=1)\n",
        "y = data['Clase']\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': range(1,4),  # Ejemplo de valores válidos\n",
        "    'p': [1, 4, 5]  # Distancias Manhattan y Euclídea\n",
        "}\n",
        "\n",
        "# 2. Divide el conjunto de datos en entrenamiento y prueba:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 3. Crea un modelo KNN e inicializa GridSearchCV:\n",
        "knn_model = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "# 4. Entrena el modelo y observa los resultados:\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "print(grid_search.cv_results_)\n",
        "\n",
        "# 5. Encuentra el valor de la accuracy para la caja 8:\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "accuracy_split8 = results_df[\n",
        "    (results_df['param_n_neighbors'] == 3) & (results_df['param_p'] == 1)\n",
        "]['split8_test_score'].values\n",
        "\n",
        "print(f\"La accuracy en la caja 8 con 3 vecinos y distancia Manhattan es: {accuracy_split8}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CaHtrm1O91Y",
        "outputId": "7d269c92-a744-47a0-f5e7-9e59c8d4e0fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean_fit_time': array([0.00200284, 0.00187595, 0.00195441, 0.0023396 , 0.00226429,\n",
            "       0.00199742, 0.0020313 , 0.00209563, 0.00224156]), 'std_fit_time': array([1.23204482e-04, 5.60315162e-05, 2.01912054e-04, 6.32475286e-04,\n",
            "       7.67925313e-04, 1.44497584e-04, 1.48635865e-04, 2.90543420e-04,\n",
            "       4.16299783e-04]), 'mean_score_time': array([0.00356731, 0.00396011, 0.00402815, 0.00450921, 0.00438499,\n",
            "       0.00408599, 0.00379322, 0.00434594, 0.00458481]), 'std_score_time': array([0.00017291, 0.00014073, 0.00045283, 0.00107665, 0.00073059,\n",
            "       0.00019599, 0.00025812, 0.00058594, 0.00084898]), 'param_n_neighbors': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value=999999), 'param_p': masked_array(data=[1, 4, 5, 1, 4, 5, 1, 4, 5],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value=999999), 'params': [{'n_neighbors': 1, 'p': 1}, {'n_neighbors': 1, 'p': 4}, {'n_neighbors': 1, 'p': 5}, {'n_neighbors': 2, 'p': 1}, {'n_neighbors': 2, 'p': 4}, {'n_neighbors': 2, 'p': 5}, {'n_neighbors': 3, 'p': 1}, {'n_neighbors': 3, 'p': 4}, {'n_neighbors': 3, 'p': 5}], 'split0_test_score': array([0.8, 0.9, 0.9, 0.9, 1. , 1. , 0.9, 0.9, 0.9]), 'split1_test_score': array([0.8, 0.9, 0.9, 0.8, 1. , 1. , 0.9, 0.9, 1. ]), 'split2_test_score': array([1. , 1. , 1. , 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]), 'split3_test_score': array([0.8, 0.9, 0.9, 0.8, 0.9, 0.9, 0.8, 0.8, 0.7]), 'split4_test_score': array([0.7, 0.6, 0.6, 0.8, 0.7, 0.7, 0.8, 0.8, 0.8]), 'split5_test_score': array([0.9, 0.8, 0.8, 0.9, 0.9, 0.8, 0.9, 0.8, 0.9]), 'split6_test_score': array([0.8, 0.9, 0.9, 0.9, 0.8, 0.9, 0.8, 0.8, 0.8]), 'split7_test_score': array([0.9, 0.7, 0.7, 1. , 0.9, 0.9, 1. , 0.9, 0.9]), 'split8_test_score': array([0.6, 0.8, 0.8, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8]), 'split9_test_score': array([0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.8, 0.8, 0.8]), 'mean_test_score': array([0.81, 0.83, 0.83, 0.85, 0.87, 0.87, 0.86, 0.84, 0.85]), 'std_test_score': array([0.10440307, 0.11      , 0.11      , 0.08062258, 0.10049876,\n",
            "       0.10049876, 0.0663325 , 0.04898979, 0.08062258]), 'rank_test_score': array([9, 7, 7, 4, 1, 1, 3, 6, 4], dtype=int32)}\n",
            "La accuracy en la caja 8 con 3 vecinos y distancia Manhattan es: [0.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gemini solución**"
      ],
      "metadata": {
        "id": "jFKyeNM7PV7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler  # Para escalar los datos si es necesario\n",
        "\n",
        "# Cargar los datos\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "\n",
        "# Separar las características (X) y la variable objetivo (y)\n",
        "X = data.drop('Clase', axis=1)\n",
        "y = data['Clase']\n",
        "\n",
        "# Escalar los datos (opcional, si las características tienen escalas muy diferentes)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Definir los parámetros a probar\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 7, 11],\n",
        "    'metric': ['manhattan', 'euclidean']\n",
        "}\n",
        "\n",
        "# Fijar la semilla aleatoria para reproducibilidad\n",
        "random_state = 42\n",
        "\n",
        "# Mezclar los datos aleatoriamente\n",
        "data = data.sample(frac=1, random_state=random_state)\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba (opcional, si quieres evaluar en un conjunto de prueba independiente)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)\n",
        "\n",
        "# Crear el modelo KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Utilizar GridSearchCV con 10-fold cross-validation\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtener los resultados\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Encontrar la accuracy para 3 vecinos y distancia Manhattan en la caja 8\n",
        "accuracy_caja8 = results[(results['param_n_neighbors'] == 3) &\n",
        "                         (results['param_metric'] == 'manhattan')]['split8_test_score'].values[0]\n",
        "\n",
        "print(f\"Accuracy para 3 vecinos y distancia Manhattan en la caja 8: {accuracy_caja8}\")\n",
        "\n",
        "# Evaluar en el conjunto de prueba (opcional)\n",
        "if X_test is not None:\n",
        "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "    print(f\"Accuracy en el conjunto de prueba: {accuracy_score(y_test, y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE_IJs-8PYkH",
        "outputId": "1326146c-34e0-4664-973b-4e1538dd8fbc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy para 3 vecinos y distancia Manhattan en la caja 8: 0.8\n",
            "Accuracy en el conjunto de prueba: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Ejemplo\n",
        "En este ejercicio se proporciona el conjunto de datos de\n",
        "entrenamiento datos_entrenamiento_ssii.csv sobre el cual\n",
        "ya se han aplicado todas las fases de preprocesamiento\n",
        "necesarias. Utiliza este conjunto de datos para entrenar\n",
        "modelos usando el algoritmo de los vecinos de cercanos\n",
        "probando distintas combinaciones de números de vecinos\n",
        "y distancias. En concreto, prueba todas las posibles\n",
        "combinaciones formadas con los números de vecinos 3, 7,\n",
        "y 11 y las distancias Manhattan y Euclídea. Para cada\n",
        "combinación de parámetros utiliza GridSearchCV para\n",
        "obtener los resultados de la accuracy en validación cruzada\n",
        "empleando 10 cajas. Observa los resultados del modelo\n",
        "entrenado con 7 vecinos y la distancia Manhattan: ¿Cuál es\n",
        "el valor de la accuracy obtenida al validar el modelo\n",
        "utilizando la caja con id 4 y el resto de cajas para entrenar?"
      ],
      "metadata": {
        "id": "MCRYrTgXabwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "8o5w9AKia3UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Cargar los datos\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "\n",
        "# Separar las características de la etiqueta\n",
        "X = df.drop('Clase', axis=1)\n",
        "y = df['Clase']\n",
        "\n",
        "# Definir los parámetros para GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 7, 11],\n",
        "    'p': [1, 2]  # 1 para Manhattan, 2 para Euclídea\n",
        "}\n",
        "\n",
        "# Crear el modelo KNN\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# Configurar GridSearchCV con validación cruzada de 10 folds\n",
        "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "# Entrenar el modelo\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Obtener los resultados de la validación cruzada\n",
        "results = grid_search.cv_results_\n",
        "\n",
        "# Convert the results to a pandas DataFrame for easier indexing\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Obtener el valor de la accuracy para el modelo con 7 vecinos y distancia Manhattan en la caja con id 4\n",
        "split4_test_score = results_df.loc[\n",
        "    (results_df['param_n_neighbors'] == 7) & (results_df['param_p'] == 1),\n",
        "    'split4_test_score'\n",
        "].values[0]\n",
        "\n",
        "print(f\"Accuracy en la caja con id 4 para 7 vecinos y distancia Manhattan: {split4_test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klkT814gbTIG",
        "outputId": "621796b0-a291-48e3-971c-7d7e19aff729"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en la caja con id 4 para 7 vecinos y distancia Manhattan: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solución Gemini**"
      ],
      "metadata": {
        "id": "IPsmjnuVbWE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar los datos\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "\n",
        "# Separar las características (X) y la variable objetivo (y)\n",
        "X = data.drop('Clase', axis=1)  # Suponiendo que la columna objetivo se llama 'Clase'\n",
        "y = data['Clase']\n",
        "\n",
        "# Escalar los datos (opcional, si las características tienen escalas muy diferentes)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Definir los parámetros a probar\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 7, 11],\n",
        "    'metric': ['manhattan', 'euclidean']\n",
        "}\n",
        "\n",
        "# Fijar la semilla aleatoria para reproducibilidad\n",
        "random_state = 42\n",
        "\n",
        "# Mezclar los datos aleatoriamente\n",
        "data = data.sample(frac=1, random_state=random_state)\n",
        "\n",
        "# Crear el modelo KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Utilizar GridSearchCV con 10-fold cross-validation\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Obtener los resultados\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Encontrar la accuracy para 7 vecinos y distancia Manhattan en la caja 4\n",
        "accuracy_caja4 = results[(results['param_n_neighbors'] == 7) &\n",
        "                         (results['param_metric'] == 'manhattan')]['split4_test_score'].values[0]  # split3 corresponde a la caja 4\n",
        "\n",
        "print(f\"Accuracy para 7 vecinos y distancia Manhattan en la caja 4: {accuracy_caja4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opHjdiX9bcTB",
        "outputId": "9dc2b9bd-4673-415f-8395-ee779852ba63"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy para 7 vecinos y distancia Manhattan en la caja 4: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solución notebook**"
      ],
      "metadata": {
        "id": "cY1KdloBbmgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Carga el conjunto de datos y define los parámetros:\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "\n",
        "# 2. Separar las características de la etiqueta\n",
        "X = df.drop('Clase', axis=1)\n",
        "y = df['Clase']\n",
        "\n",
        "# 3. Definir los parámetros para GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [1, 3, 7],\n",
        "    'p': [1, 2]  # 1 para Manhattan\n",
        "}\n",
        "\n",
        "# 4. Crear el modelo KNN\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# 5. Configurar GridSearchCV con validación cruzada de 10 folds\n",
        "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "# 6. Entrenar el modelo\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# 7. Obtener los resultados de la validación cruzada\n",
        "results = grid_search.cv_results_\n",
        "\n",
        "# 8. Convertir los resultados a un DataFrame de pandas\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# 9. Obtener el valor de la accuracy para la caja con id 4\n",
        "split4_test_score = results_df['split4_test_score'].values\n",
        "\n",
        "print(f\"Accuracy en la caja con id 4 para 7 vecinos y distancia Manhattan: {split4_test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRCY994hbzhJ",
        "outputId": "ebf3d03d-a196-4d6f-8a7f-c84ca69d016f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en la caja con id 4 para 7 vecinos y distancia Manhattan: [0.92307692 0.84615385 1.         1.         1.         1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "Q5V6Bgjplbev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar los datos\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii (1).csv')\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X = df.drop(\"Clase\", axis=1)  # Cambia 'Clase' por el nombre real de la columna objetivo\n",
        "y = df[\"Clase\"]\n",
        "\n",
        "# Escalar características (opcional, útil si las variables tienen escalas distintas)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Definir los parámetros para GridSearchCV\n",
        "param_grid = {\n",
        "    \"n_neighbors\": [3, 7, 11],  # Vecinos\n",
        "    \"metric\": [\"manhattan\", \"euclidean\"],  # Distancias\n",
        "}\n",
        "\n",
        "# Crear el modelo KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Configurar GridSearchCV con validación cruzada de 10 folds\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring=\"accuracy\", return_train_score=True)\n",
        "grid_search.fit(X_scaled, y)\n",
        "\n",
        "# Convertir resultados a DataFrame\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Crear una tabla con las métricas principales\n",
        "summary_table = results[[\n",
        "    \"param_n_neighbors\", \"param_metric\", \"mean_test_score\", \"std_test_score\"\n",
        "]].sort_values(by=\"mean_test_score\", ascending=False)\n",
        "\n",
        "# Mostrar la tabla general\n",
        "print(\"Resultados de GridSearchCV:\")\n",
        "print(summary_table)\n",
        "\n",
        "# Filtrar resultados del modelo específico: 7 vecinos y distancia Manhattan\n",
        "specific_model = summary_table[\n",
        "    (results[\"param_n_neighbors\"] == 7) & (results[\"param_metric\"] == \"manhattan\")\n",
        "]\n",
        "\n",
        "print(\"\\nResultados del modelo con 7 vecinos y distancia Manhattan:\")\n",
        "print(specific_model[[\"mean_test_score\", \"std_test_score\"]])\n",
        "\n",
        "# Obtener la accuracy específica para el fold 4\n",
        "accuracy_caja4 = results.loc[\n",
        "    (results[\"param_n_neighbors\"] == 7) & (results[\"param_metric\"] == \"manhattan\"),\n",
        "    \"split4_test_score\"\n",
        "].values[0]\n",
        "\n",
        "# Mostrar el resultado específico\n",
        "print(f\"\\nAccuracy en el fold 4: {accuracy_caja4:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_edMYhJxleWP",
        "outputId": "1ff7ffc3-5303-44b4-8155-09bfd7bbcfb6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de GridSearchCV:\n",
            "   param_n_neighbors param_metric  mean_test_score  std_test_score\n",
            "1                  7    manhattan         0.848077        0.103165\n",
            "5                 11    euclidean         0.823718        0.155658\n",
            "2                 11    manhattan         0.815385        0.137598\n",
            "4                  7    euclidean         0.808333        0.124017\n",
            "3                  3    euclidean         0.791026        0.142394\n",
            "0                  3    manhattan         0.761538        0.154959\n",
            "\n",
            "Resultados del modelo con 7 vecinos y distancia Manhattan:\n",
            "   mean_test_score  std_test_score\n",
            "1         0.848077        0.103165\n",
            "\n",
            "Accuracy en el fold 4: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-129dfb902da8>:43: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  specific_model = summary_table[\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ejemplo\n",
        "Considera la siguiente salida de código. Realiza una\n",
        "comparación de los dos modelos obtenidos contestando\n",
        "cuestiones como por ejemplo ¿hay sobreajuste en alguno\n",
        "de ellos?, ¿qué impacto tiene la poda?, ¿sería necesario\n",
        "podar más?, ¿elegirías algún parámetro más, y en caso\n",
        "afirmativo qué otros parámetros y por qué?\n",
        "\n",
        "```\n",
        "## ÁRBOL SIN PODA\n",
        "## Accuracy train sin poda: 1.00\n",
        "## Accuracy validación cruzada sin poda (media = 0.91)\n",
        "## [0.88 0.96 0.88 0.92 0.92]\n",
        "## Accuracy test sin poda: 0.91\n",
        "##\n",
        "## ÁRBOL CON PODA\n",
        "## Parámetros del árbol (elegidos {'max_depth': 3,\n",
        "'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0})\n",
        "## Accuracy train con poda: 0.97\n",
        "## Accuracy validación cruzada con poda (media = 0.92)\n",
        "## [0.88, 0.96, 0.92, 0.92, 0.92]\n",
        "## Accuracy test con poda: 0.91\n",
        "##\n",
        "## Árboles resultantes\n",
        "##\n",
        "## ÁRBOL SIN PODA\n",
        "## |--- 3 <= 0.16\n",
        "## |   |--- 18 <= -1.42\n",
        "## |   |   |--- 3 <= -0.88\n",
        "## |   |   |   |--- class: 0\n",
        "## |   |   |--- 3 >  -0.88\n",
        "## |   |   |   |--- class: 1\n",
        "## |   |--- 18 >  -1.42\n",
        "## |   |   |--- 19 <= -2.32\n",
        "## |   |   |   |--- class: 1\n",
        "## |   |   |--- 19 >  -2.32\n",
        "## |   |   |   |--- 6 <= 0.99\n",
        "## |   |   |   |   |--- class: 0\n",
        "## |   |   |   |--- 6 >  0.99\n",
        "## |   |   |   |   |--- 13 <= -0.68\n",
        "## |   |   |   |   |   |--- class: 1\n",
        "## |   |   |   |   |--- 13 >  -0.68\n",
        "## |   |   |   |   |   |--- class: 0\n",
        "## |--- 3 >  0.16\n",
        "## |   |--- 7 <= 1.97\n",
        "## |   |   |--- class: 1\n",
        "## |   |--- 7 >  1.97\n",
        "## |   |   |--- class: 0\n",
        "##\n",
        "## ÁRBOL CON PODA\n",
        "## |--- 3 <= 0.16\n",
        "## |   |--- 18 <= -1.42\n",
        "## |   |   |--- class: 1\n",
        "## |   |--- 18 >  -1.42\n",
        "## |   |   |--- 19 <= -2.32\n",
        "## |   |   |   |--- class: 1\n",
        "## |   |   |--- 19 >  -2.32\n",
        "## |   |   |   |--- class: 0\n",
        "## |--- 3 >  0.16\n",
        "## |   |--- 4 <= 2.14\n",
        "## |   |   |--- class: 1\n",
        "## |   |--- 4 >  2.14\n",
        "## |   |   |--- class: 0\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sKnbihy3rBQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "ow8jwmIerqZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparación de los Modelos de Árbol de Decisión\n",
        "1. **¿Hay sobreajuste en alguno de ellos?**\n",
        "+ *Árbol sin poda*: Sí, hay sobreajuste. Esto se observa porque la accuracy en el conjunto de entrenamiento es 1.00, mientras que en el conjunto de test es 0.91. La diferencia indica que el modelo se ajusta demasiado bien a los datos de entrenamiento, pero no generaliza tan bien a los datos de test.\n",
        "+ *Árbol con poda:* También hay sobreajuste, aunque es menor. La accuracy en el conjunto de entrenamiento es 0.97, mientras que en el conjunto de test es 0.91. La poda ha reducido el sobreajuste, pero no lo ha eliminado por completo.\n",
        "2. **¿Qué impacto tiene la poda?**\n",
        "+ *Accuracy en entrenamiento:* La poda reduce la accuracy en el conjunto de entrenamiento de 1.00 a 0.97, lo que indica que el modelo es menos complejo y menos ajustado a los datos de entrenamiento.\n",
        "+ *Accuracy en validación cruzada:* La poda mejora ligeramente la accuracy media en validación cruzada de 0.91 a 0.92, lo que sugiere que el modelo generaliza mejor.\n",
        "+ *Accuracy en test:* La accuracy en el conjunto de test se mantiene igual en 0.91, lo que indica que la poda no ha afectado negativamente la capacidad del modelo para generalizar a nuevos datos.\n",
        "3. **¿Sería necesario podar más?**\n",
        "No parece necesario podar más. La poda actual ha reducido el sobreajuste y ha mejorado la accuracy en validación cruzada sin afectar negativamente la accuracy en el conjunto de test. Podar más podría llevar a un modelo subajustado, que no capture suficientemente bien los patrones en los datos.\n",
        "\n",
        "**4. ¿Elegirías algún parámetro más, y en caso afirmativo qué otros parámetros y por qué?**\n",
        "Sí, se podrían considerar los siguientes parámetros adicionales para mejorar aún más el modelo:\n",
        "\n",
        "+ *ccp_alpha:* Este parámetro controla la complejidad del árbol mediante la poda de costo-complejidad. Ayuda a encontrar un balance óptimo entre la complejidad del modelo y su capacidad de generalización.\n",
        "+ *min_samples_leaf*: Define el número mínimo de muestras que debe tener un nodo hoja. Ayuda a evitar que el modelo se ajuste demasiado a los datos de entrenamiento.\n",
        "+ *criterion:* Permite elegir el criterio para medir la calidad de una división (por ejemplo, \"gini\" o \"entropy\"). Diferentes criterios pueden afectar la estructura del árbol y su rendimiento.\n",
        "+ *max_leaf_nodes:* Limita el número máximo de nodos hoja en el árbol. Ayuda a controlar la complejidad del modelo y a prevenir el sobreajuste.\n",
        "\n",
        "**Resumen**\n",
        "\n",
        "+ *Sobreajuste:* Ambos modelos presentan sobreajuste, aunque es menor en el árbol con poda.\n",
        "+ *Impacto de la poda:* La poda reduce la complejidad del modelo, mejora la accuracy en validación cruzada y mantiene la accuracy en test.\n",
        "+ *Necesidad de más poda:* No parece necesario podar más, ya que la poda actual ha logrado un buen balance.\n",
        "+ *Parámetros adicionales:* Se podrían considerar ccp_alpha, min_samples_leaf, criterion y max_leaf_nodes para mejorar aún más el modelo."
      ],
      "metadata": {
        "id": "GlY59ADeuI8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gemini Solución**"
      ],
      "metadata": {
        "id": "rckxbJ4gvRnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Hay sobreajuste en alguno de ellos?**\n",
        "\n",
        "+ *Árbol sin poda:* Definitivamente sí. La precisión en el conjunto de entrenamiento es del 100%, lo que indica que el modelo ha memorizado los datos de entrenamiento y es muy probable que no generalice bien a nuevos datos. Esto es un claro signo de sobreajuste.\n",
        "+ *Árbol con poda:* No se observa un sobreajuste tan evidente. La precisión en el conjunto de entrenamiento ha disminuido ligeramente, pero la precisión en la validación cruzada y en el conjunto de prueba se ha mantenido estable. Esto sugiere que la poda ha ayudado a regularizar el modelo y evitar el sobreajuste.\n",
        "¿Qué impacto tiene la poda?\n",
        "\n",
        "**La poda tiene un impacto significativo en el modelo:**\n",
        "\n",
        "+ *Reduce la complejidad del árbol:* Al eliminar ramas y hojas innecesarias, el árbol se vuelve más simple y fácil de interpretar.\n",
        "+ *Mejora la generalización:* Al reducir la complejidad, el modelo es menos propenso a sobreajustarse y puede generalizar mejor a nuevos datos.\n",
        "+ *Puede reducir el tiempo de entrenamiento y predicción:* Los árboles más pequeños son más eficientes computacionalmente.\n",
        "**¿Sería necesario podar más?**\n",
        "\n",
        "La necesidad de podar más dependerá de varios factores:\n",
        "\n",
        "Desempeño en el conjunto de prueba: Si la precisión en el conjunto de prueba sigue siendo alta y no hay signos de sobreajuste, podría no ser necesario podar más.\n",
        "Complejidad del problema: Para problemas más complejos, puede ser necesario podar más agresivamente para evitar el sobreajuste.\n",
        "Interpretabilidad: Si la interpretabilidad del modelo es importante, podar más puede ayudar a obtener un árbol más simple y fácil de entender.\n",
        "*En este caso particular, parece que la poda ha sido suficiente para obtener un buen rendimiento. Sin embargo, siempre es recomendable explorar diferentes niveles de poda para encontrar el mejor compromiso entre precisión y complejidad.*\n",
        "\n",
        "**¿Elegirías algún parámetro más, y en caso afirmativo qué otros parámetros y por qué?**\n",
        "\n",
        "Sí, existen otros parámetros que podrían ajustarse para mejorar el rendimiento del modelo:\n",
        "\n",
        "+ *criterion:* Esta opción determina la función de impureza utilizada para evaluar la calidad de una división. Las opciones más comunes son \"gini\" y \"entropy\". La elección puede afectar ligeramente la estructura del árbol.\n",
        "+ *splitter:* Este parámetro controla la estrategia utilizada para seleccionar el mejor atributo para dividir un nodo. Las opciones más comunes son \"best\" y \"random\". \"Best\" selecciona el mejor atributo en cada división, mientras que \"random\" selecciona un atributo aleatorio de un subconjunto de atributos.\n",
        "+ *class_weight:* Si las clases están desbalanceadas, se puede utilizar este parámetro para asignar pesos diferentes a las clases y evitar que la mayoría se imponga.\n",
        "+ *min_samples_leaf:* Este parámetro especifica el número mínimo de muestras requeridas en cada hoja. Un valor más alto puede ayudar a prevenir el sobreajuste.\n",
        "La elección de estos parámetros dependerá de las características específicas del conjunto de datos y del problema a resolver. Se recomienda realizar una búsqueda de hiperparámetros para encontrar la mejor combinación de valores.\n",
        "\n",
        "En resumen, la poda ha sido fundamental para mejorar el rendimiento del modelo en este caso. Sin embargo, siempre es recomendable explorar diferentes configuraciones y evaluar el rendimiento del modelo en un conjunto de validación para tomar decisiones informadas."
      ],
      "metadata": {
        "id": "WnSkZI8ewKBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "YFgbpzYsw3vU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. ¿Hay sobreajuste en alguno de los modelos?**\n",
        "+ *Árbol sin poda:*\n",
        "-+ Accuracy en entrenamiento: 1.00 (perfecto ajuste).\n",
        "++ Accuracy en validación cruzada: Media = 0.91, con variaciones entre folds [0.88,0.96,0.88,0.92,0.92]\n",
        "[0.88,0.96,0.88,0.92,0.92].\n",
        "++ Accuracy en test: 0.91.\n",
        "++ Indicador de sobreajuste: La diferencia entre el rendimiento en entrenamiento (1.00) y validación cruzada (0.91) sugiere un posible sobreajuste. El modelo está memorizando los datos del entrenamiento en lugar de generalizar.\n",
        "+ Árbol con poda:\n",
        "++ Accuracy en entrenamiento: 0.97 (ligeramente menor que el árbol sin poda).\n",
        "++ Accuracy en validación cruzada: Media = 0.92, con variaciones menores [0.88,0.96,0.92,0.92,0.92]\n",
        "[0.88,0.96,0.92,0.92,0.92].\n",
        "++ Accuracy en test: 0.91.\n",
        "++ Indicador de sobreajuste: No hay evidencia de sobreajuste. El modelo con poda logra casi el mismo rendimiento en validación cruzada y test que en entrenamiento, lo que indica que generaliza mejor.\n",
        "\n",
        "**2. ¿Qué impacto tiene la poda?**\n",
        "+ Efectos positivos:\n",
        "La poda reduce la complejidad del árbol al limitar la profundidad (\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑑\n",
        "𝑒\n",
        "𝑝\n",
        "𝑡\n",
        "ℎ\n",
        "=\n",
        "3\n",
        "max_depth=3) y las particiones pequeñas (\n",
        "𝑚\n",
        "𝑖\n",
        "𝑛\n",
        "_\n",
        "𝑠\n",
        "𝑎\n",
        "𝑚\n",
        "𝑝\n",
        "𝑙\n",
        "𝑒\n",
        "𝑠\n",
        "_\n",
        "𝑠\n",
        "𝑝\n",
        "𝑙\n",
        "𝑖\n",
        "𝑡\n",
        "=\n",
        "10\n",
        "min_samples_split=10).\n",
        "+Esto mejora la capacidad del modelo para generalizar:\n",
        "El rendimiento en validación cruzada mejora ligeramente (0.91 → 0.92 de media).\n",
        "Se mantiene la misma precisión en el conjunto de test (0.91).\n",
        "+ Efectos en la estructura:\n",
        "++ Árbol sin poda: Es más profundo y tiene más ramas, lo que indica una mayor complejidad. Esto puede llevar a decisiones sobreajustadas basadas en ruido en los datos.\n",
        "++ Árbol con poda: Es más compacto y toma decisiones basadas en características más relevantes. Esto reduce la posibilidad de sobreajuste.\n",
        "\n",
        "**3. ¿Sería necesario podar más?**\n",
        "\n",
        "Evaluación de la poda actual:\n",
        "\n",
        "El modelo con poda ya muestra buen rendimiento en validación cruzada y test, sin evidencia de sobreajuste.\n",
        "Una poda adicional (reduciendo aún más\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑑\n",
        "𝑒\n",
        "𝑝\n",
        "𝑡\n",
        "ℎ\n",
        "max_depth o aumentando\n",
        "𝑚\n",
        "𝑖\n",
        "𝑛\n",
        "_\n",
        "𝑠\n",
        "𝑎\n",
        "𝑚\n",
        "𝑝\n",
        "𝑙\n",
        "𝑒\n",
        "𝑠\n",
        "_\n",
        "𝑠\n",
        "𝑝\n",
        "𝑙\n",
        "𝑖\n",
        "𝑡\n",
        "min_samples_split) podría degradar el rendimiento, ya que el modelo podría subajustar y no capturar relaciones importantes en los datos.\n",
        "C*onclusión: No parece necesario podar más*. La configuración actual (\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑑\n",
        "𝑒\n",
        "𝑝\n",
        "𝑡\n",
        "ℎ\n",
        "=\n",
        "3\n",
        "max_depth=3,\n",
        "𝑚\n",
        "𝑖\n",
        "𝑛\n",
        "_\n",
        "𝑠\n",
        "𝑎\n",
        "𝑚\n",
        "𝑝\n",
        "𝑙\n",
        "𝑒\n",
        "𝑠\n",
        "_\n",
        "𝑠\n",
        "𝑝\n",
        "𝑙\n",
        "𝑖\n",
        "𝑡\n",
        "=\n",
        "10\n",
        "min_samples_split=10) ofrece un buen balance entre simplicidad y rendimiento.\n",
        "\n",
        "**4. ¿Elegirías algún parámetro más, y en caso afirmativo, qué otros parámetros y por qué?**\n",
        "\n",
        "Sí, podríamos explorar ajustes adicionales para mejorar el rendimiento del modelo:\n",
        "\n",
        "+ min_samples_leaf:\n",
        "\n",
        "Define el número mínimo de muestras requeridas en una hoja. Aumentarlo podría reducir la cantidad de hojas con pocas observaciones, lo que haría el modelo más robusto.\n",
        "+ max_features:\n",
        "\n",
        "Limitar el número de características consideradas en cada división. Esto puede reducir la complejidad y mejorar la generalización, especialmente en datasets con muchas variables.\n",
        "+ class_weight:\n",
        "\n",
        "Ajustar los pesos de las clases en caso de desequilibrios en el dataset. Esto puede ayudar si una clase tiene significativamente más observaciones que otra.\n",
        "+ ccp_alpha:\n",
        "\n",
        "Controlar el costo de complejidad para la poda posterior al ajuste. Ajustar este parámetro permite explorar diferentes niveles de simplicidad del árbol.\n",
        "\n",
        "**Conclusión:**\n",
        "+ ¿Sobreajuste?\n",
        "\n",
        "El árbol sin poda muestra indicios de sobreajuste.\n",
        "El árbol con poda generaliza mejor y no muestra sobreajuste.\n",
        "+ Impacto de la poda:\n",
        "\n",
        "Reduce la complejidad, mejora la generalización y mantiene un rendimiento comparable en test.\n",
        "+ ¿Podar más?\n",
        "\n",
        "No es necesario. Más poda podría llevar a subajuste.\n",
        "+ Parámetros adicionales:\n",
        "\n",
        "Considerar\n",
        "𝑚\n",
        "𝑖\n",
        "𝑛\n",
        "_\n",
        "𝑠\n",
        "𝑎\n",
        "𝑚\n",
        "𝑝\n",
        "𝑙\n",
        "𝑒\n",
        "𝑠\n",
        "_\n",
        "𝑙\n",
        "𝑒\n",
        "𝑎\n",
        "𝑓\n",
        "min_samples_leaf,\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑓\n",
        "𝑒\n",
        "𝑎\n",
        "𝑡\n",
        "𝑢\n",
        "𝑟\n",
        "𝑒\n",
        "𝑠\n",
        "max_features,\n",
        "𝑐\n",
        "𝑙\n",
        "𝑎\n",
        "𝑠\n",
        "𝑠\n",
        "_\n",
        "𝑤\n",
        "𝑒\n",
        "𝑖\n",
        "𝑔\n",
        "ℎ\n",
        "𝑡\n",
        "class_weight, y\n",
        "𝑐\n",
        "𝑐\n",
        "𝑝\n",
        "_\n",
        "𝑎\n",
        "𝑙\n",
        "𝑝\n",
        "ℎ\n",
        "𝑎\n",
        "ccp_alpha para optimizar aún más el modelo.\n",
        "El árbol con poda es claramente preferible en este caso debido a su equilibrio entre simplicidad y rendimiento."
      ],
      "metadata": {
        "id": "GBqCP0vaxiXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Ejemplo\n",
        "Considera la siguiente salida de código. Realiza una\n",
        "comparación de los dos modelos obtenidos contestando\n",
        "cuestiones como por ejemplo ¿hay sobreajuste en alguno\n",
        "de ellos?, ¿qué impacto tiene la poda?, ¿sería necesario\n",
        "podar más?, ¿elegirías algún parámetro más, y en caso\n",
        "afirmativo qué otros parámetros y por qué?\n",
        "\n",
        "```\n",
        "## ÁRBOL SIN PODA\n",
        "## Accuracy train sin poda: 1.00\n",
        "## Accuracy validación cruzada sin poda (media = 0.90)\n",
        "## [0.92 0.92 0.88 0.84 0.96]\n",
        "## Accuracy test sin poda: 0.88\n",
        "##\n",
        "## ÁRBOL CON PODA\n",
        "## Parámetros del árbol (elegidos {'max_depth': 3,\n",
        "'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0})\n",
        "## Accuracy train con poda: 0.96\n",
        "## Accuracy validación cruzada con poda (media = 0.94)\n",
        "## [0.96, 0.88, 0.96, 0.88, 1.0]\n",
        "## Accuracy test con poda: 0.91\n",
        "##\n",
        "## Árboles resultantes\n",
        "##\n",
        "## ÁRBOL SIN PODA\n",
        "## |--- 3 <= 0.29\n",
        "## |   |--- 3 <= -0.71\n",
        "## |   |   |--- 19 <= -2.40\n",
        "## |   |   |   |--- class: 1\n",
        "## |   |   |--- 19 >  -2.40\n",
        "## |   |   |   |--- 11 <= 1.13\n",
        "## |   |   |   |    |--- class: 0\n",
        "## |   |   |   |--- 11 > 1.13\n",
        "## |   |   |   |    |--- 14 <= -0.52\n",
        "## |   |   |   |    |    |--- class: 0\n",
        "## |   |   |   |    |--- 14 > -0.52\n",
        "## |   |   |   |    |    |--- class: 1\n",
        "## |   |--- 3 >  -0.71\n",
        "## |   |   |--- 4  <=  1.07\n",
        "## |   |   |   |--- 7  <=  -0.83\n",
        "## |   |   |   |   |--- 2  <=  0.58\n",
        "## |   |   |   |   |   |--- class: 0\n",
        "## |   |   |   |   |--- 2  >  0.58\n",
        "## |   |   |   |   |   |--- class: 1\n",
        "## |   |   |   |--- 7  >  -0.83\n",
        "## |   |   |   |   |--- class: 1\n",
        "## |   |   |--- 4  >  1.07\n",
        "## |   |   |   |--- class: 0\n",
        "## |--- 3  > 0.29\n",
        "## |   |--- class: 1\n",
        "##\n",
        "## ÁRBOL CON PODA\n",
        "## |--- 3 <= 0.29\n",
        "## |   |--- 3 <= -0.71\n",
        "## |   |   |--- 19 <= -2.40\n",
        "## |   |   |   |--- class: 1\n",
        "## |   |   |--- 19  > -2.40\n",
        "## |   |   |   |--- class: 0\n",
        "## |   |--- 3  > -0.71\n",
        "## |   |   |--- 4 <= 1.07\n",
        "## |   |   |   |--- class: 1\n",
        "## |   |   |--- 4 > 1.07\n",
        "## |   |   |   |--- class: 0\n",
        "## |--- 3 >  0.29\n",
        "## |   |--- class: 1\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zDhgis93y4TQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "P_8LGM1Q6OoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1**. ¿Hay sobreajuste en alguno de ellos?**\n",
        "\n",
        "+ Árbol sin poda:\n",
        "++ Accuracy en entrenamiento: 1.00 (perfecto ajuste).\n",
        "++ Accuracy en validación cruzada (media): 0.90.\n",
        "++ Los resultados por fold\n",
        "[0.92,0.92,0.88,0.84,0.96]\n",
        "[0.92,0.92,0.88,0.84,0.96] muestran variaciones significativas entre folds.\n",
        "++ Accuracy en test: 0.88, más bajo que en validación cruzada y entrenamiento.\n",
        "\n",
        "**Conclusión**: Hay evidencia clara de sobreajuste. El modelo memoriza perfectamente los datos de entrenamiento, pero su rendimiento en datos no vistos (test) es inferior.\n",
        "\n",
        "+ Árbol con poda:\n",
        "++ Accuracy en entrenamiento: 0.96 (ligeramente menor que el árbol sin poda).\n",
        "++ Accuracy en validación cruzada (media): 0.94, con menor variabilidad entre folds\n",
        "[0.96,0.88,0.96,0.88,1.0]\n",
        "[0.96,0.88,0.96,0.88,1.0].\n",
        "++ Accuracy en test: 0.91, consistente con los resultados de validación cruzada.\n",
        "\n",
        "**Conclusión**: No hay indicios de sobreajuste. El modelo con poda generaliza mejor, logrando una precisión consistente entre entrenamiento, validación y test.\n",
        "\n",
        "**2. ¿Qué impacto tiene la poda?**\n",
        "+ Reducción de la complejidad del árbol:\n",
        "\n",
        "El árbol sin poda tiene una estructura más profunda y compleja, con más nodos y ramas.\n",
        "El árbol con poda limita la profundidad (\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑑\n",
        "𝑒\n",
        "𝑝\n",
        "𝑡\n",
        "ℎ\n",
        "=\n",
        "3\n",
        "max_depth=3) y simplifica las reglas al eliminar divisiones irrelevantes, resultando en un árbol más compacto.\n",
        "+ Impacto en las métricas:\n",
        "++ Entrenamiento: La poda reduce ligeramente el rendimiento (\n",
        "1.00→0.96), lo cual es esperado, ya que el modelo ya no memoriza los datos.\n",
        "+ Validación cruzada: La poda mejora la precisión promedio (\n",
        "0.90\n",
        "→\n",
        "0.94\n",
        "0.90→0.94), lo que indica una mejor capacidad de generalización.\n",
        "+ Test: El rendimiento mejora de\n",
        "0.88\n",
        "→\n",
        "0.91\n",
        "0.88→0.91, confirmando la capacidad del modelo podado para generalizar.\n",
        "\n",
        "**Conclusión:** La poda reduce la complejidad y mejora la generalización del modelo, eliminando el sobreajuste observado en el árbol sin poda.\n",
        "\n",
        "**3. ¿Sería necesario podar más?**\n",
        "Evaluación actual de la poda:\n",
        "\n",
        "El árbol con poda muestra un buen balance entre simplicidad y rendimiento.\n",
        "Una mayor poda (por ejemplo, reduciendo\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑑\n",
        "𝑒\n",
        "𝑝\n",
        "𝑡\n",
        "ℎ\n",
        "max_depth a menos de 3 o aumentando\n",
        "𝑚\n",
        "𝑖\n",
        "𝑛\n",
        "_\n",
        "𝑠\n",
        "𝑎\n",
        "𝑚\n",
        "𝑝\n",
        "𝑙\n",
        "𝑒\n",
        "𝑠\n",
        "_\n",
        "𝑠\n",
        "𝑝\n",
        "𝑙\n",
        "𝑖\n",
        "𝑡\n",
        "min_samples_split) podría llevar a una pérdida de precisión debido a subajuste.\n",
        "Variabilidad en validación cruzada:\n",
        "\n",
        "Aunque hay algo de variabilidad entre los folds (\n",
        "[\n",
        "0.96\n",
        ",\n",
        "0.88\n",
        ",\n",
        "0.96\n",
        ",\n",
        "0.88\n",
        ",\n",
        "1.0\n",
        "]\n",
        "[0.96,0.88,0.96,0.88,1.0]), el modelo logra una buena media (\n",
        "0.94\n",
        "0.94), lo que sugiere que la poda actual es suficiente.\n",
        "\n",
        "**Conclusión:** No parece necesario podar más. El modelo actual ya equilibra simplicidad y rendimiento de manera adecuada.\n",
        "\n",
        "**4. ¿Elegirías algún parámetro más? ¿Qué otros parámetros y por qué?**\n",
        "Sí, podríamos explorar ajustes adicionales para mejorar aún más el modelo:\n",
        "\n",
        "+ min_samples_leaf:\n",
        "\n",
        "Establece el número mínimo de muestras requeridas en una hoja. Incrementarlo podría evitar hojas con pocas observaciones, reduciendo la variabilidad.\n",
        "+ ccp_alpha (poda basada en complejidad):\n",
        "\n",
        "Controla la poda posterior basada en el costo de complejidad. Ajustar este parámetro permite explorar diferentes niveles de poda para encontrar el mejor balance entre simplicidad y rendimiento.\n",
        "+ max_features:\n",
        "\n",
        "Limita el número de características consideradas en cada división. Esto podría ser útil si el dataset tiene muchas características, ayudando a reducir la complejidad del árbol.\n",
        "+ class_weight:\n",
        "\n",
        "Ajusta los pesos de las clases, útil en casos de desbalanceo. Aunque no se menciona el desbalanceo en este caso, es algo que vale la pena verificar.\n",
        "\n",
        "**Conclusión general:**\n",
        "+ ¿Sobreajuste?\n",
        "\n",
        "El árbol sin poda muestra sobreajuste claro.\n",
        "El árbol con poda no tiene sobreajuste y generaliza mejor.\n",
        "+ Impacto de la poda:\n",
        "\n",
        "Mejora la generalización al simplificar la estructura del árbol.\n",
        "Mantiene o mejora las métricas de validación y test.\n",
        "+ ¿Podar más?\n",
        "\n",
        "No es necesario. La configuración actual parece adecuada.\n",
        "+ Parámetros adicionales:\n",
        "\n",
        "Explorar\n",
        "𝑚\n",
        "𝑖\n",
        "𝑛\n",
        "_\n",
        "𝑠\n",
        "𝑎\n",
        "𝑚\n",
        "𝑝\n",
        "𝑙\n",
        "𝑒\n",
        "𝑠\n",
        "_\n",
        "𝑙\n",
        "𝑒\n",
        "𝑎\n",
        "𝑓\n",
        "min_samples_leaf,\n",
        "𝑐\n",
        "𝑐\n",
        "𝑝\n",
        "_\n",
        "𝑎\n",
        "𝑙\n",
        "𝑝\n",
        "ℎ\n",
        "𝑎\n",
        "ccp_alpha, y\n",
        "𝑚\n",
        "𝑎\n",
        "𝑥\n",
        "_\n",
        "𝑓\n",
        "𝑒\n",
        "𝑎\n",
        "𝑡\n",
        "𝑢\n",
        "𝑟\n",
        "𝑒\n",
        "𝑠\n",
        "max_features podría llevar a un modelo aún más robusto y eficiente.\n",
        "El árbol con poda es claramente preferible para este caso debido a su equilibrio entre simplicidad y rendimiento."
      ],
      "metadata": {
        "id": "zldXurTL13y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gemini Solución**"
      ],
      "metadata": {
        "id": "Xhj6_pwP9CEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sobreajuste y Poda**\n",
        "+ Árbol sin poda:\n",
        "++ **Sobreajuste evidente:** La precisión en el conjunto de entrenamiento es perfecta (1.00), lo que indica que el modelo ha memorizado los datos de entrenamiento en lugar de generalizar a nuevos datos. Esto es un claro signo de sobreajuste.\n",
        "Baja precisión en validación cruzada y test: Los valores de precisión en estos conjuntos son menores, confirmando la falta de generalización del modelo.\n",
        "+ Árbol con poda:\n",
        "++ ** Menor sobreajuste:** La precisión en el conjunto de entrenamiento ha disminuido, lo que sugiere que el modelo es menos complejo y menos propenso a memorizar los datos de entrenamiento.\n",
        "Mejor precisión en validación cruzada y test: La precisión en estos conjuntos ha aumentado, indicando una mejor capacidad de generalización.\n",
        "Estructura más simple: El árbol podado tiene menos nodos y niveles, lo que facilita su interpretación.\n",
        "*Conclusión: *La poda ha sido efectiva en reducir el sobreajuste y mejorar el rendimiento del modelo en datos no vistos.\n",
        "\n",
        "**Impacto de la poda**\n",
        "\n",
        "La poda ha tenido un impacto positivo en el modelo:\n",
        "\n",
        "+ Mayor generalización: El modelo podado es capaz de hacer predicciones más precisas en nuevos datos.\n",
        "+ Menor complejidad: El árbol podado es más simple y fácil de interpretar.\n",
        "+ Menor riesgo de sobreajuste: La poda ha ayudado a evitar que el modelo se ajuste demasiado a los datos de entrenamiento.\n",
        "\n",
        "**¿Sería necesario podar más? **\n",
        "\n",
        "En este caso, la poda parece haber sido suficiente. Podar más podría reducir aún más la complejidad del modelo, pero también podría disminuir su precisión. Sin embargo, siempre es posible experimentar con diferentes niveles de poda para encontrar el mejor compromiso entre precisión y complejidad.\n",
        "\n",
        "**¿Elegirías algún parámetro más?**\n",
        "\n",
        "Sí, existen otros parámetros que podrían ajustarse para mejorar el rendimiento del modelo:\n",
        "\n",
        "+ criterion: La función de impureza utilizada para evaluar la calidad de una división (Gini o Entropía).\n",
        "+ splitter: La estrategia utilizada para seleccionar el mejor atributo para dividir un nodo (best o random).\n",
        "+ class_weight: Si las clases están desbalanceadas, se puede utilizar para asignar pesos diferentes a las clases.\n",
        "+ min_samples_leaf: Especifica el número mínimo de muestras requeridas en cada hoja.\n",
        "\n",
        "**¿Por qué elegir otros parámetros?**\n",
        "\n",
        "+ Mejorar la precisión: Ajustar estos parámetros puede ayudar a encontrar un modelo con una precisión aún mayor.\n",
        "+ Controlar la complejidad: Algunos parámetros, como min_samples_leaf, pueden ayudar a controlar la complejidad del árbol y evitar el sobreajuste.\n",
        "+ Adaptar el modelo a los datos: La elección de los parámetros debe estar basada en las características específicas del conjunto de datos.\n",
        "\n",
        "**Conclusión general**\n",
        "\n",
        "En base a los resultados presentados, el modelo con poda es claramente superior al modelo sin poda. La poda ha sido efectiva en reducir el sobreajuste y mejorar la generalización del modelo. Sin embargo, siempre es recomendable explorar diferentes configuraciones de hiperparámetros para encontrar el modelo óptimo para un problema específico."
      ],
      "metadata": {
        "id": "AW65avPn9brp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "VKy3Obqt-YWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. ¿Hay sobreajuste en alguno de ellos?**\n",
        "+ Árbol sin poda: Sí, hay sobreajuste. Esto se observa porque la accuracy en el conjunto de entrenamiento es 1.00, mientras que en el conjunto de test es 0.88. La diferencia indica que el modelo se ajusta demasiado bien a los datos de entrenamiento, pero no generaliza tan bien a los datos de test.\n",
        "+ Árbol con poda: También hay sobreajuste, aunque es menor. La accuracy en el conjunto de entrenamiento es 0.96, mientras que en el conjunto de test es 0.91. La poda ha reducido el sobreajuste, pero no lo ha eliminado por completo.\n",
        "\n",
        "**2. ¿Qué impacto tiene la poda?**\n",
        "+ Accuracy en entrenamiento: La poda reduce la accuracy en el conjunto de entrenamiento de 1.00 a 0.96, lo que indica que el modelo es menos complejo y menos ajustado a los datos de entrenamiento.\n",
        "+ Accuracy en validación cruzada: La poda mejora la accuracy media en validación cruzada de 0.90 a 0.94, lo que sugiere que el modelo generaliza mejor.\n",
        "+ Accuracy en test: La accuracy en el conjunto de test mejora de 0.88 a 0.91, lo que indica que la poda ha mejorado la capacidad del modelo para generalizar a nuevos datos.\n",
        "\n",
        "**3. ¿Sería necesario podar más?**\n",
        "\n",
        "No parece necesario podar más. La poda actual ha reducido el sobreajuste y ha mejorado la accuracy en validación cruzada y en el conjunto de test. Podar más podría llevar a un modelo subajustado, que no capture suficientemente bien los patrones en los datos.\n",
        "\n",
        "**4. ¿Elegirías algún parámetro más, y en caso afirmativo qué otros parámetros y por qué?**\n",
        "\n",
        "Sí, se podrían considerar los siguientes parámetros adicionales para mejorar aún más el modelo:\n",
        "\n",
        "+ ccp_alpha: Este parámetro controla la complejidad del árbol mediante la poda de costo-complejidad. Ayuda a encontrar un balance óptimo entre la complejidad del modelo y su capacidad de generalización.\n",
        "+ min_samples_leaf: Define el número mínimo de muestras que debe tener un nodo hoja. Ayuda a evitar que el modelo se ajuste demasiado a los datos de entrenamiento.\n",
        "+ criterion: Permite elegir el criterio para medir la calidad de una división (por ejemplo, \"gini\" o \"entropy\"). Diferentes criterios pueden afectar la estructura del árbol y su rendimiento.\n",
        "+ max_leaf_nodes: Limita el número máximo de nodos hoja en el árbol. Ayuda a controlar la complejidad del modelo y a prevenir el sobreajuste.\n",
        "\n",
        "**Resumen**\n",
        "\n",
        "+ Sobreajuste: Ambos modelos presentan sobreajuste, aunque es menor en el árbol con poda.\n",
        "+ Impacto de la poda: La poda reduce la complejidad del modelo, mejora la accuracy en validación cruzada y en el conjunto de test.\n",
        "+ Necesidad de más poda: No parece necesario podar más, ya que la poda actual ha logrado un buen balance.\n",
        "+ Parámetros adicionales: Se podrían considerar ccp_alpha, min_samples_leaf, criterion y max_leaf_nodes para mejorar aún más el modelo."
      ],
      "metadata": {
        "id": "nt8We64D-c5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Ejemplo\n",
        "En este ejercicio se proporciona un conjunto de datos\n",
        "definidos por variables numéricas ya divido en un conjunto\n",
        "de entrenamiento datos_entrenamiento_ssii_train.csv y\n",
        "otro de test datos_entrenamiento_ssii_test.csv. Estos\n",
        "datos contienen valores faltantes. Imputa los valores\n",
        "faltantes usando la estrategia median. ¿Cuál es el valor\n",
        "imputado en el conjunto de test en la fila con índice 5 y la\n",
        "columna con índice 3?"
      ],
      "metadata": {
        "id": "dGiMLqXT-6Z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solución Gemini**"
      ],
      "metadata": {
        "id": "-235X4S1_4vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Cargar los datos\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_train (1).csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_test (1).csv\")\n",
        "\n",
        "# Imputar los valores faltantes con la mediana\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "train_data_imputed = imputer.fit_transform(train_data)\n",
        "test_data_imputed = imputer.transform(test_data)\n",
        "\n",
        "# Convertir los arrays resultantes nuevamente a DataFrames\n",
        "train_data_imputed = pd.DataFrame(train_data_imputed, columns=train_data.columns)\n",
        "test_data_imputed = pd.DataFrame(test_data_imputed, columns=test_data.columns)\n",
        "\n",
        "# Obtener el valor imputado en la posición especificada\n",
        "valor_imputado = test_data_imputed.iloc[5, 3]  # Índices en Python comienzan desde 0\n",
        "\n",
        "print(\"El valor imputado en la fila 5 y columna 3 del conjunto de test es:\", valor_imputado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxxxepty_8ey",
        "outputId": "7f246c46-5d95-4f8f-e234-6750ce983667"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor imputado en la fila 5 y columna 3 del conjunto de test es: -1.4774155392346526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "kRGcM3qNAXjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Cargar los datos de entrenamiento y test\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_train (1).csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_test (1).csv\")\n",
        "\n",
        "# Crear el imputador con la estrategia 'median'\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Imputar los valores faltantes en el conjunto de entrenamiento\n",
        "df_train_imputed = imputer.fit_transform(df_train)\n",
        "\n",
        "# Imputar los valores faltantes en el conjunto de test\n",
        "df_test_imputed = imputer.transform(df_test)\n",
        "\n",
        "# Obtener el valor imputado en la fila con índice 5 y la columna con índice 3\n",
        "valor_imputado = df_test_imputed[5, 3]\n",
        "\n",
        "print(f\"El valor imputado en la fila con índice 5 y la columna con índice 3 es: {valor_imputado}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5q9bCAhAcjg",
        "outputId": "06a33365-9a3e-4b41-fae7-b0f118bf212f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor imputado en la fila con índice 5 y la columna con índice 3 es: -1.4774155392346526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "MZwgaPn9A9Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Cargar los conjuntos de datos\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_train (1).csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_test (1).csv\")\n",
        "\n",
        "\n",
        "# Crear el imputador con la estrategia 'median'\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Ajustar el imputador en los datos de entrenamiento y transformar ambos conjuntos\n",
        "train_imputed = pd.DataFrame(imputer.fit_transform(train_data), columns=train_data.columns)\n",
        "test_imputed = pd.DataFrame(imputer.transform(test_data), columns=test_data.columns)\n",
        "\n",
        "# Obtener el valor imputado en la fila con índice 5 y columna con índice 3 del conjunto de test\n",
        "imputed_value = test_imputed.iloc[5, 3]\n",
        "\n",
        "print(f\"El valor imputado en la fila 5 y columna 3 del conjunto de test es: {imputed_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy83Jh1uBAXY",
        "outputId": "25c9bdb2-760e-4a85-b010-470e1b6bf67c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor imputado en la fila 5 y columna 3 del conjunto de test es: -1.4774155392346526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Ejemplo**\n",
        "En este ejercicio se proporciona un conjunto de datos\n",
        "definidos por variables numéricas ya divido en un conjunto\n",
        "de entrenamiento datos_entrenamiento_ssii_train.csv y\n",
        "otro de test datos_entrenamiento_ssii_test.csv. Estos\n",
        "datos contienen valores faltantes. Imputa los valores\n",
        "faltantes usando la estrategia median. ¿Cuál es el valor\n",
        "imputado en el conjunto de test en la fila con índice 54 y la\n",
        "columna con índice 15?"
      ],
      "metadata": {
        "id": "qb1RzQjJBJKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "ICLqG0H5BX9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Cargar los conjuntos de datos\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_train (1).csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_test (1).csv\")\n",
        "\n",
        "\n",
        "# Crear el imputador con la estrategia 'median'\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Ajustar el imputador en los datos de entrenamiento y transformar ambos conjuntos\n",
        "train_imputed = pd.DataFrame(imputer.fit_transform(train_data), columns=train_data.columns)\n",
        "test_imputed = pd.DataFrame(imputer.transform(test_data), columns=test_data.columns)\n",
        "\n",
        "# Obtener el valor imputado en la fila con índice 54 y columna con índice 15 del conjunto de test\n",
        "imputed_value = test_imputed.iloc[54, 15]\n",
        "\n",
        "print(f\"El valor imputado en la fila 54 y columna 15 del conjunto de test es: {imputed_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vDqvW1BhqQ",
        "outputId": "9732c49e-d711-472e-e958-ae0994338ae1"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor imputado en la fila 54 y columna 15 del conjunto de test es: -0.11801035360412984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "sNT5wpXlBxGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Cargar los datos de entrenamiento y test\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_train (1).csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_test (1).csv\")\n",
        "\n",
        "# Crear el imputador con la estrategia 'median'\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Imputar los valores faltantes en el conjunto de entrenamiento\n",
        "df_train_imputed = imputer.fit_transform(df_train)\n",
        "\n",
        "# Imputar los valores faltantes en el conjunto de test\n",
        "df_test_imputed = imputer.transform(df_test)\n",
        "\n",
        "# Obtener el valor imputado en la fila con índice 54 y la columna con índice 15\n",
        "valor_imputado = df_test_imputed[54, 15]\n",
        "\n",
        "print(f\"El valor imputado en la fila con índice 54 y la columna con índice 15 es: {valor_imputado}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4OC-PCTB0Ku",
        "outputId": "a0a51c38-53e5-4787-bf65-1bb8df566233"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor imputado en la fila con índice 54 y la columna con índice 15 es: -0.11801035360412984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gemini Solución**"
      ],
      "metadata": {
        "id": "ykA8clB_B94V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Cargar los datos\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_train (1).csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/datos_entrenamiento_ssii_test (1).csv\")\n",
        "\n",
        "# Imputar los valores faltantes con la mediana\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "train_data_imputed = imputer.fit_transform(train_data)\n",
        "test_data_imputed = imputer.transform(test_data)\n",
        "\n",
        "# Convertir los arrays resultantes nuevamente a DataFrames\n",
        "train_data_imputed = pd.DataFrame(train_data_imputed, columns=train_data.columns)\n",
        "test_data_imputed = pd.DataFrame(test_data_imputed, columns=test_data.columns)\n",
        "\n",
        "# Obtener el valor imputado en la posición especificada\n",
        "valor_imputado = test_data_imputed.iloc[54, 15]  # Índices en Python comienzan desde 0\n",
        "\n",
        "print(\"El valor imputado en la fila 54 y columna 15 del conjunto de test es:\", valor_imputado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk0ruBuzCDdF",
        "outputId": "08cb1e83-3886-45a6-d179-7b73095ab181"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor imputado en la fila 54 y columna 15 del conjunto de test es: -0.11801035360412984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Ejemplo**\n",
        "Estamos entrenando con un conjunto de imágenes de 28\n",
        "píxeles de alto y 28 píxeles de ancho. Nuestro modelo\n",
        "tiene una única capa de convolución (además del Input)\n",
        "como la siguiente:\n",
        "\n",
        "Conv2D(filters=32, kernel_size=3, activation=\"relu\")\n",
        "\n",
        "La dimensión de salida pasa a ser 26x26, sin embargo, nos\n",
        "interesa que esta se mantenga en 28x28. ¿Qué podemos\n",
        "hacer?"
      ],
      "metadata": {
        "id": "6pg6TIWoCR20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Gemini Solución**"
      ],
      "metadata": {
        "id": "U6w001dWDZcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Padding:\n",
        "\n",
        "\n",
        "```\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "```\n",
        "2. Stride:\n",
        "3. Dilated Convolution (Convolución dilatada):\n",
        "\n",
        "**Ejemplo completo**\n",
        "\n",
        "```\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hHG5HlYyDcf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BA3FTs2ENJT",
        "outputId": "7d195fbe-8735-4bb4-dc3c-a0284511ae93"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ChatGPT Solución**"
      ],
      "metadata": {
        "id": "yFbLatCSD0hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Modelo con padding=\"same\"\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),  # Input de imágenes en escala de grises\n",
        "    Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\")  # Mantiene 28x28\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "ltXDUDhoEIFy",
        "outputId": "f8026eac-40e5-49e6-d0b9-50e6ffeefe8a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Copilot Solución**"
      ],
      "metadata": {
        "id": "jUxcMtJIEUjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28, 28, 1)))\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "npaU9n6NEX27",
        "outputId": "bfc6a05e-ea0d-400d-c02a-274c20c9d4cb"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Ejemplo**\n",
        "Realiza una comparación de las salidas obtenidas por estos\n",
        "tres modelos de redes neuronales ¿detectas algún\n",
        "comportamiento llamativo?, ¿qué modelo elegirías?\n",
        "![Sin título.jpg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4QBaRXhpZgAATU0AKgAAAAgABQMBAAUAAAABAAAASgMDAAEAAAABAAAAAFEQAAEAAAABAQAAAFERAAQAAAABAAAOw1ESAAQAAAABAAAOwwAAAAAAAYagAACxj//bAEMAAgEBAgEBAgICAgICAgIDBQMDAwMDBgQEAwUHBgcHBwYHBwgJCwkICAoIBwcKDQoKCwwMDAwHCQ4PDQwOCwwMDP/bAEMBAgICAwMDBgMDBgwIBwgMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDP/AABEIAwAFVgMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP38ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAGySrEuWYKPUnFKXAYDIy3QZ618Z/8ABdH4caL8W/2NdM8PeItPh1TR9Q8UWn2i1lzsl2W91IucejIp/CvmHwp4i1/Rv2nvhH401uHXtVv/AIBWGtfDqxS+gkMtzfad4e1ubUJEU7TcfaVh0o+cCPM8sYC80AfrXWcvi/SX8WPoI1TTjrsdouoNpwuU+1rbM5jWcxZ3+WXVlD4wSpGcivgnxV+0h8V/2ePgL8KviRN8Tb3xxP4/+H2ta3qmjX9pp0lvHfweHJdYgnsUtrWCX7Oktu8Tb5XGLiFTlmDrk3Xj7xp+y78ePiz4z1Lxtc/E/wAReGv2aoPFFtczxWc4e7in1GciNbSC2V7Z5IgY8jcQx+YDGAD9CvFvjTR/AOjjUNd1bTdFsDcQWgub+6S2hM08qQwx73IG+SWSONFzlndVGSQK06/Mf45ePvir4t/Z7vx4vtPiTL4OutZ+G19Yah4xt9EimfU28XWIukt/7MIBt2iNsy+YpOd+CBxXtXjf49fECb4m+LvFlj401fStG8JfFjwl4Ft/CcllYi0u7DUo9DW6acNA119pL6vM6FLhFCwwnaQHEgB9mvII1yxCj1JoByK8K/4Ka/Dnw/8AEv8AYB+MFt4i0PSdettP8HaxqNtDqNpHcxwXMVhcNFMquCBIh5Vhyp5BBrvP2Xv+TZ/h3/2LGm/+ksVAHdUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFACBwWxkZHUelCOJFypBHqDX5lftgSa78J/wDgo58V/H/hWXV4db13wlpnw1jWxSSZWu9Us72TS5pI1UhfLv7WJBMT+7F04IIcleo/Z2k1L4F/A79nj4JfDvWr3wH4b8Q/Erxz4ekv7KK3lu7TTdNvtemhtoXuYpohI7QQj5omZkSTBU80AfodWf4Y8V6X420OHU9G1Kw1fTbgsIruyuEuIJSrFG2uhKnDKynB4II7V8Pfsh/Gr4pftc+M9I8K6x8UtT8PDwt4f1WTUdS8O2umLP4ourfxHfaVFcqbi0mjeEQ6fvcwxxDfdRnbh1VPA/2dP2n/AIxSfBrwd8N/An/CeX+saZ8LLnxZbXng2y0aWDU9Yuta1S3jNy+ofK1orWiki3RWAuMkncgUA/VyPxfpM3iubQU1PT21y3tEv5dOFyhu4rd3dEmaLO8Rs8bqGIwSjAHINaNfnB8XPjr8R/Bnxx17XrqM+DfH2veC/Bfh6aYQQSf2Ol/41vNPacAmaEOLacuhbzFDlCyMMpX1h+x54u8TXfi74weEvEfia78YL4A8Xx6VpmqXkVsl5JazaRp18I5zbxQxGRJLuVRtjU7BGDuOWIB7aJVZyoYbh1GeRTq+T9b8C+DfF3/BRTwcvw58LaBba74A1C/1/wCIviTS7GCCQG8026t4NNurlMPNcTS3MV0bdg21LaKVyh8kSfWFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUjMEXJIAHUntS185f8FdrCHVf+CZPxvtbhBLBc+E7yKVD0dWXBH4g0AfRZkCgZIGTgc9adX5Sav4hk+JmnfCP4V6xDrt9qP7K/jfw/Bqdze2sqRLdjxbo+maJOJ2AW5aXSZb5iwHJcsQrYFXfHX/BRb4zfDfQ/gv8SI/GUGqWXxY+P9/8MdQ8JT6daNb6ZpMeu3djEbdEiS5W5WCxw7SXEi77j7vzKEAP1A1LxPpuj6rp1hd6hY2t9q8jxWFvNOqS3rojSOsSk5cqisxCg4VSTwKl1nWbTw5o91qGoXVtY2FjC9xc3NxKsUNvEilnd3YgKqqCSScAAk1+aHjD9obx9pNp8H/jVqvi258SzXNj8QfE0Hhee0tNmmyWOmX5s4LeGGGOc+XEvlTrLPIwlKjdk5rSt/i78b/H3wMXUtRtvixqPg/xN8MddufFl34otfDselQzvoxntptPaw23G1pg6jfuHlyLkZ+ZQD9INP1CDVrCC6tZ4bm1uY1lhmicPHKjDKsrDgggggjrmpXcRrliAPUmvzti+OPxM8Q/Ar9oXXtB+I+o+CV/Z98L6anhzTYrXTxYXcsfhaz1Z5r/AO0W00rxyS3JjzHJGPLjwoVgXb68+OHhnVPjz+ybeR6V4d8Ca/4o1bRo77SNN8aWBudEN+YhJF9piAZtiuedvzDHBoA9WSQSLlSGHqDS18hf8ElPCvif4aaV8W/C/j6x8B6J4/sPFkV7q+keBrZ7bwxp0c+m2f2b7FGyhk3xRh5Q3zGVnY8OpP17QAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFchqH7QXgLSdQntLrxv4Qtrq1kaGaGXWbdJIXUlWRlL5DAggg8giuvr5i/YL8C6Bcfs/eJtS1CzMj/wDCyfHzSOJZAW2+LtZ7BgOgoA9o/wCGkvh3/wBD74L/APB3bf8AxdH/AA0l8O/+h98F/wDg7tv/AIuqY8FaMwyPCWpY/wCvxP8A4/R/whOjf9ClqX/gYn/x+gC5/wANJfDv/offBf8A4O7b/wCLo/4aS+Hf/Q++C/8Awd23/wAXVP8A4QnRv+hS1L/wMT/4/R/whOjf9ClqX/gYn/x+gC5/w0l8O/8AoffBf/g7tv8A4uj/AIaS+Hf/AEPvgv8A8Hdt/wDF1T/4QnRv+hS1L/wMT/4/R/whOjf9ClqX/gYn/wAfoAuf8NJfDv8A6H3wX/4O7b/4uj/hpL4d/wDQ++C//B3bf/F1T/4QnRv+hS1L/wADE/8Aj9H/AAhOjf8AQpal/wCBif8Ax+gC5/w0l8O/+h98F/8Ag7tv/i6P+Gkvh3/0Pvgv/wAHdt/8XVP/AIQnRv8AoUtS/wDAxP8A4/R/whOjf9ClqX/gYn/x+gDK+JPj/wCD3xc0OHTvEHiz4f6nZwTi5SK51SymVZArKGAcsM4dhnGeTVrX/it8JvE/iPQtWvfGPgK4v/Dc8tzp00mrWbvaySQvA7IxYlSY5HUlSCQxB4JFW/8AhCdG/wChS1L/AMDE/wDj9H/CE6N/0KWpf+Bif/H6APMfhR8K/wBmf4KeL73XPDtx8JtOv762msi8MmlQ+TbysGlhQxqpEb7V3LnB2rkHAqb4H/Dz9m79nPUb+68H33wq0SbU7NdOuWs5tLtjNbKxZYWMQQmNckBDlQO1ekf8ITo3/Qpal/4GJ/8AH6P+EJ0b/oUtS/8AAxP/AI/QB5X4L+EH7M/w+0DUdL0m9+FdnYandWN1LBFNpUcYayuFubVQqqBtimUOgIOw8rg81ta/4f8A2efE/wAdLH4kX2p/Cy58Y6cI/J1KS5017kPGjpHJ5pBl3osjqpDjaGIHBNd1/wAITo3/AEKWpf8AgYn/AMfo/wCEJ0b/AKFLUv8AwMT/AOP0Ac58ctf+C37Rnw7uvCvi3xZ4C1XQ71lae1uNUsZ45cdmSUuhHPdal+C/iv4N/AD4eWXhbwv4v8Cabounlzb20Oq2MKR7mLEBYyqgZPYV0Vh4J8OXOox20+gXlnJNnyzLc7lYgE4+SVuwP5Vr/wDCnvDn/QO/8mJf/iqAKH/DSXw7/wCh98F/+Du2/wDi6P8AhpL4d/8AQ++C/wDwd23/AMXV/wD4U94c/wCgd/5MS/8AxVH/AAp7w5/0Dv8AyYl/+KoAof8ADSXw7/6H3wX/AODu2/8Ai6P+Gkvh3/0Pvgv/AMHdt/8AF1f/AOFPeHP+gd/5MS//ABVH/CnvDn/QO/8AJiX/AOKoAof8NJfDv/offBf/AIO7b/4uj/hpL4d/9D74L/8AB3bf/F1f/wCFPeHP+gd/5MS//FUf8Ke8Of8AQO/8mJf/AIqgCh/w0l8O/wDoffBf/g7tv/i6P+Gkvh3/AND74L/8Hdt/8XV//hT3hz/oHf8AkxL/APFUf8Ke8Of9A7/yYl/+KoAof8NJfDv/AKH3wX/4O7b/AOLo/wCGkvh3/wBD74L/APB3bf8AxdX/APhT3hz/AKB3/kxL/wDFUf8ACnvDn/QO/wDJiX/4qgCHSfj34G1/U4LKx8aeE728unEcMEGr28kszHoqqHJJPoK6yvCf2tvhtougfDvw7d2ll5VxF478J7X86RsZ8QaeDwWI6E17tQAUUUUAFFFFAGX4t8caL4B09LvXdX0vRbSWQQpNf3cdtG7kEhQzkAthScdcA+lc9/w0l8O/+h98F/8Ag7tv/i6+Pf8AgvPZx6hYfsiW8y74p/2lfB8brkjcpF6CMjnpX2j/AMKe8Of9A7/yYl/+KoAof8NJfDv/AKH3wX/4O7b/AOLo/wCGkvh3/wBD74L/APB3bf8AxdX/APhT3hz/AKB3/kxL/wDFUf8ACnvDn/QO/wDJiX/4qgCh/wANJfDv/offBf8A4O7b/wCLo/4aS+Hf/Q++C/8Awd23/wAXV/8A4U94c/6B3/kxL/8AFUf8Ke8Of9A7/wAmJf8A4qgCh/w0l8O/+h98F/8Ag7tv/i6P+Gkvh3/0Pvgv/wAHdt/8XV//AIU94c/6B3/kxL/8VR/wp7w5/wBA7/yYl/8AiqAKH/DSXw7/AOh98F/+Du2/+Lo/4aS+Hf8A0Pvgv/wd23/xdX/+FPeHP+gd/wCTEv8A8VR/wp7w5/0Dv/JiX/4qgCh/w0l8O/8AoffBf/g7tv8A4uj/AIaS+Hf/AEPvgv8A8Hdt/wDF1f8A+FPeHP8AoHf+TEv/AMVR/wAKe8Of9A7/AMmJf/iqAOZ0r4sfCbRPF+r67beMfAcWq67HbxX1wmrWayXCwBxEGYNubaJGxuJxk4xk1yfjrSfgB8R/hkfCOsa18M73Q/7Tm1mO3lvNNkWC8lnluJJ0VsoshknlJfbuPmPkksSfTL/4VeGdOspbiXTyI4ULtieU8AZP8VZQ8F6KwyPCWpYPI/0xP/j9AHlvj74R/sy/Ejwv4W0bUrj4Stp/gy1Njo8KvpRWxt22boY1ZSqRsY0JVAoJUccCk8V/CH9mbxl4H8N+Hby6+FB0nwkk0OkwLLpWyxhmYNLDGpUqkbkLuVAA21c5xXqf/CE6N/0KWpf+Bif/AB+j/hCdG/6FLUv/AAMT/wCP0Acfr1r8APE1nq9vfat8Lrq213RxoN9DLdac8dxZiWWYQspyGQSTSMFbK7mJxkknQ+C3iH4J/s+eCV8P+EvEvw60XTPPkupIrTULC2E80hy8riIqrO3GWxk4Ga6D/hCdG/6FLUv/AAMT/wCP0f8ACE6N/wBClqX/AIGJ/wDH6APMvC3w4/Z48F/Ga88eaX4h+H1j4i1DUZ9WuZ4L/TIjcXUylZJXZVDs7A8sW3HAyTXrP/DSXw7/AOh98F/+Du2/+Lqn/wAITo3/AEKWpf8AgYn/AMfo/wCEJ0b/AKFLUv8AwMT/AOP0AXP+Gkvh3/0Pvgv/AMHdt/8AF0f8NJfDv/offBf/AIO7b/4uqf8AwhOjf9ClqX/gYn/x+j/hCdG/6FLUv/AxP/j9AFz/AIaS+Hf/AEPvgv8A8Hdt/wDF0f8ADSXw7/6H3wX/AODu2/8Ai6p/8ITo3/Qpal/4GJ/8fo/4QnRv+hS1L/wMT/4/QBc/4aS+Hf8A0Pvgv/wd23/xdH/DSXw7/wCh98F/+Du2/wDi6p/8ITo3/Qpal/4GJ/8AH6P+EJ0b/oUtS/8AAxP/AI/QBc/4aS+Hf/Q++C//AAd23/xdH/DSXw7/AOh98F/+Du2/+Lqn/wAITo3/AEKWpf8AgYn/AMfo/wCEJ0b/AKFLUv8AwMT/AOP0AXP+Gkvh3/0Pvgv/AMHdt/8AF0f8NJfDv/offBf/AIO7b/4uqf8AwhOjf9ClqX/gYn/x+pbHwN4euL+KCfw9eWZnJEbS3O5WIBbHySsegPbHFAHReEPiR4d+IIuP7A17Rdc+ybfP/s++iufJ3Z27tjHGcHGeuD6VtV4B8H/Ddl4X/wCCifxat7GHyIm+Hvg6QrvZssdR8TjOSSewr3+gAooooAKKKKAOY8R/Gvwb4O1eTT9X8W+GdLv4QDJbXmqQQTICARlGYEZBBHHQ1R/4aS+Hf/Q++C//AAd23/xdeb/ATwHpPin4/wD7Qs99a+fKnjmyjDea64X/AIRjQzjAIHc16v8A8Ke8Of8AQO/8mJf/AIqgCh/w0l8O/wDoffBf/g7tv/i6P+Gkvh3/AND74L/8Hdt/8XV//hT3hz/oHf8AkxL/APFUf8Ke8Of9A7/yYl/+KoAof8NJfDv/AKH3wX/4O7b/AOLo/wCGkvh3/wBD74L/APB3bf8AxdX/APhT3hz/AKB3/kxL/wDFUf8ACnvDn/QO/wDJiX/4qgCh/wANJfDv/offBf8A4O7b/wCLo/4aS+Hf/Q++C/8Awd23/wAXV/8A4U94c/6B3/kxL/8AFUf8Ke8Of9A7/wAmJf8A4qgCh/w0l8O/+h98F/8Ag7tv/i6P+Gkvh3/0Pvgv/wAHdt/8XV//AIU94c/6B3/kxL/8VR/wp7w5/wBA7/yYl/8AiqAKH/DSXw7/AOh98F/+Du2/+LrG+IXxT+EvxT8Ean4d13xh4C1HR9Yga2u7W41azminjbqrI7MrD2IIrqP+FPeHP+gd/wCTEv8A8VR/wp7w5/0Dv/JiX/4qgDnPFnxe+FPjfR4rDU/GfgS7tYLy0v0jl1ezkVZrW4juYHAZiMpLFGwOMqVBBBAI4nRPCX7OXh74xah48tbv4Sx+J9TkM816JdMEomZo3eYSACTzGeKNmYsSSik8gY9Z/wCFPeHP+gd/5MS//FUf8Ke8Of8AQO/8mJf/AIqgDx/wn4E/Zw8D/F268c6XffCmz8T3d1PePfwzaXHOJJ1dZyJFAk/eeYxc7ssSSScmsnwR8D/2Yfhzq9/eaNc/CiwbULS5sGjgk0mKOKG4QxyogRRhWQ7COhXggivdv+FPeHP+gd/5MS//ABVH/CnvDn/QO/8AJiX/AOKoA8T+Ivwn/Zn+K/ifTdX1+7+FGpXemWtvZKbiXSphPBbktDHJvViyISdq5AXJwBmux+MniT4LfHvwaNB8T+K/AGpack6XUcc+p2MwilTIV1EhZQwDEZxnk+td3/wp7w5/0Dv/ACYl/wDiqP8AhT3hz/oHf+TEv/xVAHAfBLWPgh+zv4Rl0Twj4k+HWjWNzdPfXC2uoWFubqdwoaWTyioZyFUbiM4VRngV2H/DSXw7/wCh98F/+Du2/wDi6v8A/CnvDn/QO/8AJiX/AOKo/wCFPeHP+gd/5MS//FUAUP8AhpL4d/8AQ++C/wDwd23/AMXR/wANJfDv/offBf8A4O7b/wCLq/8A8Ke8Of8AQO/8mJf/AIqj/hT3hz/oHf8AkxL/APFUAUP+Gkvh3/0Pvgv/AMHdt/8AF0f8NJfDv/offBf/AIO7b/4ur/8Awp7w5/0Dv/JiX/4qj/hT3hz/AKB3/kxL/wDFUAUP+Gkvh3/0Pvgv/wAHdt/8XR/w0l8O/wDoffBf/g7tv/i6v/8ACnvDn/QO/wDJiX/4qj/hT3hz/oHf+TEv/wAVQBQ/4aS+Hf8A0Pvgv/wd23/xdH/DSXw7/wCh98F/+Du2/wDi6v8A/CnvDn/QO/8AJiX/AOKo/wCFPeHP+gd/5MS//FUAUP8AhpL4d/8AQ++C/wDwd23/AMXQ37Snw6Vcnx94KAHUnXLbj/x+r/8Awp7w5/0Dv/JiX/4qvA/+Cq3wq0HTv+CYH7RtxDYbJYPhh4kkRvPkO1hpdyQcFsUAfUIORS1Ha/8AHtH/ALo/lUlABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV83fsMf8my65/2VDx7/wCpdrVfSNfN37DH/Jsuuf8AZUPHv/qXa1QB9I1+T/8AwU5/4OQ779hr9va2+Fvh3wl4b8ReGtEjsX8Sajd3NylyjXKLMyRbV2rsgkjbO2XJbHBBWv1gr5G/az/4Is/BD9sf9pvRPij4t8LaZc61YiJdTTFwo1xYgBCJhHPGh2KqrlkYsqqpyoAr9L8Ksy4QwObzrcaYeVfDezmoxhuqmnK3rHpzJa6Sab0WnHjoYiVO2Gdnf8D6y03UYdX0+C7tpFmt7mNZopF6OjDII+oIqekRBGgVQAAMAAcAVleOfC7eM/C11pq3t5pzXOzFxazSQyx7XVvlaNlYZxg4YcE9uK/NXa+h2HyX8L/+CmfiHXvDfxVutR8K6bqmr6LfRXHgTR7C6e3fxNp15q13pWl7piJFV7iW1SUyFVEaX0W9FVRLJ1fif9un4iaN4e+Hml2fwSk1P4s+LBPea74ITxbbrJ4WsLeWGO4u3vPJMM4T7TakIu1n88bN21sdrqf7Avw3l8OaTp+m+H7LQP7F0pNLtJ9L82ymQRz2dxBKZIZEdpIprG3dXZi4KnDDc+7S1v8AZO03XG8L376tq8fibwxHc20euR392l7cW9y8b3EDyLOHZHaCDh2YL5KbQNowgOc+Gv7b/wDwsPTLO4/4Rj7H9r/4TH5f7R8zZ/wj+trpXXyhn7Ru83/pnjb+8+9Xgnh7/gs14oh+HXwo8X+MPg3ovgbw38U7i3nt7jU/iRYR3MGlTwWUkV/DavCk90We6kTyI0Eg8gMQBIMfSXg39iLwh4H+Imqa/ZLeqNQj1eOGxN/dta2X9q3cV5qBjiacxIZrmFZWKIpBJ24BIOL4n/4J0+AvEvhXwvovlX1ppvhnwva+DxBbajewi80612G3gk8u4UuqOm75y5O5gSQzZAMf4r/tzeM/DXxS8Zab4L+ENz498I+A9FurrWPEcPiBLIW+qR2AvotMW2eFpJWkikt/3sZdV88AjcCtd58HP2n3+Ofxg8WaHoehi48KeGFig/4SmK98y2u7yS0srsW6R7BnEV6p3q7L8hGQ2Qul/wAM92Phf4p6z4z0JruC61mMT6hpMd/cRWOr3UdsLeOSSPzDCreUkUZbyiSIo852LjH/AGDP2b5P2Tf2VPC3gaeKwgvNMSee5isZXmt7eSeeScwxyOAzpEJBErFVysa4VBhQAeE/Ev8Abk+MHwP+Lb+HYfDWh/Fq8vvHMvgvTdK0uFtAuGCeG7fW2uWmkluEO0PMmzaoICndnhs34k/8FZNc8JXXxT8K+JvA+meB/EnhP4a6j4tsl0/x/pmp6u1/a6WLy4s/sot5vs7QksFuLiJ4n8oMI5FOyvqO5/Zi8MXXxWsvGLWmdZsPEM3iaKXzZeLyXSF0hnxv2/8AHqoXBXb327vnrgPGn/BNr4feO9c8VXF9BeSWfiuLWVuLD+0L0W0b6tavbahIIxcBA0quxJVVK5baVLE0AeYS/wDBWTV9J/am1HwHcfCy6bwb4a1nw5oWueNpNeASwm1tIo7Fjai1DSeZdzR2/wC7bapbe5jUHFHXP+CoHxB8NeFo5fC3wY1T4lW+i6Bb+JvEepTeKbWwfSbGW71SF5WUWapMY101mCRLvcPgLldze7ar+wZ4C1jUPE9zNp2ZPFureHdZvz59x+8n0O6hurFuJeNkkCHC4Bx84cZB2PCv7IfhDwf4Y8RaTZ2Wy08T+H08N3q+dMfMtEkvpAuTISPm1C45Uhvm+9wu0A870z9vzW9a/aw0rwTa/Da4m8Aa3rX/AAj1j45GsDybi/TS7nUJ4RaeRvHli38vcXCsWbB3IyV9L18wzfsYara/td+D/EmkWkGleD/C+ty+IZ93iG8mF5cto0+m/JYMDDHI3nKWkyCBCxG5pnr6eoAy9f8A+QhpP/X5/wC0pa1Ky9f/AOQhpP8A1+f+0pa1KACiiigAooooAKKKKACiiigAooooA8l/bO/5JVoP/Y9+Ev8A1IdOr1qvJf2zv+SVaD/2PfhL/wBSHTq9aoAKKKKACiiigD4N/wCC7X3P2Pv+zmPBv/t5X3lXwb/wXa+5+x9/2cx4N/8AbyvvKgAooooAKKKKACiiigAooooAKKKKAM/xV/yLt3/1zNaFZ/ir/kXbv/rma0KAPyU/4LCf8HGnin/gn5+2PN8LfA3gzwp4ji0GxtbjWLvVJrnzPPnXzRAipsC7YmjO7Lg+Z2KkV+mP7MPxxs/2mf2c/A3xCsI44bXxpodprCwpIZFgM0Ku0e4qpOxiVyVGdvQV84ft4/8ABEH4Nft+fGrTvHnijR7WDX4oorfUriP7Uj6tFHgIsnk3MQ3BBsDlS23aM4UAfWPw88A6T8KvAWi+GNAsYNM0Pw9Yw6bp9pCCI7a3hQRxxrkk4CqByc8V+t8aZtwRiOGMrw3D+GnTx9Nf7RN7Sdlf7TTvLWNkuWOjODDwxKrzlVd4vY2K+Uvgd/wUbj1+++K0vjZtB0qw8LQ3viDw6LZpPM1LRbefU4hIcFzK7R6W9ySihgl1GPL4V5fqPWtOOr6Pd2glltzdQvCJYnZHi3KRuVlIIIzkEEH0IrxO+/4JxfCS707wnaR+D9HtIPCOkXWh24to5IGntLm0FnOkrI6mXdDuUtKXb52IIJJP5Id551/w8H+L1tonhjSbv9nK5tvit4lv7yZPBf8Awmtq7waDam0SfWDeCDydqyXsCfZztkLNhc4YDu9C/bbvruK9i1TwUdJ1PTfF9t4Ru7RtWExgmk8PW+su5YRYOxpzb7Rw3l79wzsGu37F2mzPoeoTeIPEU/ibw69zFZa7Jqt+19HZ3K24ntPMNyXMTm1t2KsxXfEH278sS7/Yd8K3/wATbfxPNNqktzHdQ6nPA2p3vk3moR6edOF7JH9o8t5TaERlmQkhVJJZQwAPm2T/AILB/E/Sf2bbb4o61+zvpHhrwzrqaPdeHJ9a+KmmabHrlpe2ktzNMrXEKGNoAkQETrvm87KgbSK9jb9urxp48+MWkaX8M/hDN8QvAc0OnPrHi6PxHFp0ejS3kNvdCMW00O+fbZ3MM5KNjDhTtbiu48SfsWeE9f8Ahp4A8Lx/b9OsvhzYJpWlSWd/d200dmLVbR4RJFMsmGiVRlnYgqGzuAameDv2M9D+GuuaZceGdS1nQLSztdPtrmxtNSvUtr82UEVtC8kYuNhb7PDFEzFWZ1jQOX2jABR/Zr/bDuf2ivEOj6WvhVtHuZfBlr4k17N/9o/4Ry/nuJLcaXJ+6QSSLJbXgLgjBtTlF3qT5V+1F+2F8Vv2SvFupB08N/ESCwk8I2tto9npcmkXep3GvazdaUqC4aedU8toonH7s7sspK53D179jn9nG7+A7/EnVNSttPstQ+InjK+8Smzs7l7iOwhlCKkW9goyzJJOwVVUSXMg+Y5duh+Kv7L/AIX+MHiUarrFp510LzQL0N5sq/vNG1KTUbI4WRR8s8jN0wc4YOvy0AfOvhf/AIKw6zZ/tc+FfhR46+HHhjwRe+I0sbeaQ/EnTdR1Gwv7i1SRrQ6fCnntsuJEgEnCuCZR8gOMn4Yf8FYNemvfhhY3fw71LVPDPiLQ/C+oeIvGF54ggEmhSa7e3VhaLLbw2cazs11BGhMKxqPP3MsaoSfdb39gXwXffFdvFTHVVkHiFPFMdkmq36Wi34khleZoVuBC5aSCJ8NGVDLkLknKaP8A8E+vh9onguDQodN22FvaeHLJE+0XPEeh6g+oWIyZs/JO7Hrk5w5dfloA8r+Kn/BSLxR8LZ/FEfhn4cap8TJ9L1LXbh4v7dgshZ6dpg0lppUZbTHliPUWcIxeUmLaGkMihJ/iV/wVL1fwz8ZpNH8N/Cu58WeCNP1PRNL1XxZHrn2WLT5NWuLO3tiLdrctKC9zKDsYhTb4cpvGPa7D9j7wfpt3rU0dlh9etNVs7o+dP88eopZJcj/WcbhYW/TBG35SuW3eHfGz/gndfeJ/iNa/8Ihpdpomk3fiDwzqWr3z+KL8R3cGj3VncJusPmiZ9tvJGoJALSeYzbhyAfY1Z2u/8fWmf9fY/wDRclaNZ2u/8fWmf9fY/wDRclAHj/w//wCUj/xY/wCydeDv/Tj4or3GvDvh/wD8pH/ix/2Trwd/6cfFFe40AFFFFABRRRQB4z+zJ/yXP9oj/sfLP/1GNCr2avGf2ZP+S5/tEf8AY+Wf/qMaFXs1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV8/f8FY/+UWn7SX/ZLfE3/pqua+ga+fv+Csf/ACi0/aS/7Jb4m/8ATVc0Ae+2v/HtH/uj+VSVHa/8e0f+6P5VJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUV8vf8FHdSufBviD4Qa9YeKfEmgXQ8UXGmy21jrtxZWd9byaPqUrC4gR1jn2yQwspkVtjAFcE0z9ujxxH4k+JXw88KP401bwx4P1GPXbnWdQ0HXpNJuUvrKwiurS3e7hdGQbHmnMW8eYIV3K0e8EA+pK+bv2GP+TZdc/7Kh49/wDUu1qu2/ZZ8f8Ajf4m/sP/AAx8Uapb6fJ4/wDEPg3R9U1KG+D2cH26ezgkuA6qhaP52k+ULwcDArgf+Cf7Xb/snaidQS3jvz8SvHZuUt3Z4Vl/4S3Wd4RmAJXOcEgEjHAoA2fjX/wU++Dn7PXxO1Pwf4p1fxbba9o5iF1FZeBtd1KBfMiSVNs9tZyQv8ki52OcEkHBBA5X/h9L+z3/ANB7x5/4bTxN/wDK+voDxH8DPBPjDWZtR1bwd4W1TULjb5t1eaTBPNLtUKNzshY4UADJ6ACqX/DM/wAN/wDon/gj/wAEVr/8RX3GExHB6oQWJw+JdSy5nGrSUXK2tk6LaV9k22l1ZzSWIv7rVvR/5niNh/wWY+AGp30NtDrvjoy3EixIG+G3iVQWY4GSbAAcnqTivqUHNcVF+zX8OoJVdPAPgpHQhlZdDtQVI6EHZXSeLNDuPEfh+eytdW1HQp5tuy+sFha4gwwY7RNHJHyAVO5Dwxxg4I8XPKmSTcP7Gp1Yb83tZwnfa1uWELdb3v02NKftP+XjXy/4dny/8Df+CqmgfFS78dxTaT9puND1OyHh+y0S9t72513T77UpdLsZWLSJHDNLcwPI0cjqIoLm1Z2Bc49b1T9qy303xz4e8Jp4N8X3njHXrK81KTQ4H043GlWtrJbRyTXEjXYtwM3lttWOV3YScL8rbeN07/gmJ8MvCmmaRF4Yi1TwheaRplrpw1HSDbpd3r2t3aXlrdXDSQus08U9mGUupQ+fcBkYSEDsNV/ZPt9T8Y+HPFCeNPGNn4x8P2d3p0mvW6aaLrVrW5ktpJYbmM2htyM2ltho4o3URcMNzbvBNSLwP+2d4X8fWNtPZ2Gvxpdf8JLsE0EQI/sHVF0y8ziU/fmYNF/eTltjfLXD6f8A8FQfBj/CDwT431Pw94k8O6N4+0y21vTItW1DRLa//s+4SB47prX+0DMy4nGUiR5AUYbMlQ3TeBf2EvD3w/8AGF5qVp4l8YzWE8fiBLXR557Q2OmnW7+LUL9oituJiTcxbk82WQIJHUDGAOU8af8ABKv4f+OPA3grw9c6x4qSw8C+ErPwZZHGnTyy2dqEEUhea0kMM58sbpLbyd/AYEKoUA9A1L9rayj1PxzHpXg/xn4isPh5HJ/a2o6fHZeQbhLCO/8AssKS3Mc0sphngwVj8vdMqlxh9ux8G/2k9D+PXiPxBa+GrXVL3TPDtxHaS65si/s28me0tLsJbuJC8o8q8jy4TZuSRd2VxVK1/Zxj8G+NfFXiDw/rGsCPxSTeah4XuJrYaLqd4tlFZq8jtay3MQaK3t1by5Nv7vd5bEsGzf2D/wBmOT9kX9mLw94Lu7mK+1e0V59Suo53ufNmduE86RVkmWGIRQJJIA7RwR5A6AA878O/8FHY9X0zwnLc6Rp9hPBbaq3jyG71KCy/4Ru5sL1NLeBHuZIo/wB7qDN5LSuglggkZcsVU5nxG/4KnaNZ+CNR8ReH7YrpnhYa8PEKypa6rPbnT9AfWENubS9+zT7kMXy/aBnLIWiYFl6f4h/8Eufh58R7/wCKVxc6l4tsv+FsPYvfxWd5CkOk/Zpzct9ijMLLH9ouGaacuHMjtnIwuM9v+CTXw8l8A+LvD0ms+LPsvjQ6m1/JbrptkYzf6INFm8mK3s44I8WyhlAjx5uWbcCVIBjfHP8A4Kff8I9ZPbeBvCusatc6Z428JeFdV1q/tYF0eBdW1qzsLgKBdrcGREluUUiNkWaNd25PvdR47/4KS+GtNtPijp3h7TLjW/FPw68L6l4mSzi1PTbmDUIbPzEc77e7kMQEqRqyTCOUeauE4fazxN/wS+8HeIfEV5dQ+LPH+laZqXiLQ/FN5o1ndWX2G6vdJvob+3J8y1eVVe4iLyKki7vNfG3CbTwB/wAEs/h78PvFPinVItT8UXzeLvC+o+Eb2K4ayQGxvpxPMTJDbRzTTBhgTTySvgncWPNAGvB+3NDa+M4NAvPCHis+JNQsNHns/D8ENh9rkmv11SQKLg332cgQ6XcSEMyBVVcNI8nlplX3/BTbw3Y+CbjWP+EC+JTzaXpWs6zrGmfZdPS90W20tLGS5aYPeLGzNFqNrJGsLyMyseAyla37n9hDSrrxHb6+3jfx1/wldlb6Zb2muBtO+1Wv2AakkTrH9j+zlmh1W6ifdEyldhAV13mton/BO7wjpXgXVtFuPEHjTVpde0HXPD+papfXlu99exasllFPKzLAqCWOLT7aOIqgUKh3K5OaAPYbnVIdci8P3ts2+3vJknibGNyNBIwOPoRW5XPR6RD4e07w1p9s7yW9jJHbRO5BZlSCRQSQAM4HYV514t/4KBfCLwJ+0H/wrHV/HfhbTvFy2puZLS51qyhaDC7/AC3RphIrlPmAKfd56V3YDLMZjZShg6UpuKcmopu0Vu3boiZTjHWTsezUV83/APBUb/gpF4f/AOCX/wCzbF8Qdc0S88SyX2qQ6RYaZa3UdvJczSJJJku+cIqRMSVVj04wSRB/wTs/4KheB/8Agol+z1N460S3m0CXSrU3Os6VeXlvLNpf7y4T5ij5Cn7M7KzqmVIOOuPcjwTnksj/ANZI4eTwfP7P2mlufta/N5Xta+l7mf1ml7X2N/e3sfS9Ffnb/wAE+f8Ag4v+HX7e/wC0rqfw6g8H634QkCeZo+oahqFtJHqYNzFbqjKGXZKzTIwRDJkBueBmv/wWR/4L6xf8Es/jj4W8A6Z8Pl8batqulx67qMs+qiyhtrV5pYUjTakjGUmGQ5YBVG3G7J2/SUvBvjGefQ4a+pNYucedQcoL3Ur35ubl/G99NzH+0MP7L23N7p+jVFfJWl/8FW9E8cf8Eotd/ah8PeHbqSx03StQvYNEu7mPzTNbXMlsscjoWChnRW4yQrDjNfHv/BFb/g4f+IX/AAUA/axtPhT8QvBvhO1m1i0vr6z1XQhPbiDyY1lWJ4ZZJNw2rKNwcHlOOCSYHwf4pxeW5jmtOglTy+Uo1k5RUoygrzSV9eVb2+VxSzChGcIN6z2P13or8Z/+CuP/AAck/Ev9iL9vLXvhb4A8G+DLvR/BUdvDqM+uxXE82pXE9rHcZjMU0YijQTIMEMWKsSQCAPb/APgqj/wWL8afAL/gk98KfjX8NdIttJ1/4vPpojkv4ReR6EtxZSXTjB+WR8x7FLDBG5sZGK9WHgRxa45VOVKEY5k0qLc19qPOue13G8Pe2btp8WhH9p0PfV/g3P0por84P+DfD/grl4+/4KZ+DfG2lfELRtOTWvh9b2DPrdjEYU1c3Ml59+IDZGyrAg+XgnccDpXwr4I/4Obf2hb/APb7/sC503wrdeC9U8XR6HF4f/soieytTfLDhJgwkafy8glyV3MSEHAHdgfo9cXYvN8yyWnGmq2AjGVS89GprmhyO2vNHXXlttKz0Jlm2HjThUd7S20P2v8A2zv+SVaD/wBj34S/9SHTq9aryX9s7/klWg/9j34S/wDUh06vWq/Dj0gooplxH50DoWZQylSytgjPcHsaAH0V4B+zXqNv4O/aI+OOlT+K9Y1Gwi17TJrWLWdemv1sZbq0i3QW4mkYQxtM4VYY9qhmAC5PPiP7LvjLVL/xx8F/GL+OPF2r+LviV4u8QaP4x0e88SXV1ptpb21rrMnlQ6Y0ht7P7Pc2VpEHjijfgrIS0j7gCL/gu19z9j7/ALOY8G/+3lfeVfnp/wAF05vEB8ZfsjJJbaMPDo/aR8GGGZbmQ3rS/wClZDR7NgX73IcngccnH6F0AFFFFABRRRQAUUUUAFFFFABRRRQBn+Kv+Rdu/wDrma8P+Nf/AAU++Dn7PXxO1Pwf4p1fxbba9o/lC6isvA2u6lAvmRJKm2e2s5IX+SRc7HOCSDggge4eKv8AkXbv/rmaxfEfwM8E+MNZm1HVvB3hbVNQuNvm3V5pME80u1Qo3OyFjhQAMnoAK9jJZ5VCu3m8Kk6dtFTlGEua63coTVrX0te9te+dTnt+7tfzPn//AIfS/s9/9B7x5/4bTxN/8r6dB/wWf/Z9uZ0jXXvHe52Crn4a+Jhyfc6fivcf+GZ/hv8A9E/8Ef8Agitf/iKVf2afhyjAj4f+CQQcgjQ7Xj/xyvp/rPBPTD4r/wAHUv8A5QY2xPeP3P8AzO1VtwyK+Vfg3/wVU8GeOtU+Jq63c6Rp9v4Lt7vXNLWwvkvbjVtItzfq0uxTxcH+zLmbyRysM1sTy5x9R6nZvf6ZcW8VzPZSTxNGlxAEMluSCA6h1Zdw6jcpGRyCOK+az/wSR+D9tY+HYdPsdW0dtD0G98O3c9hcRwz+Ira7s3s5Wv5PLLTSbJJmVwV2yTyMOWr4A6jvLz9rr+zvHnh7wjcfDrx7F4x8SWd9qltonmaS08VhZvZxz3kkq3xt1jEt9BGF80ysxYiMqpap0/bC8PpfajaXGkeIrO80nxRH4RuoJYrdmivX0eHV+qTMpjWCZULAn94rAArhzUuv2P8A+0PGnh7xVcfEf4gTeMvDVre6bba8U0lbmXT7xrSSeykjWxFu0RlsreQN5QlVlbEgVitVb/8AYZ0fUviO3iKXxh43P2nWIvEV7polsVs9Q1KPShpX2uTFr5oZrZU3Ikixb41YIDnIBkaV/wAFE9EvvgV4c+Id34K8WaFoHjGytNQ0FdZ1Xw/ptxqsNzbNcoY1m1JQGWMLuRmVxvGFIDFer+HP7XFj8ZNTI8IeEfF/iLR4hY/aNZg+wW9nbNd2dveorLPdRzsVtru3kbZEwHmbQWYMow/GH/BPrwf4z+DPw18Dz6lryaT8LdOh0rS3eKwu5LqGOzW0BnS4tpYTIY1B8yOON1YtsZAxB0/hN+xvafAuS0i8KeOPHGk6VDBp0V3pgOnT22pvZWdtYpNK0to0qvJbWkCP5MkanZuVUYliAaXwM/ax0H9oHxB/ZmjaX4gtrm30O31rUPtkEKLpLzXFzbCxnKSt/pay2lyHRN6p5XL/ADJu8p0P9v7W49Dg0TXtB0PSfiZpXikaN4i0iS/8q1sbFNO/tee+illKbohp+FWRysQuWEbuoBNd3+xr+zFe/s+N4/1TWHsf7X8d+JrvWRa2d3JeW+kWjyPJFZxTSRxuyCSW4nwUVUe7kVRtAJh+KH/BPzwN8WPjlr/j+/uvEVrq/iPwjd+Ebq2srtIrILcp5T6gsfln/TxABAszFtsQCbcZoA5/TP8AgoVpfxQ0gz+DLaLz9L8ZaV4U1eG+mtrxYvtlxpuXimsrmWB/9HvwylZG2uMMuVKniPFH/BVT+0/g54V1fwX4c1TWtQ1W/wDBceqX95p0Ntp2lQa9rFvZhZYhemYT+Q8rqIjOiM0RdiCVPpHwo/4Jw+CvhDDrIsNU8QztrvifTvFd0THp9pGLuyFiIljhtbWGGOIjT4N6qgLFpDkFsjAs/wDglJ4H0jw1oGjad4r+IGm6Top8Nvc2kF1ZFNbk0G9W8sJLkvaswbeio/kmIOgAwCAwALPx5/4KWeGfgvNr+hLZHU/GOn+HtR1XT7SHUtPki1C6s9LbUXtmjS6NzAfKRzunhjUiNsMSyb7uu/t/2Hge48IDxH4e8RaTd+J/DFzrqaQtra3FxJKl5pNnFAs6XhiV5ZtVgVFYFWEmXkh8sh87xP8A8Eo/h14x+MM3jLUdU8VXF1cSanJJaF7IRuNQ0uTS7hGn+zfa2j8iViiNOVjYLtAUbK6HxP8A8E+fDfjlPD0mt+KPGmqah4Y0G50Gwv5JbGOZFlvNNvI7giO1WMzQTaTZmM7NmFbekm7NADtL/b103XvGUPhnT/APxBvfFYuNTtb3R1TTI59Lksf7OMglke9WA+YmqWbxmKWQMshztKkV3Xwk+M2k/tEfCXwR440KO9h0nxRHFqFtFeRCO5hV4nPlyKCwDqcqwDEZBwSOawPhd+xtoHwv+IMfiwa14m1zxI0mpz3uoalNbl9Tlvm07zJJVihjRSiaXaRRiJUUIrZVmO4bvwg+C2l/s6/CfwZ4J0Se/utK8OEWltLfOj3DoElOXKKqk8noo+lAHHfD/wD5SP8AxY/7J14O/wDTj4or3GvDvh//AMpH/ix/2Trwd/6cfFFe40AFFFeIf8FDbUp+y7rWqQ6/4g8O3ugSwajZ3Oka1caXI8qSqAkjwuhkjIJ3RMSjY+YEcUAe30V8+/t3/FK3tvhhpekad4wfQ49U8YeHtD8QXek6oLW/06xv72KMgTowe1M4dYxKpRwJSY2D7SOk/Y01m/1X9nMhdUutffStc8QaRpt7qV9Jdy3VrZ6xfWtoZrht0kp8mGIGVi7vjcxZiSQCv+zJ/wAlz/aI/wCx8s//AFGNCr2avBf2M5dam+Kv7QbeIINLt9T/AOE+tfMj0+eSaAD/AIRnQtuGdEYnGM/L1r3qgAooooAKKKKACiiigAooooAKKKKACivhP/g4a/bS+Jn7DX7BUXij4W3H9l63qviG20e71YWYuX0m2kincyIGVo1ZnjjjDOCB5nA3FSMr/g3I/bc+KH7c37EWta98VL9td1bQfE02j2WsPaJbvqFsttbyAOI0VGZGkZS45PG7kEn9Fj4ZZpLg18bqcPqyq+y5eZ+0v3ta1r/3r9bW1OT65D6x9W1va/kfoDUd3eRWFu0s8scMSfeeRgqr9SaauoQNfNbCaI3KoJGiDjeFJwGK9cZ71+Uv/B1f+0X8ZPgD8Cvhp/wrnxF4j8KeF9Z1K7j8Q6jock9rcCaNYTaxPdRYMaNunOzeu8p0IXjzfD/g2vxVxDhuH6FSNKVdtKUr2VouT23bStFdXZF4rEKhSlVavY/WDNFfJ/8AwRD+J3xC+MH/AAS++FviT4oX95qfinUbO5Jvr4SC8u7VLqaO2lnLgF3aFEPmc71KuSSxJ+ifhz8avCHxgbUR4V8UeHfEh0mb7PejS9ShvPsknPyyeWzbDweGweDXlZ/w9iMrzHF5dL3/AKtUlTlON3G8ZON79m1pculVU4RntdXOinvYbWSNJJY42mbbGrMAZD1wPU1LX4I/8HIv7Zf7RXwO/wCCkvhXRfA/jXxx4X8O22lWV54bs9Dlnt4NRu3dhL5ioAt2/mALsbeoUqu35mB/Sr/gqZ8Wvi58Mv8Agjz4u8W+DLi5074nWvhzTpr240+2k+02Zkkt1v5IEC7o3SN5mDEDywpbKlcj9Ex/g7jcNhMixTxVJ/2s0oK7/dtyilz6bLnXNbZprXc5I5hGUqseV+5+J9gWl5Ff26ywSxzRN9142DKe3BFSV+SP/BqP+0f8ZPj/APCn4qp8RPE3iTxb4V0W+sV0K/12ee8uFuJVuDdRR3MuS6AJASm47C4OBv5/RGx/bp+FmpftOS/CCDxl4dk8eQxF201dWtDOJFGWg8oS+d5oUbimzIXmvnuN/DrMOHuIMZkEX7eWFSlKVNNpRcYyu+1lJKV9nc2w2LhVpRq7c3c9ZuruKxt2lmkjhiQZZ3YKqj3Jp4bcMjkHoa/LT/g6i/aE+L3wC/Ze8BS/DfxD4i8K6Hq+tTQeItR0SSa2uV2xo1tG1zHgxRs3mZG5d5VRyARX0J/wQ0+KvxO+NH/BK3wJ4i+IWoXWseL7yC8SyvtWEv2i8t0nkS1kuGYBpCVVf3nJddrZJJNdWM8M8Vh+CsNxrKvB061Z0lC7501zavS32XddE4vrpMcZF4l4azule59hxXkU88kSSxvLDjzEVgWjzyMjtkUXN5FZKpmljiDsEUuwXcx6AZ7mv5/P+CC37bH7Tvxh/wCCvF1oHjHxj438Q6RqI1N/Gml6w9zPZaV5UUrR7IXBSyZbgRxqAIxg+XjkLXrX/B1b+1X8cvgH8Vvhbpvgbxh4v8GeCL7Tpbw3GgXNxYG61JZmBSW4i2ltsfllYt3csV6GvvMR9HnMaPG+G4JljaTqVqXtedc3KlaTata/N7rt3i09NjlWbQeGeJ5XZO1j9rqjtLyK/gEsEsc0bZAeNgynBweR718H/tDfHX47aD/wQAHj7TLi+h+NT+BdNvr66t7CT7bC0pgF1MsQTck627yOTtAjYM3AXI+ev+DUD9pD4xfH/wAA/F2P4geK/EvjDwtot5p/9j3mvXdxfXEV1KtwbiOK4lLFkCpCzJuOwupAG8k/IQ8JsZLhfMuJ3iafJgayoygm3KT5ox5o6WteScb7pS2tr0fXo+3hRs/eVz9dHvIorlIWljWaUEpGWAZwOpA6nFeB/wDBWP8A5RaftJf9kt8Tf+mq5r8dv+Con7bH7UPw6/4LxDwz4T8ZeM7C2stY0u18MaBYNc/2VfWc0cJbfaAbLkOzyiRyjnKsAfkXb+xH/BWDd/w6w/aR3Y3f8Ks8S5x0z/ZVzXDx54a4nhfL8szCvXhUWOpe1io3vFWi7Suu0lquqkumtYXGKvKcUrcrse/Wv/HtH/uj+VSVHa/8e0f+6P5VJX5qdgUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBxXxb/Zt+HXx+lsX8d+AfBfjV9LDrZNr2h22pG0D7d4jMyNs3bFztxnaM9BU2ofs/eAtX8InQLrwR4RudBaeG6Omy6NbvaGaFI44ZPKKbN8aRRKrYyqxoBgKMdfRQAgG0YFeA/8E8LGLUf2c/EEUyB0b4l+PgR/3N+sjrXv9eDf8E4/+Te9e/7KX4+/9TDWaAPZf+ESt/8AnvqX/gdL/wDFUf8ACJW//PfUv/A6X/4qtSigDL/4RK3/AOe+pf8AgdL/APFUf8Ilb/8APfUv/A6X/wCKrUooAy/+ESt/+e+pf+B0v/xVH/CJW/8Az31L/wADpf8A4qtSsX4jfEXRPhF4B1jxR4l1K20fw/4fs5L/AFG+uDiK1gjUs7tjnAAPQZ9KulSnVmqdNNybsktW29kl1bBu2rJv+ESt/wDnvqX/AIHS/wDxVH/CJW//AD31L/wOl/8Aiq8X/Yq/4Kc/BT/goRNrsPwp8Yp4gvPDhBvrSWxuLK4jjZiqTBJkQtGxHDDOMgHBOK/M/wD4K/8A/BfX4mfsgf8ABUmx8B+EU1Ow8FfDx7AeI9LMNmx8VefHFcv5by27yRDypljBVuSpI29a/S+EvCHibiDPKvDuHoOliaVOVSUat6bUVa101e8nKKjpb3k21G7OOvj6NKmqrd4t201P2XPhO2UZNxqP/gdL/wDFU2HwzaXMSvHdX8iMMqy38pB+h3V8e/8ABdPw/wDE340f8EsPGNp8JtL8WSeIr+e1F1punQyJqlzYLOBcRrEmXbcoBKLyybuoJB+Z/wDg13+EH7QHwt+HusJ8Q9N8Y6D8OJhetpGna+sluy3LNYlZIoJQJFjIW4wQAhbecZJJ1y/w2o4ngzE8Vzx9OFSjV9n7B255aJ3T5r3d9Fyu6TfN0FLGNYhUFF2avc+4vAn/AAUT/Z7+Jn7SepfCPQ/ipYX/AI/0ppo59NTULkK0kIJmjjmOIZJIwrbkRyw2PkfK2PC/+C5H/BVFf+CWXw+8HReHoH1Txr4zupmtYL/7Tc2kVpbhPOd9lxEQ26WILyc/NxxmvlH9m7/g2a+JXwx/4KP33jzXfFPgyX4cW1/qV/aSWtxdHULpbqO4SKMxbV2MhlUsTKR8vBbJx+m37fH/AATh+GP/AAUY8C6Vo/xE0G11KfQJ2n0q9Z545rAybPNCtDLExWRUUFS2PlU4yor67G5X4a8O8V5ZUp4meYYBwUq6SV1NppLaN1zWlKHxJXXM2c8Z4ytQmmuWd9Dmf2cv2urL9sT/AIJ1D4v+ARrFxrl74XvL6309zOrrqUCTxNCIvNbI+0wOqgOdwA55r8u/+CHn/BVP9qD9r39tSbwl408Q6t4v8Ow2aSalD/ZsVv8A2Zm+tYmlZ4VjZCI5JRgkjqdp28ftx8C/gZ4U/Zr+E2ieB/BGi2fh7wv4dt/s1jYWoOyFSxdjliWZmdmZmYlmZmJJJJrf0rwzpuhXV1NY6fZWc19J5tzJBAsbXD9NzkAFj7mvnMs474byzDZvgaOUxrwxUv8AZ51eV1KEbyt9l68rV+WUdVuzaeGrTdOTqW5d7bM/G7/g4S/bC/ap/ZG/a38J6b8JtQ8TWHgLXdBgayey0tdSF1qQnmWZC7pIwlCmDCAjgqQMkmvevFF5+1/qX/BDefxDLBryftMW0ktxdWMdrFJeXNomqOpRLRVaJ5DZgEKq7mAGMucH9JGQPjIBwcjI6Glon4oYH+ycry6lk+GVTB1IznVcE5V+Ru0KmifLJP303LmaTXLawfUpe0nN1HaStbt6fofln/wQL1T9sD4n+ML/AMUfHqHXLD4f/YLuDTLLWtKh0u6N+JLUJKtv5SShfLNyA5AU4PXivlr9ub/g28+OP7QP/BS/x94l8PxaO3w98a6tc67FrV3ryJJbNMpkaF08syhhMSoCxsApX5jya/fGivUy7x5zfKOIMVn+QYWhhXXp+z9nCFoRV7qSScffX82z6xIlldOpSjSqybs73ufMH/BSz/gmP4W/4KN/ssad8PddutSt7rw5cRX+jajHeCOeK4jhaH95I0Uu5XRzv+QknB4IFRf8E8v+CUHw2/4J9/AbU/COh2l3f3fizT1svEt7e3huH1QA3B28JGqqBcyKNqLlduckZr6kor86XHefLJP9XY4mSwvP7TkTsua9/uv71tubXc6/q1L2ntre9sfnP+wZ/wAG53ws/Yt/aU1Px/8Aa9c102dxHJ4ct7zU1mXT9k8U6yOqW8RMivEoHzsNpOQSc17N/wAFDv8AgjL8Gf8Agpb408O+I/H1lrdtr/h6EWQv9HvhaTXlpvLi3m3I4ZVZnK4AYeY2G5r6yor08Z4qcWYrN4Z9Ux1T6zCPLGak01G1mlbv17vUiOCoRp+yUVynmvw//ZA+G3ww/Zxf4R6N4S0u2+HUttdWcuhspkt5Yrl3eZW3Ek7mkcnJ78dBXnv7IP8AwSb+AH7CniubX/hn8PrLQ9enWaL+05ru4vruOKUoXiSSeRyqfIowPf8AvNn6Mor52PFOdRpYihHF1VDEPmqrnlao3e7mr2m3d3crmvsKd0+Vababeh8z/tT/APBHv9nX9tH4wQePPiP8ObTXfE8duLaa7j1C7svtyKuxPPWCVBIUXAVm+YAKM4AA9c+IX7MHw8+K/wAFoPh14k8G+H9Z8DWtvBaQaJdWavZ28UKhYVjT+DYoAUrgrjg13lFFbinOq1LD0auLqyjh/wCEnUk1T/69q/uf9u22XYFRpptqK13039Tkvgx8B/Bn7Ovgi08N+BfDGi+FNDsk8uGz021WCNRuZucDLHc7nJJOWY9zXE6V/wAE9fgbonxmvPiHa/CnwLF41v7kXs+rjSYjcNcCQS+eCRhZfMAcuoDFhknNex0Vy088zKnUq1qeImpVfjanK876vmd7y111uV7ODSTS0PJf2zv+SVaD/wBj34S/9SHTq9aryX9s7/klWg/9j34S/wDUh06vWq8ssKbJGJYyrAMrDBBGQRTqKAOE8Pfsu/DPwl4v1LxDpXw68C6Zr+szi51DU7TQLWG8vpROtyJJZVjDyMJ0SXcxJ8xFb7wBrU0P4KeDfDPxC1HxbpvhLwxp/ivWE8u/1q20uCLUL1fl+WWdVEjj5V4Zj90egrp6KAPg3/gu19z9j7/s5jwb/wC3lfeVfBv/AAXa+5+x9/2cx4N/9vK+8qACiiigAooooAKKKKACiiigAooooAjurVL22eGVd8cilWX1BrP/AOERt/8AnvqX/gdL/wDFVqUUAZf/AAiVv/z31L/wOl/+Ko/4RK3/AOe+pf8AgdL/APFVqUUAZf8AwiVv/wA99S/8Dpf/AIqj/hErf/nvqX/gdL/8VWpRmgDL/wCESt/+e+pf+B0v/wAVR/wiVv8A899S/wDA6X/4qk8b+OdF+GnhK/1/xFq2m6DoelQm4vdQ1C5S2tbSMdXkkchVUepNYfwY/aF8B/tG+H7nVvAHjPwv410yzuDaXF1oepw38UEwAJjdomYK2CDg9iD0NdUcFiZUHio05OnF2crPlTfRvZPyFzK/LfU3f+ESt/8AnvqX/gdL/wDFUf8ACJW//PfUv/A6X/4qvmL4if8ABcP9l74V/tCy/DDXPilp9l4stNTfR75WsLv7Hpl2hCmOe68ryEw52lt5VGVgxXaay/8Agq5/wWY8D/8ABKSDwnb+IfD2t+LNb8YLcy2djpsscIhhh2AySO54BeRVGAScMf4efqsD4c8UYvG4bLqWAqqriU5UlKDh7SKV3KLnyppLW97Wt3RhLF0Ixc3JWW/kfWP/AAiVv/z31L/wOl/+Ko/4RK3/AOe+pf8AgdL/APFV8zfs1/8ABUTRv22P+Cdni342/Dnw5rsuo+HtO1MN4clCterqFrAZVt1ZQ6vvzGVYKchxldwK1+T3/BDL/gr3+0X+0d/wVD8I+FfG/jfxN448N+Kre8gv9OeO3W3sxFZyyJc7ViUIFaNc7NpbdyWJwfrsh8EOIcywGb42fJReWJ+1hN2m3GMpNRsmtouzbSelm9WuermVKEqcVrz7WP36/wCESt/+e+pf+B0v/wAVTJ/DNnawPLLdX8ccalndr+UKoHJJO7gV+F//AAdL/tRfHb4OftjeFdJ8L+LPiH4L8AT+F4ZrQ6LqtxY2Wp3YuZDO7GErukT/AEddrlio2EY38/ZGufDr4+/tpf8ABuXFoVz/AG7/AMLo8T+Fo2mj1Gb7LqGrwpeB/LkYhcPcWaBcPjf5gDn5mNdeJ8F6mEyLJ+IMZj6UKOYVY0/OkpN3nLVJqCT59Vyuyb10lZjzValKMXeCv6n3p4Z1Lwz41uLyLRvEUerS6dL5N2llrRna1k/uSBHO1vY4NeEfEn/gqH+zV8Ifj5H8MvEPxd0/T/GjXy6ZLYm9u3W0uWCERzTKDFEfnUfO4AOQcFTj82/+Daf/AIJt/tB/so/tteMPE/xC8H6/4F8Kp4cuNKul1EqqavdPcQNGsYDESBfLkbzFyo6A/PWP+19/wayfF341/tyeL/F3h/xj4Bj8D+OvFV7rkk11PdLfaVBczmdkaHy2EjqZHRdsuG2Akpu+X63D+FHh/geKcVkueZ8nh6dGM4VafLaU3vFte0jeK15U7yukmnoYPHYqVCNSlS1b1T/pH62ftkfte/Cj9gf4dWnij4o+KtQ8P6XqFy1nZ7Zbq5mvJxE8vloke4k7UPJwMkAkZFVv2Ev23fhP/wAFB/h5c+MPhfrmpazaaPeGyvINQWeG40+coGAeKQ45RuGXIPIByCB5h/wWJ/4JQL/wVA/Z28MeEdM8RWXhTVvB2oNf6feXlpJdpIptpIjAdsilQzGIlzvI8voc1U/4Ii/8Epr/AP4JU/AXxPoOveIdJ8TeJPF2rrqN3dadbyxQQRRxLHFADIcvg+Y+7Yn+tIwdoNfnf9kcEf6iyzD63U/tf2llSt7nJzb/AAfya359JaWOv2mJ+tcnKvZ23PZPh/8A8pH/AIsf9k68Hf8Apx8UV7jXh3w//wCUj/xY/wCydeDv/Tj4or3Gvyk7grmvil8GvCHxy8OppHjXwp4b8YaTFMtyllremQ6hbpKoIEgjlVlDAMwBxnDH1rpaKAOSsvgH4F03QtR0u38F+E4NM1iyh02/tI9It1gvrWGPyooJUCbXiSP5FRgVVeAAOK6Dw34b07wdoFnpWkWFlpWl6dCtvaWdnAsFvaxKMKiIoCqoHAAAAq7RQB4z+zJ/yXP9oj/sfLP/ANRjQq9mrxn9mT/kuf7RH/Y+Wf8A6jGhV7NQAUUUUAFFFFABRTLm5js7eSaZ0iiiUu7u21UUDJJJ6ACviv8AYz/4L3/Ab9uT9qW/+E3hC58R2uuL5/8AZF5qdkkNl4jEIZpPszLIz52I0gEqoWRScZG2vfynhbN80wuJxuXYedWlho81WUVdQi76y+5v0TeybMp16cJKM3ZvbzPsHxZ480PwFbQTa7rOlaLDcyiCGS/u47ZZZD0RS5ALH0HNcp+1V8cYv2b/ANmHx98Q2ja6j8G+Hr3WljjiM3mmGB5FG0MuQSoz8y8H7wHI/KD/AIOfP+Cenx4/az+Nnw08QfDnwrrvjvwxp2kTadLZ6YwkbTLxrguZGiJBAkjMY8wAj9zhiMLn9L/2Cvghr/w4/wCCfnw0+H/xLii1PXdP8JW2ka9a3TLco/7nY9vIeVkCofLPUNtPUGvuMy4LybKuHMr4k+vQxE6837XDxspwjFu93zNq6Vm5RWsla635oYipOtOjy2SWjPhX/g3+/wCC33xE/wCCjnx08ceA/idb6IdQstK/t7R5tI0s20UUKTJFNFIxlboZotny5OHy/QH5U/4Kh/8ABSn9p/4S/wDBcC68K+EvFPi3TtK0bWtMstA8MWsRax1W2ljgJ3W4ytx5zPJljlucAqVAX9pv2Wv2Bvg9+xVPrUvwu8A6F4Pn8QsrahNZo7S3AUkqhd2ZggLEhAQoJ6V6ldeGtOvdZt9Rm0+yl1C0VkgungVpoQ3UK5G5Qe+DX2VPxX4Qyzi/GZ3lOSRng61H2caNTlSjJqN5pKM4q9mmlq02+ZXaOf6jiJ4eNOpU95O91/SIPFvgzSPiR4Ru9E8RaTp2taRqcXlXmn39slxbXCnBKvG4KsMgcEHpUfgD4daB8KPCdroPhfRNJ8O6JYgi30/TLSO1toASSdsaAKMkknA5JJrZor+fPrNX2XsOZ8l78t3a+17bXtpfc9Wyvc/nq/Z1/Yu/ap0b/g4Tk8T33hrx/bxReObjU9W8TyxTJpd3ojTsSBdECKSJ7faixAk8BdoKkL/QfqGnW+rWb291BDcwScPFKgdG78g8GpqK/RvEnxNxXGNfCV8RQhReGpRpLkvqo9XfbyS0icmDwccOpJNu7vqebftjfDLXfjR+yX8TPCHhe8bTvEnibwvqWl6VcrcG38m6mtpI4iZACUG9lywGQM4r8n/+Da//AIJYfHz9jH9rbxx4v+Jnhi/8FeG28Oy6IlvNqEL/ANq3bXMEiOI42cPGiRy4kJHLjbnLY/amiseHPE3M8l4bzDhjC04OjjeXnck3ONv5Wmlr5p23VmOtg4VK0K0m7xILrTLe+mgkmt4ZpLZ/MhZ4wxibGMqT0OCRketT0UV+dXb0Z1kGn6bb6TaLb2sENtAmdscSBEXJycAcdSa/Erwt/wAG/Pxhs/8AguA3xRuorVPhTB4+k8cR63/bqNeSp9pN5HDs2mXzDKVRgUA2hv3nRq/byivvuB/EnOOFFjFlTj/tVN0p8ybsn9qOqtJXdm7rXVM5cTg6dfl5/su5Df6fBqtm9vcwRXMEow8UqB0cehB4NSqoRQAMAcADtS0V8Dd2sdRBBp1va3c88cEMc9ztM0ioA8u0YG49TgcDNF9ptvqcaLcwQ3CxusqCVA4V15DDPQjsanop80r3vqAVDp+nW+k2iwWsENtAhJWOJAiLk5OAOOSSfxqaild2sBBLptvPfRXLwQvcwBlilZAXjDdQG6jOBnHpXgv/AAVj/wCUWn7SX/ZLfE3/AKarmvoGvn7/AIKx/wDKLT9pL/slvib/ANNVzQ23uB77a/8AHtH/ALo/lUlR2v8Ax7R/7o/lUlIAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8G/wCCcf8Ayb3r3/ZS/H3/AKmGs17zXg3/AATj/wCTe9e/7KX4+/8AUw1mgD3miiigApizq8zID8yYJGOmaJwzQuEO1yp2nGcHtX88/wDwS2+EX7Wumf8ABa68vvE9r8UdOuPtWsHxRq2q2c8mnTRtbXHk72ZhA8bTCHygjFeFKcLX6ZwF4d0uJMvzPHVMdTw/1Kl7RRnvU+J2Wqt8NrpSd5RVtTjxWLdGcIqLfM7eh9df8F6P+C7XxM/4JuftM+FPh38OfD/hWb7RokHiLUr/AFqCW5+1LJcTxLbIiSJsUCAlnyWO8AbduW+ytb0D/h7B/wAEpoba6Y+EJvjX4Ft7lmQfaF0ue5t0lGBkb0WTHcEqOxPHW/tZf8E7Pgv+3LfaHdfFPwFpXiy78OM32C4meWCaJGILRl4nVmjJGdjErnJxya9f0HQrLwtodnpmm2lvYadp0CWtrbW8Yjit4kUKkaKOFVVAAA4AFdea8YcOxyHKaWQ4J0MxwsnOrW0am07xa1fNrZ2lFKNuVXTJhh63tajqyvCWyPzY/wCCD/8AwQ68Yf8ABL74h+N/GHjzxX4e1nV/ENimj2NlonmyQRW6yrK00kkqI29mRAEC4ABJYk4H1p+0H/wTF+C37Un7Qvhb4peNvCs+reM/BwjGm3iateWyIInMkW6KOVUbY5LDjno24cV79RXi8QeJnEecZ5U4ixGJlDE1I8jlTfs/d5eXlXLbRrddeppSwdGnSVFL3V31CiiivgjqCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPJf2zv8AklWg/wDY9+Ev/Uh06vWq8l/bO/5JVoP/AGPfhL/1IdOr1qgAooooAKKKKAPg3/gu19z9j7/s5jwb/wC3lfeVfBv/AAXa+5+x9/2cx4N/9vK+8qACiiigAooooAKKKKACiiq2l61Z63E72V3bXaRtsZoJVkCtgHBIPXBB/EU7Nq6As0V8sftSf8Fm/wBnj9j342xfDzxv8QtP0vxWktut/Z/Yr2f+zY5lLo8skMEkanaUO1mBCurHAIJ8U/4ODP8Agpz47/YO/ZM8DeIfhDe6St74+1UW8euNbLfRwWotzMrQhgYiZMrhmyNobAz8y/e8P+GXEWbZhgcuhh5Unjf4M6kZQhNJczkpNapR192+lrXujlq42jThKbd+Xe25+iVRrdI1wYgf3ijJGO3+TX51f8G73/BSf4n/APBRv9nDx9N8SLjTr3xB4O1SKztNXtrFbc3cc0LOokjTEZaNlPKhcqy5GRub8o/2Gvgx+17Y/wDBXnwZea1pPxctfFEfjaCbxRql7aXJtjaG5X7a80hIgeBoS/RtjKyhM5Wv0PJvAPE1sfnOV5tmFLDVstgpNN8yqXi5LlbcWo2SvKzacknE5KmaJRpzpxbU/wAD94f+Ch3/AAVZ+E//AATI07w5L8SZ9ea58VtONNtNK043UsywhTIxJKooBkjHLZJcYGASLFr/AMFI/B/xH/4Jw+J/2jfh9DeeIvD2jeHNU1u1s7uFrKaaaySXfbyBh8uJIipZdwxkqW4z88/8F0f+CLl//wAFQL7wZ4k8PeJbnRtf8IWlzYG0+yR3EN7FIfMX/WTwiNg64zk5DjIG2vdv+CWv/BPCy/4J/fsPWHwo1DUG8Vm7mur3WGvbVEhne6wJIfJDyL5YQBCNzBvmP8WK8OvlvAOH4NwGZ0q86uZ+1XtqN2o+zUpXXw+7eKhaSk3dvT+XVTxTxEoNWhbR+Z+eH/BJL/g48+L/AO2r/wAFBPDHwy8deGPBCeHfGy3EEDaNaz29xpc0NpLOHDSTOJEYxEMp5G4FTxtb5u/4OJP2w/jL8Ov+CrOsaVFqtrpGl+GbbTpPCyQWlrP+4aGOXzXZ0Zi5nMuQ/A2gAY5P7c/s5f8ABK39n79kn4s3Hjj4efDLQ/DXiie2NoL2F5pDbxsArCJZHZYiwGGKAEgnJ5OfZvEvww8NeM9Wtb/WPD2h6rfWBBtrm8sIp5bfByNjMpK8gHg9RX32H8ZeCcm4zWf8P5Ivqv1f2TpT5Yv2jld1F/EivdSg+sld6Nu/I8vxNTD+yq1Peve/l26ep8Jf8FT/ANmX41/8FCP+CL3hzQrKw0cfFS9stF1/xFpCXMMMF3NHCJLmCGVm8tCJWDD5wp8sjcQefH/+DYv/AIJx/GT9iW5+KWu/EvSbTw3pfihLSxsdPF9a3s1xNbSTb5i0DuEVd5UAtliScYAJ/WqivzSj4v5rR4SxnBtCjSjhsTUdR+6+aN5RlyxfNaycI2um0tL7W7Xl8HXjiG3zJWPw5/aP/wCDUXxx8ZP24PEfiqw+I3he0+HHjDxPc6zdtMs51iwt7ibz5I0iEflSSBnkRSZACFVjjJUfoD/wVL/4IzeB/wDgqXoHguHxB4k8Q+FtR8CR3EGn3mnrHMJIpljDJJG4wcNFGQQQeGHfj7ForTNPHLjPH4nAYypi+WrgYyjSlGMU1zRUZN6Wk5RSTurWW24oZZh4qUVHSW54R/wTm/YB8K/8E2P2abP4beE7/VNXtkvJtSvNQ1Bl869uZdoZ9q4VFCoihV6BRkkkk9z4B/Zg8DfDD4j6j4t0PQ/sPiDVoEtru7+2XEvmxqAFXY8hQYCjkKDxXfUV+eZhxFmeOxWIxuKrylUxDbqO9ue7u+ZKyav0tZdEdcaUIxUYrRbFfUtKg1i28m4TzI8g43Ecggjp7gVYoorx7u1uhoFFFFIAooooA8O+H/8Aykf+LH/ZOvB3/px8UV7jXh3w/wD+Uj/xY/7J14O/9OPiivcaACiiigAooooA8Z/Zk/5Ln+0R/wBj5Z/+oxoVezV4z+zJ/wAlz/aI/wCx8s//AFGNCr2agAooooAK+GP+C4f/AAV21L/glR8KvCN34d8LWHifxL4z1Ce2txqMzx2dnFBGjyOwTDOxMsYVQVHLEnjBo/HP/gvt8NPgZ/wUe0z4BX0NnLbtdQaZq/iI3lwqaRfzY2W7RC2ZXwWjDOJdqlzuK7Gr6I/bj/4J6/Cz/gol8O7Dw18UNCl1W00m6N7p9xa3T2t3YyldrFJEOcMvBU5U4UkZUEfqXD+QUeGs6y3MOOsDN4GvH2ij1qU2nytWktpOMnFtPlt0kr8VWq61OcMLJcy09Gcz/wAEwP23Iv8Agpx+w3o3xD1DQY9Cudaa70rVdOinaSFJYnaKTy34bY64Yd13YycZPyn/AME5P+DarQf2Bv23IPi0/wAS7/xVZeHDcnw5pX9li0khM8MkJNzL5jiTZHKwARU3NhjgDYf0C/Zm/Zm8Gfsf/BXRvh98P9IXRPC+hK4tbbzXlbc7l3d3clmZnZiST39K72uer4h4vKsTm2E4SnLD4DHOUXTai37K8uWLb5nFqMnFuMr2bTk9xrCRmqcq+so9fMKKKK/NTsCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACvn7/grH/yi0/aS/7Jb4m/9NVzX0DXz9/wVj/5RaftJf8AZLfE3/pquaAPfbX/AI9o/wDdH8qkqO1/49o/90fyqSgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8G/wCCcf8Ayb3r3/ZS/H3/AKmGs17zXg3/AATj/wCTe9e/7KX4+/8AUw1mgD3mvgH/AIOMv26PiT+wf+xFouu/C7UJtC1/xF4ng0efV1sIroWNsba4lcDzQyJI7RoFYqeN+MHBr6g/aF8f/GTSvFVjoXwt+H/hnWUvrNpp/EviTxAbLTNJl3ECNraGOS5uGwA2E2Kc4Mi9a+ePFf8AwSc8bftceI4b79oj4w3niDRrd45E8HeELaew8O3Txn5HuoL6e7WfoDjYmG5ya/UfDrD5Plma4XO+I6lKWHpvndF/vJVEr+64RUlHXW1Xlv2szixbqTpypUU7vrtb+vI8a/4JA/8ABePRvid+xZFd/HTxmmrfE7TtYuNNhsNH0aS71nWbdUiaGUWVmjuxJd0Mixonyc4PLe7/ABd/a4/ao+KOl21/8B/gQdO064AZLj4nQwabJMvci2j1FbmLPYTRI3qK+p/gz8DfCP7PfgWz8N+C/DmieGtGslwltpmnw2cbMcbnKRIq7mwCTjk11lPPuMuHJ51XzTJ8qioznKShVlzU4p7KNOmqXL6OU0tkFLD1lTUKk9u2/wB7ufnjp3hX/gpl45M1zd+JP2avBqiMtBaQxXcrNJ/CrkwXA2eu18+hplj4n/4KaeBb2I3/AId/Zt8ZWqMFmFjJdRSyL3ZPMmtxn0zjp0r9EaKy/wCIl3upZVgnHt7C1vmpKX3yY/qf9+X3nwT4++OX/BQTXrmFfBvwc+EujQbAJ38SXiM+/GCU+zalINuckZGcVzx03/gqA4/tP7f+y2qx8/2Rtv8AfL7btmP/ACKK/Reioo+I8KUFCnlOD+dGUm/nOpL8LMHhL7zl9/8AwD4y+B/7Uv7V3w8sLub45/Aca3BGCY5/hk1ldFB23w3WpiZ/pHGx9q9C0/8Ab61/XgP7N/Zu/aJuS/3PP0rR7AH6/atSi2/jivouivFxnEuX4qo69TLaUZPpB1YQ/wDAfaP8GvQ0jRnFWU3+H+R806b+2B8XtH1K5uNf/Zq+KbaOQBbLpdz4cnvEbP8Ay0Qa02R/uA++BVHUP+CrfhnwtdGLxN8J/wBozwuy9Xu/hrqF1Dn0E1os8bfgxr6korOOd5RVlfFZfFL/AKdVJw/9LdVfgP2dRfDP70v+AfKn/D5H4Np/rbL4uQevmfDDxCMf+SdT2H/BZn9nqeby73xX4j0KT01nwVrenjHrumtFX9eOpr6koq3j+GGv9yrr0xMP1wzDlrfzL7v+CeK+Df8AgpB+z98QJEi0n42fCy6uXOBanxPZxXIPoYXkEgP1WvWPDPjPR/GlobjR9V03VoFODJZXSToD6ZUkVmfEv4MeEPjPoz6d4v8ACvhvxVYSLta21jTIL6Ij/dlVh+lfL3xO/wCCGPwK8b6gt94d0/UvhXqsa7YtR8Bwafod5D7rKlqWB78GtMJh+F8U7Vq1bDPzjGsvm4+yf/krFJ147JP8P8z7GrO1rxdpXhof8THU9PsM9PtNykX/AKERXxHB/wAEFvCmpHPiT4+ftPeM93+tj13xpDfQyjsCslqcgdgT3NdT4M/4IT/s4+EMmTwPpOuStkvLq2jaXcyOfUn7KMmuypknCVJXeZ1JvtHDv85VY/kSqld/YS+f/APoPXP2s/hX4YfbqXxL+H+ntnGLnxFZxHP/AAKQV22h69Y+JtLhvtNvLTULK5UPDcW0yyxSr6qykgj3Brx/wZ/wTf8AgD4Ctymm/Bb4UQuylHmHhDTllkU8EMywjIrwzx3/AMEQfCOheKrnxR8FvHHiv4G+KJJjME8NJDZ6NcrxiC5tbRbeSWEEEhPPXBYnmscPl3CuJm6X1yrRfSU6SlF+qhJyj6pT9BuVda8qfz/zPt6ivky7+GH7Y2taDBosnj34BaXb2ieSdWt9C1ue9vhjaJCn26MRMFPI8yXLAHI6DhD/AMEYPEnxQumu/ij+0/8AHLXpiS62HhzWJdH0pCf+ne4kvCSOgO4fSqw/C+TxTePzWnDsoQqVG/ujGK9HJP56A61T7MH+CPu6ivhdf+CAnwrm/wCPzx98ZtTHpe65ZzD9bSh/+Df74QR/8efi74raWezWOq2UBX6YtK2/sHhLb+1p/wDhM/8A5b+gva1/5Px/4B90UV8JSf8ABBbwzB/yDv2if2sdE9Bpvj2K2A/75tKb/wAOTde0v/kGftf/ALWigfdGo+N5LsD/AL5EdV/q5wrL4c4t64eovyche1r/APPv8Ufd9FfCH/Dnb4iJ9z9sD4/f8D1i5b/25Fe9fsVfsieJv2VIPESeI/i942+K39ttbm3bxDPLKdM8rzNwj8yaTG/eM4x9wde3nZrkWR4fCyrYPM41qitaCpVYt6pPWUeVWWur6W3LhUqOVpQsvVG3+2d/ySrQf+x78Jf+pDp1etV5L+2d/wAkq0H/ALHvwl/6kOnV61Xxp0BRRRQAUUUUAfBv/Bdr7n7H3/ZzHg3/ANvK+8q+Df8Agu19z9j7/s5jwb/7eV95UAFFFFABRXL/ABf+Nvg/9n7wVN4j8c+KNB8IaDA6xSahrF9HZ26u3CrvkIBY9h1NeW/tF/Hbwf8AGj9gf4h+IfBXxP8ABNvpOs+GtSstN8Vrr0UemWdy8EkaM10j4jKyMuSDuU9s8V6+X5LisVKlJQkqc5qHPytxUm9rpatLWy1IlUjG/danqfhL41+DfH3iG70jQvFvhnWtWsMm6srDVILm4tsHad8aMWXB4OR1r8o/+DgP/guD8Xf2Av2rPD3w7+Fk2i6dANAh1jU59R0YXL3Ek00yKiO7bSgWIZ2qDuJG49B+fH/BEj4A/HD4Jft1+BPitpPwd+KniXwroZvDPcaLpJFtqsMttPbhYrmaSG2kQyMPm83aApYBiAp/W39r39jn4j/8FRr/AEfVfE/7OPgbwVd6ArQ2d94u8Y2k2oTQMSRG0drp158gYlthnTkt3bI/qmHhtwx4fcb0Vm9WlmOB9k3LnnRhy1HzKzpyqNztZPRacy7a+H9crYvDP2acJX89vWxrfFn4s/E//gp7/wAG/N34p+Htvd2/xK8deGImmtNNzYvdSw3Spfw2+XY7ZUhnVF35dXC9WxXxF/way/sgfHX4JftjeM/EHinwX438DeBj4Yksb9de02402LUbxp4Ht1jjmRTI6KsrblHyBiCR5gDfoKv7DP7S/ijwRpPhk/GD4ZfCvw7otpFY2Vh4B8M6rB9lgjUKqI39pQoMAdViUf7PaqEP/BDGx8cSb/iX+0F8f/iLF0Ol3/iFX0dl/wBq1uEnBJ7nfz6V5OXceZFlfDmb8MUsVRhh8dUlNKNKrVnTjJq0U7U4S5YxXK7rld3rcueFqzrU6zTvFd0k/wA2fGf/AAWA/wCCGcH7Sn7f2pfEvQ/ij8KvCnhvxTNZTeJLbxF4tFlfW8qr5Vw8KG3dVBjjjKhnPzl+AuAPvH4ifHn9iqD9nXQfhR4x8f8Awf8AG/hLwzp9rp9po9zqtrr9yi20QiifyoTJIJAo++qg8nHWu5+F/wDwSP8A2dPhXDb/AGb4Q/DrU5rX7lxqPhXTJpgeOdwt1OeOvua998K+DNH8C6Wtjomk6bo9kn3bextUt4l+ioAP0r4bifxRp5jgsvy2viK9angVy0nHkw7Vkkne1ZuSUUk9GkdVHBOEpzSSct+v+R8cfBb/AIKK/sj/ALM3g/8A4Rb4WWGq6dpCymf7D4S+GutyQzSEAGQtFZbZHIAG4sSQBzXaWn/BWHwvr9wsWhfCf9pDxBK/3Ba/DDU7dCPUyXKRRqPdmFfU1FfCYnO8hrVJV6mErVKktXKpiVJt93ahBv77+Z0qnVSspJLyX/BPkf4pftWftK+KY4Zvhd+zzrOn2zrkt43uNIhd+OCEt9XLrzjh1BxnivPLn47/APBQ1/8AUfBj4Nr/ANdb3/DU6++6K3wnG2Fw0FThlWFkl1lGrJ/N+21E8NJu/PL8P8j87774pf8ABTDX5vLs/hv+zrokeMebd3Nwxz/wC9k4/CoR4Q/4Kha5+8Hin9lXRs/8snh1FiPyt5P51+i1FegvEtRVqWU4Jf8AcBy/9LnIn6n3nL7z87IvhZ/wU+Y/vPiT+yuv+5a6j/WxrrfAnwJ/bz1Vl/4TH40fC/TAT83/AAjNjExA9vtWlv8ArX3NRWNfxJr1I8qy/Bx81hqd/wAUxrBpfbl97Pl3U/2Vfj/B4eM+n/tJ+NZddxxDeab4b/s8nuDs0QSY6dDnrXjHiHwB/wAFK/Cuqyf2L43/AGcPEum5/dHU4LqO74/v+Vawx8+1foTRXJgOP8Rh2/aYLC1U/wCfD09PTlUX+JUsKntKS+bPzpGjf8FQL/8A5iv7LFln+8moHH5RtR/wjP8AwVB0v94fEX7K2pf9MVi1FT+sKfzr9FqK9L/iJ0v+hVgrf9g6/wDkrmf1L+/L7z86f+E9/wCCnWkfIfBP7NOqf9NEnu1z+d0n8qB8Qf8Agp1df8yN+zTbfW4uzj/ybNfotRR/xEunv/Y+C/8ABMv/AJZYPqb/AOfkvv8A+AfnT/wsL/gpzp/J8C/s033fC3F2P53a1paL8cv+CjVu4/tT4OfA2dR1+wXrZP08zUxX6CUVM/EejNWlk+C+VKa/Kqh/VGv+Xkvv/wCAfF+iftIftk26D+1vgHokzdzp9/p2P/Imrivrj4e6rquu+AtFvdd01tH1q7sYZr+wZkY2U7IDJETG8iHaxK5V3XjhmHJ2KK+UzrPaWYRiqeDpULPempq/k+ac1b0SN6dNw3k36/8ADHh3w/8A+Uj/AMWP+ydeDv8A04+KK9xrw74f/wDKR/4sf9k68Hf+nHxRXuNfPGoUUUUAFFFFAHjP7Mn/ACXP9oj/ALHyz/8AUY0KvZq8Z/Zk/wCS5/tEf9j5Z/8AqMaFXQftI/G7X/gl4Zsbjw18NPGHxO1XUrg20VhoUlnCLY7S3mXEtzNEscfGNw3nJHy966sFg6uLrxw9G3NLa8oxXzlJqK9W0hSkoq7O28VeK9L8C+G73WNb1Kw0fSNNha4vL6+uEt7a1iUZZ5JHIVVA6kkAVzfwO/aN8A/tM+FJNc+HvjLw3400mGY28t1o2oRXkcMg6o5Qna2OcNg4IPQiviH/AIKP/s3ftXf8FKP2PvEvgyPwv8Mfhlp2sWiSNolx4nudU1e/khuIbqONpYoY7SEs9uqctKuHJ3rXgP8AwQ4/4JZftd/8E89A8aa/HD8LdAuvGM1tbXXhrxTdXNy80dr5pjnSexkeOEkzyL8ySnA6L/F+vYDw3yGfCuJzPGZvRp5hCajChzwlGUXbVyi3du8neN4x5UpP3tPPljKqrqEabcLbn0d8ev8Ag3s+D3xx/b8T456rdeIYBc30euaxpUepxx2d3ewlCrbDblxG2zMgEy5OcYya7T40fty+Lf2rPGKfDf8AZZvDd6xp+sRxeK/HFzpe7QdD01GKzmzu5leC5u2cNHGscVwm6KXcoC7qt/HL4DftFftr+H7X4c+O18A/DLwFcTLN4m1rwd4mvtR1LX7ZSM2EEUtrbLBHKNyymYzoUO0I+Tj6s8B+BdJ+GPgrS/Dug6fZ6Voui2sdnZWdpAkENvEihVVEQBVAA6KAPaufNeKq0MNhJ55iFjq+Hi4Uabkp0aUFZJztzKo5dKakrcsfaX+AqFBXl7Jcqe72b/y9fuPlPxD+zj+1zZyH+xPj7ZXSdjqunaUG/wDIOjqK8/1jS/8Ago98JfEMdzYal8BPidoeV820uElt9QAz820qlnF06Zbr14r9A6K+fwviFVpaVcBhKi7Sw8F+MOVr5NGrwqe0pL5s+Xn/AOChnib4b6ZaxfED9nr496fqcyhd+g+GrbxBazPgBtp068umjBYNjzdnGM1pQft2+LvFumufDf7Nvx8uZnXEMmpWGi6XEG7b0u9UhkA/4D+tfR9FeVLPMqa9osvhz9ffqcnyjzKS+c38i/Zz25/yPlvwt+1R+0FZzlvEP7OHi+5g3EgaRqHh7zNv/bXWgM1uXv7dvibRE/4mP7Nf7QtuwHzeRZaFejPt9n1STNfRFFKpxBgKsuapl1JL+7KtH86sl+A/ZSW03+H+R8v3n/BUG10sE3fwF/afgA6+X8Obi6x/34eQn8Krf8PZfDg+98Gf2pF+vwi1n/4zX1TRWizXIGvfy+V/Ks1+cH+YuSr0l+H/AAT5W/4ez+GT934O/tQOfQfCLWs/+iabL/wVq8M2ULT3fwc/agsbOIbp7q4+EusJFbIPvO58rO0Dk4B4FfVdFV/avDv/AEL5/wDg/wD+5C5K3834f8E4X4E/tM+AP2mvCUet+AvFui+J7B8B/sdwDNasQT5c0JxJDIMHMciq4wcgYrr9c16x8L6RcahqV5a6fYWiGWe5uZlihhQdWZ2ICj3Jr5t/bD/4JT/Dv9rXxivjGK41P4ffEa1i/wBE8W+Foray1aOZSpjle48rz2KhdnEinYzKCM5Hn+g/8EmvE3xl8baPqf7QnxWuPidovhYRx6Z4WtLGWLQtQaPhbrULa+nu1uJyO6hNpLfMc8d9PJuFq9NYpZhKlHVypSpudRdowlG0J3/ml7K27iS6ldPl5L+d9P8ANfiej+Pf+CsPwj8J+MbvRdEfxn8SJdK/5C134D8L33iWx0b2uLm0jeJWzwUVmZT95RVrwL/wVr/Z28d3yWn/AAtDRPDl6/AtvFMNx4cl3ZwUAv44cv8A7IycYPQg17p4B8AaJ8LPBuneHvDmladoeiaTCLe0sbC1jtre3QdkjjCoo74AHWrfiHw3p3i7Rp9O1awstT0+6XZPa3cCzQzL6MjAqR9RXnTxfDNvZxwtbT7XtoXfm4+wa9IqSts5Pcvlrb8y+7/gngfxH/4Kxfs+fDXUvsL/ABJ0rxJqPQ2fhO2uPEs8bdlkXT45/LJPA8zbkketV/Dn/BRK+8f2puvDH7Pf7RWu6eTiO7l0DT9EWb3WPU761mK/7WzHvXvngzwNonw48PQaR4e0fS9B0q1GIbLTrSO1t4R/sxoAo/AVq1EsxyClC2Hwc5y71Kt4v/tynCm0/wDuJIOWq95fcv8AO/5HzpqX7XHxZuV/4l37Mnxbj97zUPCo/wDQdczU9t+2T8QtPt/+Jl+zF8cfN6lrS68LSp+mtk19CUVl/b2Ca5Xl9G3rXv8Af7Yfspfzv8P8j51f9vbxBCcP+zZ+0SpHXGm6K/6rqZFMb/goFrMf3v2cf2jR9NE0tv5aga+jaKf9sZX1y+P/AIMq/wDyQezn/N+CPm5v+CiGoR/e/Z2/aRH08NWTfyvTU9j+3zr2rj/Qv2bf2ip/+uul6PZ/+lGpR19FUU3nGU293L4386lS34ST/EPZz/m/BHknwU+Ovjv4o/ECe01z4PeNvh94eSyeeK/1+60aQyzB4wsW2y1K5cEqztzGF+Q5YHAPM/8ABWP/AJRaftJf9kt8Tf8Apqua+ga+fv8AgrH/AMotP2kv+yW+Jv8A01XNeJj8VTxFX2lKlGkrW5Y81vX3pSd36mkU0rN3PfbX/j2j/wB0fyqSo7X/AI9o/wDdH8qkriKCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArwb/gnH/wAm969/2Uvx9/6mGs17zXg3/BOP/k3vXv8Aspfj7/1MNZoA95ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPJf2zv8AklWg/wDY9+Ev/Uh06vWq8l/bO/5JVoP/AGPfhL/1IdOr1qgAooooAKKKKAPg3/gu19z9j7/s5jwb/wC3lfeVfBv/AAXa+5+x9/2cx4N/9vK+8qACiiuC/aV/aN8NfsrfCLUfGHiiedbS0KwWlnaxeffaveSHbBZWsIIM1xM+ESMcknqACR0YTCVsVXhhsNFynNpJLVtvRJClJRV3sfmd/wAHYmleMPiP8GPhL4K8Evr2t6hq+s3t3eeFtFhkurrU4YYFZbl4Isu8ULZ5KlQZASQQKzf+CCX/AASk8ReLP2NN3x9vPiOvhS61aebSfhrqV5e6XpaxfLumvLQrG0wkkUssbM0JHzFWLmvuz/gnx+zh4m8L6XqnxX+LVvDP8bfiMPN1WXzN40HTd5ez0iBcbYY4EYb0UvumLs0svDV9KV+75l4t4rJuFI8A5Ry2ozcpYiL96U+aTl7NpaJN8saifPKKv7qlyrzIYCNSv9aqdVt/n/kYvgD4ceH/AIU+F7TRPDGh6T4e0ewjEVtY6baJa28CAkgKiAKBkk9OpPrW1RRX4HVqzqzdSo25PVt6tvzZ6iVlZBRRRUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHh3w/wD+Uj/xY/7J14O/9OPiivca8O+H/wDykf8Aix/2Trwd/wCnHxRXuNABRRRQAUUUUAeM/syf8lz/AGiP+x8s/wD1GNCr2avGf2ZP+S5/tEf9j5Z/+oxoVezUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXz9/wVj/5RaftJf8AZLfE3/pqua+ga+fv+Csf/KLT9pL/ALJb4m/9NVzQB77a/wDHtH/uj+VSVHa/8e0f+6P5VJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB8eftq6N4Sj/ahm1D4n+FbjxN4Vm8DwW3h/zPDs+t21vfLqbNeqkccUnlzvE1k33Qzxwvg7Y3ryv9rfw/4i+IX7JvwG8O332yz8T+GdONj4l1bW/D02r2FhqMfh5TJBNC8MqTTTSTKsc4jYKyyhZBJ+7f9F6KAPJ/hLfeK9P/AGLvBM/hvwpHB4tTwrpZg8PeKtZnsTaS/Z4d9vd3YhupVkjG4M3lSFnTnqWHHf8ABLe41S6/ZSvJdbtbGx1qT4g+OWv7ayu2u7a3uD4t1cyJFM0cTSor7grtFGWABKLnaPomvBv+Ccf/ACb3r3/ZS/H3/qYazQB7zRX5v+OP+DkP4feDP+CkyfAD/hCdfubGPxFH4UuvEwuVVYdQeUQnbbbSzQrKwQvvBwGYKQBn9IK+o4k4Lzvh+GHnnGHdJYiCqU7296D66N2e107SV1damNHEU6t1Td7aMKKKK+XNgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/8AUh06vWq8l/bO/wCSVaD/ANj34S/9SHTq9aoAK5r4z2Wq6n8HvFdtoJkXXLjRryLTjG21xctA4i2nsd5XBrpaKAPiL9iZdG8B/Fjw5Ovh7VtG8QWmja9pnj67fw/dQzX2s3ev2Edk1xN5X+k73F9JFJuZUhkaTKRSAnzD9ij4ba1oX7ZHhDWbi3Xbe+K/FTXOiDw09prHhmOQ6m8VxqGoGBZLmN/kQLLK6F7qBkMgRHH6WUUAfnB/wXO1bxy/xc/ZLtJ9A8Lx+BE/aM8FvaatHr876rNc5ud0b2JsxEkYBkxILtydq/uxuJX9H6+Df+C7X3P2Pv8As5jwb/7eV95UAVNf1+y8K6Fe6pqV1BY6dp0D3V1czuEit4kUs7sx4CqoJJPQCvz6/ZP1jwh+1z+3afjr458deHQL/dafCzwHrOqRpqNnZBI1tdVFkZFCTz7r6SPdE0oivEPmdFX13/goFqtx+1J8TND/AGWdHf7NH450w+IPHWokANp3hqKcRvFBuGGuLqYeQGXJiXe5Gdlfix+1j/wSC/aY17/grJ4ibw/o2lPe6z4xfWPD+ttqdklrDa/aDJazvEzmQCKNF3IY2YmM8PnLf0t4O8DZZjcFi4ZlmUMDXr0JSjKXLdUb2fxNW9o072fOqcdE41bnj5hiZxlFwhzJP8f+B+fof0tUVHaJJHaxrM4klCAO4XaGbHJA7c1JX80s9gKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8O+H//ACkf+LH/AGTrwd/6cfFFe414d8P/APlI/wDFj/snXg7/ANOPiivcaACvn39uOw8PS+KPhdd+ONEOv+AbLWb1tXt5dHk1a0jkbTblbd57dI5MruLKpZSBJJGB8xWvoKigD4G+MV7feL/+CYHg7wA9pr6eM/DMfgiLXf7U0K9uo9E33FnKZ7pGhdLtIkRjNHiVVK4m2Dcy/QH7AGlav4X/AGKtJtFtLaXWLS51pbYSwPpVrqLDU7wxTpH5Wba3nGyVFSLbHHKoRCoUV7zRQB86/sGaj4t1Xx78f5vHGj+H9B8RN4/thPZ6LrMur2cajw1oewrcS2tq7ErgkGFcEkZbGT9FV4z+zJ/yXP8AaI/7Hyz/APUY0KvZqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAr5+/4Kx/8otP2kv+yW+Jv/TVc19A18/f8FY/+UWn7SX/AGS3xN/6armgD321/wCPaP8A3R/KpKjtf+PaP/dH8qkoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACvBv8AgnH/AMm969/2Uvx9/wCphrNe814N/wAE4/8Ak3vXv+yl+Pv/AFMNZoA8C8Yf8G73wR8Zft9L8e57/wAVxai2tp4luPD6XEJ0y41FZVl807ozJ5bSDe0e7BJOCF+Wvvaiivo8/wCLs5zuNCGbYiVZUIKFPmd+WK6L/N6uyu9DKlQp0r+zVr7hRRRXzhqFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeS/tnf8kq0H/se/CX/qQ6dXrVeS/tnf8AJKtB/wCx78Jf+pDp1etUAFFFFABRRRQB8G/8F2vufsff9nMeDf8A28r7l8RpfSeH75dMkgh1JreQWkk0Rljjm2nYWQMu5Q2MjcuRxkda+Gv+C7X3P2Pv+zmPBv8A7eV95VUZcslID57/AGAf2UNc+AnhjW/E/wARNbm8X/F3xxOjeIteuLeK3eWC3Bhs7aOOJ3jjijiG7arcySyMeWwPoSiivQzjNsRmeMnjcU1zS7JKKSVlGMVpGMUlGMVoopJaIinBQjyxCiiivNLCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPDvh//wApH/ix/wBk68Hf+nHxRXuNeHfD/wD5SP8AxY/7J14O/wDTj4or3GgAooooAKKKKAPGf2ZP+S5/tEf9j5Z/+oxoVezV4z+zJ/yXP9oj/sfLP/1GNCr2agAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK+fv+Csf/KLT9pL/ALJb4m/9NVzX0DXz9/wVj/5RaftJf9kt8Tf+mq5oA99tf+PaP/dH8qkqO1/49o/90fyqSgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8G/4Jx/8m969/2Uvx9/6mGs17zXg3/BOP8A5N717/spfj7/ANTDWaAPeaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/wDUh06vWq8l/bO/5JVoP/Y9+Ev/AFIdOr1qgAooooAKKKKAPg3/AILtfc/Y+/7OY8G/+3lfeVfBv/Bdr7n7H3/ZzHg3/wBvK+8qACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8O+H/wDykf8Aix/2Trwd/wCnHxRXuNeHfD//AJSP/Fj/ALJ14O/9OPiivcaACiiigAooooA8Z/Zk/wCS5/tEf9j5Z/8AqMaFXjf7aX/Bdz4AfsJ/GfSvAvjDV9bvdZvgXvW0fT/tcOjIJnhLXDbgch45MpGHcBCdvK59k/Zk/wCS5/tEf9j5Z/8AqMaFXw3/AMFLf+Daqx/bw/actviDo/xNn8JRagZBrVndaWb9mL3M9wz27+agU5mKhGGBgHPY/pfhZgeDcVm7p8bV50cNyuzgn8VtL8sZv00330OPGyxEad8Mrs/T/QNds/FGhWWp6fcR3dhqMCXVtPGcpPE6hkdT6FSCPrVusf4eeCrX4a+AND8O2LTPZaBp9vptu0rbpGjhjWNSx7nCjJrYr85rqmqklSd43dr726XOtXtqFFFFZDCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK+fv+Csf/KLT9pL/slvib/01XNfQNfP3/BWP/lFp+0l/wBkt8Tf+mq5oA99tf8Aj2j/AN0fyqSo7X/j2j/3R/KpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArwb/AIJx/wDJvevf9lL8ff8AqYazXvNeDf8ABOP/AJN717/spfj7/wBTDWaAPeaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/8AUh06vWq8l/bO/wCSVaD/ANj34S/9SHTq9aoAKKKKACiiigD4N/4Ltfc/Y+/7OY8G/wDt5X3lXwb/AMF2vufsff8AZzHg3/28r7yoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDw74f/wDKR/4sf9k68Hf+nHxRXuNeHfD/AP5SP/Fj/snXg7/04+KK9xoAKKKKACiiigDxn9mT/kuf7RH/AGPln/6jGhV7NXjP7Mn/ACXP9oj/ALHyz/8AUY0KvZqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAr5+/4Kx/8AKLT9pL/slvib/wBNVzX0DXz9/wAFY/8AlFp+0l/2S3xN/wCmq5oA99tf+PaP/dH8qkqO1/49o/8AdH8qkoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDmfjB8YfDnwE+Ht74q8Waj/AGVoOnPBHcXX2eWfy2mmSCMbIlZzmSRF4U43ZOACa3dG1e38QaRbX1pJ5treRLNC+0rvRhkHBAI4PcVwP7WPiG58PfBC8Wz1a80G61nUtL0GLUbWzt7uaya/1G2sRIsVwrQsR9oz+8R1HUo+Np8y/ZE/Y/8Ah/8As++Jb/R/AU3jHRz4I1yRdUibXp/7N16e506KeWR9PRlsYizXsch8i3ixJCCoVSQQD6Uor4T/AOCmGqfDrRP2jbCX4z6L/b/hKXweD4UiuSot7bVU1AC98nzHRTdyWskBGwmQQQXP3ULbuA/bR1a8+Jn7NfwL0jx94rn0vwv4fjOj/Eaa+02xv4rrXU0G3u7RbqK/R7Yq85dNlym9pZ4tirJ5ciAH6V14N/wTj/5N717/ALKX4+/9TDWa6/4Ial4x8XfsmeB72ey0Xwf441HwzplxeWU+nTy2OkXb20TTwfZzJFLsRi6BWdWXAzyCK4b/AIJkR3kP7MWppqM1tcagvxF8di6ltoWhhll/4S7WN7IjM5RS2SFLsQMAsetAH0HRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeS/tnf8kq0H/se/CX/qQ6dXrVeS/tnf8kq0H/se/CX/AKkOnV61QB55p/7VngHVPj1qHwxg17f440oK11pv2G5HlBoYpx+9MflH93NG3Dn72OoIHodfG37R/wAHvDn7YnxG+KKePdZ17U/BHwevYjL4TgtLCzgurm30mz1NJ1vxE2oRsPt4w8NxAVZAAMBmk9803wdfeGP2YtXsvC+reILq9u9JvLrRZ9UvptQvbR5onkgjM0heWTy2ZQpZnbCgZOBQB6bRX5//ALCnj/wn4O+P7XFvYXmn+MFttV0n4n3MpH2nUdcuPEVlaaXJebn3bmU3b24mCv8AZplESlPlXz/9gHSotG/ba0HU9V1u18VfGjVvEniXTPHNjf6Jpv8AaXhzT4v7RNveJcLF/acUUpt9PSP7TJ5DQ3UaoiD7OqAHp3/Bdr7n7H3/AGcx4N/9vK+gf+Ch37ePhf8A4Jxfsy6l8TPFdhqurWVpcwWNtYacqme8uJmwiBmIVBgMxZjwFOATgH5i/wCC6Vn4kXxv+yNNLqWiN4ab9pHwYsFkumyrfJN/pWWa488oyY3/ACiEHlfmODn6Z/4KLfsDeFv+Ckn7MuofDTxXf6npFrPdwahZ6jYbTPY3MJOxwrgqwKs6sp6q5wQcEfQcKf2T/bOF/t7m+qc8fa8t+bkv71ra7dte2plX9p7OXsvitoeV/wDBJ/8A4LOeDP8Agq6viy10Hwvr/hLWfB6wTXdpqEkc8c0MxdUeOVMZIKEFSoxkYzzj7Jr4w/4JN/8ABFjwX/wSjn8WahovifWvGGv+Lo4ba4vb+3jtkt7eJmZY440zjLNliWOdq4Awc/Z9ez4kf6s/6w1/9T+b6j7vJzc1/hXN8XvW5r25tTPB+29kvrHxBRRRXwx0hRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHh3w/wD+Uj/xY/7J14O/9OPiivXPHPjXTPht4J1jxFrVz9i0bQLGbUr+48t5PIt4Y2kkfagLNhFY4UEnHAJryP4f/wDKR/4sf9k68Hf+nHxRXc/tM/FIfA39m74g+NSZAPB/hrUdbJjgWdx9mtZJuI2ZFc/JwpdQehYZzQBs/DD4oaH8ZfA9h4k8N339paLqcfm21x5MkPmr67ZFVh+IFb9fJ/7O/wCyB4O+C/x+Fxp+s+MZ/iH4ps08Ya7r6ajHZW+vBZfKaG506zSCxYYl2rJ9nMuACZCyBjof8FMbzwTp+n/DeX4p6db6t8LP7euV161vtn9nGX+zrprR7rzGWLaJ1VYxIf8AXvAV+cKQAfUFFfnf8dPjHqnjj/gmnongubWPE2leIPCcHgaL4kTzRrPf2WlXz2hvXuFlYnCW7SPcfa1ERSOXzRJHvVvpv/gntDHF+xb4dtNCXSbbT7KTVLHQri20q3s7O7sodQuorK8FvaiODbNAkMx+zhIn80tGFVlAAL/7Mn/Jc/2iP+x8s/8A1GNCr2avA/2LrXXLP4pftBR+I77SdR1UePrXzZ9NsZLK3Yf8IzoW3bFJNMwIGM5c5PPHSvfKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAr5+/4Kx/8otP2kv8Aslvib/01XNfQNfP3/BWP/lFp+0l/2S3xN/6armgD321/49o/90fyqSo7X/j2j/3R/KpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8i/btGpXX7K/iaw0bQvDviTV9bey0axsNftZLjS5J7u9gtY5LlIyH8mNphIzJ8yCMsASuD4R/wAEMvGPiPxZ+ynq/wDwktp8L7S+tfEDLs8DRzi1Qyafp87x3TzFpGvY5ZpYpd7EqYlQn5K91/bu1/UfCP7Mmr6xpN5PZaho2o6RqMLxabqOomTydUtJTE1vp0M13IkgQxuIom+R2LYQMwrfsRftQS/tTfDzWNVuFsorvR9Yk0ueG30jWNL8l1gt5sPFqlpaz7sTg5EZQhlwxIYAA9oooooAK8G/4Jx/8m969/2Uvx9/6mGs17zXg3/BOP8A5N717/spfj7/ANTDWaAPeaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/wDUh06vWq8l/bO/5JVoP/Y9+Ev/AFIdOr1qgD8of+CwmvfEC1/aA1bxN4a8C/s7R+G/DmpW3hu+174hafeJc3dwNHbU08ySNxDNZO0lvap5oO65IiK8K1fqd4TvJdQ8LabPMixzT2kUkiKhQKxQEgKeRz2PSvh/4/8A7aXiD9j79qP4pA3sV74avbu11d11Pwb4xv4tJP8AZWnxMI7ux0yey8j/AEcyERyNtklk3MrbkH3Po99/amkWtzwftEKS5UMB8wB4DAEde4B9RQBZooooA+Df+C7X3P2Pv+zmPBv/ALeV95V8G/8ABdr7n7H3/ZzHg3/28r7yoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDw74f/8AKR/4sf8AZOvB3/px8UV6J8fPHEfwy+BfjTxJLpdxrkXh/Qb7Un023tvtUuoLDbySGBIsjzGfbtCZG4sBkZrzv4f/APKR/wCLH/ZOvB3/AKcfFFdj+1losniT9lj4l6dDqGo6TLf+FNUt0vtPjuJLuyZ7SVRLCtvHJO0iE7lEUbyFgNqM2AQD4b/4IgeJvHdt8c/it4b8Z+GvgZ4auNNWRJLLwNaXUeo2Jt9SureFLw3DO8drLAqXFomQjRTF0VQWA/SSvmP9gv8AbX1D9pLxNrHhrWf7MTWPD2l215PHB4a8R6LK4dmjEpXVrG2BRmjbGxnPynPTNfTlABRRRQB4z+zJ/wAlz/aI/wCx8s//AFGNCr2avGf2ZP8Akuf7RH/Y+Wf/AKjGhV7NQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfP3/AAVj/wCUWn7SX/ZLfE3/AKarmvoGvn7/AIKx/wDKLT9pL/slvib/ANNVzQB77a/8e0f+6P5VJUdr/wAe0f8Auj+VSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB5z+1Z4il8N/Bidre/l0u51LV9I0eC7jsIb428l5qdraIxhm/dsu6cZzyBkjkCsT9lLwXB8PNU+IGktqt9resw+Ilk1W9lsbWxhnnfTNPYeTDboqoghMIO7cxcSEtggC1+21qdro/7OGrXGo6Pba5oyahpX9r289rLcpDp51K1F5chIv3gaC3Ms6uvKNCrD7tc9+wt408FeNdH8cT/DpbG68Hw+JGis9Vga4mk1lxYWLSzyXE7NJcOJWki8wkjbAig/JQB7xRRRQAV4N/wTj/5N717/ALKX4+/9TDWa95rwb/gnH/yb3r3/AGUvx9/6mGs0Ae80UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHkv7Z3/ACSrQf8Ase/CX/qQ6dXrVeS/tnf8kq0H/se/CX/qQ6dXrVAHyT8btHuvjx4p+N9qfF17pnhvwPu0zV9MTwzpdxLcL/YtjfSCC4njkb5orxQGkU7X3DaVUZ+o/Bc0Fx4O0mS1877M9lC0PnNuk2FBt3Hu2MZ96+JP2qPiN8KfDXxn+MSfFbQNJ07xDFAkPhUPZagq+NLI6VZPHFOID5V9uvjdweQwJZLRAUIjDV9veE7iW78LabLcRRwTyWkTyRRjCRsUBKj2B4FAGhRRRQB8G/8ABdr7n7H3/ZzHg3/28r7yr4N/4Ltfc/Y+/wCzmPBv/t5X3lQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHh3w//AOUj/wAWP+ydeDv/AE4+KK7b9qT4kQ/Bv9mX4i+L7l7mO28K+GNT1iV7e3juJlS3tJZmKRyERu2EOFc7ScA8E1xPw/8A+Uj/AMWP+ydeDv8A04+KK7n9py/17Sv2bPiFdeFdDtPE/ii28NalLo+jXcPnwateLayGC2kjyN6SSBUK5GQxGRQB5n+z38Of+Fd/tFSyaz4gvfEfifXfCUdylwmkWGmWkVolyP3bJbxq8kgeUENI7KAWCqm5y/0JXyl+w745+FniH42alZ/Ca00+60+38K2g1vURBetcWU6TsLfTRLdElI4lac/ZF/1BYZVN4DfVtABRRRQB4z+zJ/yXP9oj/sfLP/1GNCr2avGf2ZP+S5/tEf8AY+Wf/qMaFXs1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV8/f8FY/+UWn7SX/ZLfE3/pqua+ga+fv+Csf/ACi0/aS/7Jb4m/8ATVc0Ae+2v/HtH/uj+VSVHa/8e0f+6P5VJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHkn7Wnwm8Y/FjRfD8PhXVfJs7DUGm1rSP7ZutE/t+1aF08j7daq00G12V/lGH2bSQCTWL/wTx+H03wk/Z1tfC158O5fhzqWhXk1teWxNpJFqsvyv9uimt5H85JFZR5ku2UmNg6KRXutFABRRRQAV4N/wTj/AOTe9e/7KX4+/wDUw1mvea8G/wCCcf8Ayb3r3/ZS/H3/AKmGs0Ae80UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHkv7Z3/JKtB/7Hvwl/wCpDp1etV5L+2d/ySrQf+x78Jf+pDp1etUAfEXx4/ZP8dS6rNrnijwS/wAbrfT/ABeuuwJF4rlkmbTRemaO1j0W88rTd8EDGIMJdz7dw+ZyK+17BxLYwssTQK0akRMu0xjH3SBwCOlTUUAFFFFAHwb/AMF2vufsff8AZzHg3/28r7yr4N/4Ltfc/Y+/7OY8G/8At5X3lQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHh3w/8A+Uj/AMWP+ydeDv8A04+KK7X9pnwL4q+JPwW1XR/BWujw54juJbSSC8M0kAaOK6hlntzLGDJD58KSw+agLR+dvUEqBXFfD/8A5SP/ABY/7J14O/8ATj4or3GgD5v/AGHPhLc/Bj4j/Eywv/hbP4Outa1G31WHXU1KLWbfWIfsVrA8Zv3f7bLItxDcSEXMSH99uUtlsfSFFFABRRRQB4z+zJ/yXP8AaI/7Hyz/APUY0KvZq8Z/Zk/5Ln+0R/2Pln/6jGhV7NQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfP3/BWP/lFp+0l/wBkt8Tf+mq5r6Br5+/4Kx/8otP2kv8Aslvib/01XNAHvtr/AMe0f+6P5VJUdr/x7R/7o/lUlABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRWb4o8ZaR4I04XetarpukWjOIxPe3KW8ZY5IXc5AzweParcmpW8OnNeNPCtosfnNOXAjCYzuLdNuOc9MUAT14N/wTj/5N717/ALKX4+/9TDWa90sr2HUrOK4t5Y57edBJFLGwZJFIyGUjggg5BFeF/wDBOP8A5N717/spfj7/ANTDWaAPeaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/wDUh06vWq8l/bO/5JVoP/Y9+Ev/AFIdOr1qgAooooAKKo2/ifTbzXrjSotQsZdTtI1lns0nVp4Eb7rMgO5QexI5qW61e0sb62tprq3hub0stvE8gV7gqu5gik5bCgk46AZoA+Fv+C7X3P2Pv+zmPBv/ALeV95V8G/8ABdr7n7H3/ZzHg3/28r7yoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDw74f/8AKR/4sf8AZOvB3/px8UV7jXh3w/8A+Uj/AMWP+ydeDv8A04+KK9xoAKKKq61rll4a0qa+1G8tbCytl3TXFzKsUUQ6ZZmIAH1NAFqio7S8i1C1jngljmgmUPHJGwZZFIyCCOCCO9R6Zq1rrdmLizube7tyzIJYZBIhZWKsMjjIYEH0II7UAeQ/syf8lz/aI/7Hyz/9RjQq9mrxn9mT/kuf7RH/AGPln/6jGhV7NQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfP3/BWP/lFp+0l/2S3xN/6armvoGvn7/grH/wAotP2kv+yW+Jv/AE1XNAHvtr/x7R/7o/lUlR2v/HtH/uj+VSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAfOn7U2i/Yv2tvhR4o1/w7q/iLwHo3h/xHZXaWGgXOufZdTuJdKNpI9tbxSuMwQX6iXZhdxUsPMw3kWk/CX4g+MP+CYfhv4X6f4Y1D7bpsEcOvaTqz3OkyjRsT3NtYxO1vJFOzRLaW09uoKLG88R2MAo+6KKAPA/2VfDnxGh/4J5/D3RLaHRvh/470/who9jbnW9PuNWgsXjs7ZX+02iy2cu/iRDH5qFGAJJwVNH/AIJa2uqWP7KF3Drl5YajrcPxA8cpqF3Y2j2drdXA8W6uJZIoXllaKNn3FUaWQqCAXcjcfoqvBv8AgnH/AMm969/2Uvx9/wCphrNAHvNFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB5L+2d/ySrQf+x78Jf8AqQ6dXrVeS/tnf8kq0H/se/CX/qQ6dXrVABSPkoduN2OM9M0tFAHwT8F/BHib4Z/tLadq2q+FvFkGr6H4/wDHms+KNXh8P3tzHqGhahcSf2XHDcRRN9sJT+ycQI0hiFowZE8hdmpr/wAB/i1/w8e8CfEXXfC1pq+mnxdfW9jPba9NeQeGtKOkahb+YEa1H2b7Qq2jyqHCPcIiZbKMPuKigD83f+C5uh+O4/jD+yZf3HiPwpJ4Bk/aL8Fx2ejR+HrhNXgus3O6WS/N6YZIyBJiMWiMN6fvDtIf9Iq+Df8Agu19z9j7/s5jwb/7eV95UAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4d8P/8AlI/8WP8AsnXg7/04+KK9xrw74f8A/KR/4sf9k68Hf+nHxRXuNABXgv7enha68Qab8Lbx9F1PxB4Z8O+PrHVvEljYafLqUz2cdtdrFJ9ljV3nWO8ezkKqjFRHvABTcPeqKAPlL4Oab470b9g6TwL4W0S707xzdw6p/Y1vq0F9o9rpWmXGpyfZv9JEDLDPBp9zC0duNrB4fLxGI3MfVf8ABPr4deI/hh+yXd+FX8L6Z8PbrSNf8R22h2O1rq1tbdtWvXtpPKVLbMOHUqqbBJEEZWUONv0HRQB85/sDaR4v0Pxz8frfx1rnh3xH4kTx/bG4vtD0WfR7KVT4a0MoFtpru7dSFwCTO2SCQFzgfRleM/syf8lz/aI/7Hyz/wDUY0KvZqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAr5+/wCCsf8Ayi0/aS/7Jb4m/wDTVc19A18/f8FY/wDlFp+0l/2S3xN/6armgD321/49o/8AdH8qkqO1/wCPaP8A3R/KpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArwb/gnH/wAm969/2Uvx9/6mGs17zXg3/BOP/k3vXv8Aspfj7/1MNZoA95ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPJf2zv8AklWg/wDY9+Ev/Uh06vWq8l/bO/5JVoP/AGPfhL/1IdOr1qgAooooAKKKKAPg3/gu19z9j7/s5jwb/wC3lfeVfBv/AAXa+5+x9/2cx4N/9vK+8qACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8O+H//ACkf+LH/AGTrwd/6cfFFe414d8P/APlI/wDFj/snXg7/ANOPiivcaACiiigAooooA8Z/Zk/5Ln+0R/2Pln/6jGhV7NXjP7Mn/Jc/2iP+x8s//UY0KvZqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAr5+/4Kx/8otP2kv8Aslvib/01XNfQNfP3/BWP/lFp+0l/2S3xN/6armgD321/49o/90fyqSo7X/j2j/3R/KpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArwb/gnH/yb3r3/ZS/H3/qYazXvNeDf8E4/wDk3vXv+yl+Pv8A1MNZoA95ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPJf2zv+SVaD/2PfhL/ANSHTq9aryX9s7/klWg/9j34S/8AUh06vWqACiiigAooooA+Df8Agu19z9j7/s5jwb/7eV95V8G/8F2vufsff9nMeDf/AG8r7yoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDw74f/APKR/wCLH/ZOvB3/AKcfFFe414d8P/8AlI/8WP8AsnXg7/04+KK9xoAKKKKACiiigDxn9mT/AJLn+0R/2Pln/wCoxoVezV4z+zJ/yXP9oj/sfLP/ANRjQq9moAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACvn7/AIKx/wDKLT9pL/slvib/ANNVzX0DXz9/wVj/AOUWn7SX/ZLfE3/pquaAPfbX/j2j/wB0fyqSo7X/AI9o/wDdH8qkoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACvBv+Ccf/ACb3r3/ZS/H3/qYazXvNeDf8E4/+Te9e/wCyl+Pv/Uw1mgD3miiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8l/bO/wCSVaD/ANj34S/9SHTq9aryX9s7/klWg/8AY9+Ev/Uh06vWqACiiigAooooA+Df+C7X3P2Pv+zmPBv/ALeV95V8G/8ABdr7n7H3/ZzHg3/28r7yoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDw74f/8AKR/4sf8AZOvB3/px8UV7jXh3w/8A+Uj/AMWP+ydeDv8A04+KK9xoAKKKKACiiigDxn9mT/kuf7RH/Y+Wf/qMaFXs1eM/syf8lz/aI/7Hyz/9RjQq9moAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACvn7/grH/yi0/aS/wCyW+Jv/TVc19A18/f8FY/+UWn7SX/ZLfE3/pquaAPfbX/j2j/3R/KpKjtf+PaP/dH8qkoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKK+YP209G8O3P7UfwmvfiRplhq3wrg0PxFb3seq6d9u0uHV3k0prGSZCrqJPIj1FY2ZQBukAYFgD5To3xQ0rwl/wTH8KaF4v8J2PifxPZPZ6fp2jeM9Jka10qS886WwedrqMJ/o2ntuYO8Z/dGJnikfAAPvWvBv+Ccf/ACb3r3/ZS/H3/qYazXUfAD4VWXgj9l/w14R8KeN9a1G10jR7LTrTxG88N9dzLDBCizZkR4iXRAx+Uj94SAOK47/gmXZy6d+zLqlvcXc1/PB8RvHccl1MqLJcsPF2sAyMEVUBY8kKoHPAA4oA+gqKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/8AUh06vWq8l/bO/wCSVaD/ANj34S/9SHTq9aoAKKKRwShwcHHBx0oAWivz0+DbXHwt/ati1vW7LVbHxVo3jvx1feONVGlzzXN34bnuJBokcrojGWDZPpQgRS5UWzhVHlz+X2Wh674A+Lv/AAUmTT9H8M+GPBV18PNaub668RWsMVpq3jPUnt5LdrNiUjmaFXmunkwZVka3hO5VI3gGN/wXa+5+x9/2cx4N/wDbyvvKvz0/4Lp+HNQi8Zfsi6k3iDUZNOl/aR8GRJpDQW4toXH2rMgcR+cWODwZCvzHjpj9C6ACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8O+H//ACkf+LH/AGTrwd/6cfFFe414d8P/APlI/wDFj/snXg7/ANOPiivcaACiivnr/gojpMWp+FvhrJrVg+qeA7Px5YzeMLRrZrm1k04213GjXUYDbrdLx7KRsqVGwM+EVmUA+haK+P8A4RfFjwr8Nv8Agn5c6d490WbWLPTdP1XWLfw9qmiXDwz6X/abvpdqytC6qBDcafGqMu5BjKDy3C+o/sG+FbXRf2VtPh06/wBMin1Wa81G4h0UwtYaDc3UzzvZWqo0kSxW5k8tQCVbZux8xFAFn9mT/kuf7RH/AGPln/6jGhV7NXgv7Geh3vhz4q/tB2uoa1fa/dJ4+tS17dwwRSyA+GdCIBWFETgcDCjpzk171QAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfP3/BWP/lFp+0l/2S3xN/6armvoGvn7/grH/wAotP2kv+yW+Jv/AE1XNAHvtr/x7R/7o/lUlR2v/HtH/uj+VSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXg3/BOP/k3vXv+yl+Pv/Uw1mvea8G/4Jx/8m969/2Uvx9/6mGs0Ae80UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHkv7Z3/JKtB/7Hvwl/6kOnV61Xkv7Z3/JKtB/7Hvwl/wCpDp1etUAFFFFABRRRQB8G/wDBdr7n7H3/AGcx4N/9vK+8q+Df+C7X3P2Pv+zmPBv/ALeV95UAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4d8P/APlI/wDFj/snXg7/ANOPiivca8O+H/8Aykf+LH/ZOvB3/px8UV7jQAUUUUAFFFFAHjP7Mn/Jc/2iP+x8s/8A1GNCr2avGf2ZP+S5/tEf9j5Z/wDqMaFXs1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV8/f8FY/wDlFp+0l/2S3xN/6armvoGvn7/grH/yi0/aS/7Jb4m/9NVzQB77a/8AHtH/ALo/lUlR2v8Ax7R/7o/lUlABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV4N/wAE4/8Ak3vXv+yl+Pv/AFMNZr3mvBv+Ccf/ACb3r3/ZS/H3/qYazQB7zRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeS/tnf8kq0H/se/CX/qQ6dXrVeS/tnf8AJKtB/wCx78Jf+pDp1etUAFFFFABRRRQB8G/8F2vufsff9nMeDf8A28r7yr4N/wCC7X3P2Pv+zmPBv/t5X3lQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHh3w//wCUj/xY/wCydeDv/Tj4or3GvDvh/wD8pH/ix/2Trwd/6cfFFe40AFFFFABRRRQB4z+zJ/yXP9oj/sfLP/1GNCr2avC/gXdyWPxR/aVmibbJH42tWVv7p/4RbQua9cHgq0xzNqZPr/aM/P8A4/QBsUV4h8fP2tvgd+y14js9H+InxR0DwdquoRCe3s9U8SPBPJGX2CTYZNwTdkbiMcNzwcem6Do+i+KdEtNT0zUbnUNO1CFLm1urbVZpYbiJwGV0dXIZSCCCDgg13V8sxlChDFV6Uo06nwycWoytvytqzt5EqcW+VPVHRUVkf8ITZ/8APXU//BjP/wDF15/4E+Nnw7+Jfxb8S+B9G1zW7rxJ4SBbUoXXUoLcAMEfybmRVguPLchJPJkfy3IV9rcVwlHq9FeaH4t/C8eDZfEX/CwvD3/CP2909jLqf/CWL9jjuEUu8LTedsEiqCSpOQBkityxvfCmp2Md1beIYri2mligjmi113SSSWNJYkDCTBZ45EdR1ZXUjIIoA6+ivMbz4x/CvTtPlu7j4i+HILWHyPMmk8WqscfnmQQZYzYHmGKXZ/e8t8Z2nF/xV45+H/gXxNpui63400vR9Z1rb/Z9hfeJvs9zf7m2r5UbyhpMtwNoOTxQB39Fcfo1/wCE/Eg0/wDs7xAmo/2tYHVLAWuuSTG+tBsBuIgshMkWZI/nXK/vE5+YZ8sv/wBtT4RaN8XJ/BGo6n8QtJ121nS3mbUfDHiSy06LfO9vHIb6W2W0EMkyMiTeb5bkDazZGQD6DorznRPib8NfE3iDT9J03x5oeoarq0K3NjZW3ikS3F7E0YlEkUazFnUxsrgqCNrA9DmqEnxr+GWmR6aur+N9H8P3urJE9rY6j4tiiuJRK8iRbQLgh97RSBdpIYowHKkAA9VorzTUfib4D8OPqf8Abnia18OppmoNpzSan4njgWaRUgY7f9IJX/j4iG19r5dflwyFtPxX4m8EeA9asNN1zxZY6NqOqjNla33iI2814Nyr+7R5Qz/M6j5QeWA7igDuKKyP+EJs/wDnrqf/AIMZ/wD4uoptEj0G9s5bea+zJOInWW7klVlIPZmI9OaANyiiigAooooAKKKKACiiigAooooAK+fv+Csf/KLT9pL/ALJb4m/9NVzX0DXz9/wVj/5RaftJf9kt8Tf+mq5oA99tf+PaP/dH8qkqO1/49o/90fyqSgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8G/4Jx/8m969/2Uvx9/6mGs17zXg3/BOP8A5N717/spfj7/ANTDWaAPeaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDyX9s7/klWg/9j34S/wDUh06vWq8l/bO/5JVoP/Y9+Ev/AFIdOr1qgAooooAKKKKAPg3/AILtfc/Y+/7OY8G/+3lfeVfBv/Bdr7n7H3/ZzHg3/wBvK+8qACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8O+H/wDykf8Aix/2Trwd/wCnHxRXuNeHfD//AJSP/Fj/ALJ14O/9OPiivcaACiiigAooooA8H+C3/JSP2mP+x1tv/UW0Kvdx0rwj4Lf8lI/aY/7HW2/9RbQq93HSgD8SP+C8X/BC/wCPP7Z37d118Svhpp+i+I9B17SrK2kim1WOzn02WBBEysspAKEAOChPVgQCAW/Vn9gL9n7Vf2U/2LPhn8OdcvbfUNZ8H6Bbadez27s8LTIvzhC3zFASQCQOAOB0Hr9FfpfFHivnefcO4HhjHcnsMHbk5YtSdo8q5ndp2jpolfd3Zx0cDTpVpVo7yINSuJbTTp5YIGup442eOBWCmZgCQoJwBk8ZPHNfm/Y/8Eyf2nbzwBpE+u/Gyw1a91rQ/EGmap4dh8P2mnroUmvWNy10w1GEiS6WHUZLeU/IpfyA6hSAtfpPXnXw8/av8AfFX43eMPhzoGv/AG/xn4BETa9p32G5i+wCUAp+9eNYpMgj/Vu2O+K/NDsPnzxJ8FvGmrePvhf49j+Bmlvb+BLHUNDuvBsuqaYJEkmbR5YdXtWybZniGnTQRh2il2yRnMalgun4u+DXxK1n4qwwaf4FtbPw3rXjjQ/G93etrFsi6RDb6Va2U1j5K5Z5kktEYFP3TI5IfcoR/rWigD4q8V/sR+JfDX7FXwZ8B+G/CVqkmmWdnb+OdL0XUotGl1KVdGe1Znu42jcqLoxmV0cu0YbCy/ca5+xp8B/H/wCzFoeg6T4l+GMfjK91jQfDFpe63Bqlg50OWx0u2sp7efz3WR44pYZJ0aDzQxuJMKrZL/ZOeaKAPlb/AIJ1+BpYvHvxQ12PT7OLwrperT+FfBt3AQ0N5pkV9e37vbDaBHAkuofY9q5BOl7gSmwLL+2J+yZ4h+PHxda9t9J0/VPD9y3guO6iupo9k8WneKBqF6jRt95Ra5OCMP8AdGTxX1JXCSftLeCYfDUusNrWNOg8TL4Oeb7HP8uqtfLYC327N3/H06x78eXzu3bfmoA+PviR+xz8ZPGf7bGr69d6VJqPhC28beGdb8M3Vv4gjsbPSbGzuoHvt9rG6meUwqURJYmAHnFXVioll8D/APBPHxna+FvixHq/h3Rp7/xN8EdP8DaO8lxBK39ox3HiOSaLdk7ExqFkd5wpJ6/IcfavxP8AiXY/Cfw1b6rqMV3Nb3Oq6bo6rbKrOJr6+gsoWIZlGwS3CFjnIUMQGIANHxz8Y7b4a/A7XPHeuaTrFhZeHdIutZvdPPkSXqRW8Tyug2StEXKocYkxkjLDnAB8m6P+wR4t1r4h+M9Q8S+H9H1S11iXxPNaG7mhuNz6hoWhWMTYbOC72d4jHsvXh+fJf2tvhV4j8Aab4F8FajoEHi7xh4z074b6ZbmO4juL7Rp9I8Q/ab1xGd0rwiOYsZYsoixStKY12lv0k1nx5pvhvwBdeJ9Rmaz0ew099UuZWjZ2ggSMyuxVASSFBOFBJxxmq2h/EOLxTdaBJpenajf6L4h0t9Vh1lPKS1gT9wYo5EeRbjfKsxZNsTKBDIHaNigcA6Gs/Xvv2H/X2n8mrQrP1779h/19p/JqANCiiigAooooAKKKKACiiigAooooAK+fv+Csf/KLT9pL/slvib/01XNfQNfP3/BWP/lFp+0l/wBkt8Tf+mq5oA99tf8Aj2j/AN0fyqSo7X/j2j/3R/KpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiuW+J3xr8K/Bm3sZPE+uWWj/2nK0NmkxJkunVdzBEUFm2rycDgdah1/4++C/C/wANtO8YXvibR4vDGsJA+n6ktwJLe/E67ofJZc+ZvU5XbnI56UAdfXg3/BOP/k3vXv8Aspfj7/1MNZr2fwh4x0n4g+F7DW9C1Kx1jR9Vt47uyvbKdZ7e6hkQPHIjqSGVlZWBBwQQa8Y/4Jx/8m969/2Uvx9/6mGs0Ae80UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHkv7Z3/JKtB/7Hvwl/6kOnV61Xkv7Z3/JKtB/7Hvwl/wCpDp1etUAFFFFABRXJ6H8dPB/ib4lah4O0/wAR6TeeJ9LR3utNinDTwhPKMmR6p58G4DlfOj3Abhmhb/tPfD26+KzeBo/GOgv4tW4+yHSxdL9oE/lNN5WOnmeXHI+zO7bG5x8rYAPkj/gu19z9j7/s5jwb/wC3lfeVfBv/AAXa+5+x9/2cx4N/9vK+8qACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8O+H//ACkf+LH/AGTrwd/6cfFFe414d8P/APlI/wDFj/snXg7/ANOPiivcaACiisL4i/EzQPhJ4YbWfEurWWjaYs0Vv59zJtV5ZXEccajqzu7KqqoJJIAFAG7RXOf8Ld8L/wDCrv8AhNv7f0n/AIRD7B/an9sfaV+x/Zdu/wA7zM7dm3nNWfh/8RdD+KnhmPWfDup2uraZLLLAJ7dshZIpGjkjYdVdHVlZSAVKkEAigDyH4Lf8lI/aY/7HW2/9RbQqu/tG/sdX37QnjK01i1+Mvxn+HaWtktmdP8I6xa2dnOQ7v5zpLbSsZTv2khgNqJxwSYPgLYvqfxW/aUt48eZN42tUTJwMnwtoWK9bTxBdhRnR9Rz3wYf/AI5XfluZ4jAVvrGFaUttUpb+Uk1+BM4KStI+a/8Ah2FrH/R0f7U//hT6d/8AIFH/AA7C1j/o6P8Aan/8KfTv/kCvpX/hIbr/AKA+o/nD/wDHKP8AhIbr/oD6j+cP/wAcr6H/AF9zv/n5H/wXS/8AkDL6rT7fiyt4a0K4+G3wwsNNW91fxPdaDpcdsLzUplkv9WeGIL5kzqqq00hXLMqAFmJCjpXxO/7LPx4T4B+DdftNTstH+IPijRdbtvEdlpWkC1vdEudes57u4Zrk3jLI1pqn2XYygcR43KpYj7h/4SG6/wCgPqP5w/8Axyj/AISG6/6A+o/nD/8AHK+SqVJVJuct3qb7aH59eJ/2aJrnw18Mntf2XbFvh7a3l7b+Kvh2rxx6f9vuY9Kb+3ZoRGBdyxJBf22DFJ5olkJb95h+617wJ8Q9O+Lei+G/D3wkuLHwZqvjfw34rkvobuKK30Cyt9Ft7OW2WLAz5MtjCmAVYifIj2oWP2X/AMJDdf8AQH1H84f/AI5R/wAJDdf9AfUfzh/+OVAH5+fF7/gnvPo37Avwq8MeHvhXa3PibVNM0uPxqYdO0y91X7VaaRcG3DSahb3cK7b6VkD+UwiNzK6mPLPWv8Bf2fdeg8T+B9R+MnwQHxL8X2/hzwpJp3ijXVjv7zw1eR2UMN9bxuUlMDRXUL3Ly70817k8nZur7s/4SG6/6A+o/nD/APHKP+Ehuv8AoD6j+cP/AMcoA+V/+CbngKO3+K/xOZdFhtfDvwn1CT4aeBLpHEkP9jpJ/aEi2zZO2NDdWlkygkf8SePJ3KypgftGfs8/Fa8/a78Xr4W0b+1PhvdeGrv4i2SXAha2vfGsNg+lW2myK0isYJIjBdkEBRNbg7wWOPsDTr46PZrb2nh+6tYEJKxQpAiKSSTgCTHJJP1NT/8ACQ3X/QH1H84f/jlAH5bfsMfsY/Gn4VfGf4tWV14X8V6b8NNS1zwHqPhqyu10y0s0+x63Y3WoPBZ2UFtFbhALmRgIEL4JPmOS7yfGz9i7x/efCPxHpus/A6X4nalf/CiPR/CMl1cxb/Cer+Zq4njt+XEMkjS6fK0oMW4pGN7eSPL/AFF/4SG6/wCgPqP5w/8Axyj/AISG6/6A+o/nD/8AHKAPzZ+Kv7HXxW+Kn7a2t31x4Dlh0PxFp+seF9UvYLDSY7LVdGfwo0NkLqUw/a7hjqJVPLe6MSGBD5KZD0L+w3rmneCfBkfwy+DVv8NH0n4VeJNO8Qafo2nQaSusavLL4XlNrIyrCGe+i0+7tjcDdhVY7jhQf0m/4SG6/wCgPqP5w/8Axyj/AISG6/6A+o/nD/8AHKAPzOg/4J3eI/iN+0L8HW1T4VJZfByw8ceKrweD5o4W0nwtos+naZbwW/2ckAQXNza3Vz5PlqFa6kUpjlvtr9izwV4g+G/7Jfw88P8Aie2u7PV9FLWTW9zJ5klvBHNMtum7JyFgEQHJ4Ar1f/hIbr/oD6j+cP8A8cqOS5u9ZvbRTp9zbRwzebI8xjxgKcAbXJzkjtQBtUUUUAFFFFABRRRQAUUUUAFFFFABXz9/wVj/AOUWn7SX/ZLfE3/pqua+ga+fv+Csf/KLT9pL/slvib/01XNAHvtr/wAe0f8Auj+VSVHa/wDHtH/uj+VSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeHfHTwR4m0z9rX4bfEfR/Dmp+LdJ8OeG/EHh++sNNubSK6hlv59JmhnUXU0MbIBp8yNh9wMqYBG4jy/wCFPwQ+IHw0+BPwRsLrwRq13qfwu8VS+INS0+zv9PP2mC90/WIzBas9yiMbWTUoY28wxAiBjHvAXP2DRQB84fsMfs3eOvgN+ypd6HeXWj+HvFWs3o1WGCWJtStdC8yC2U2rLFLEJPLMciDy5FXoQSODY+C37LPxR+Bfg670TSfib4MntbzXNX192uvBd2zifUtSudRnUFdVUbFmupAgxkIFBLHLH6HooA8l/wCFefGT/oo3w/8A/CIvv/lvR/wrz4yf9FG+H/8A4RF9/wDLevWqKAPJf+FefGT/AKKN8P8A/wAIi+/+W9H/AArz4yf9FG+H/wD4RF9/8t69aooA8l/4V58ZP+ijfD//AMIi+/8AlvR/wrz4yf8ARRvh/wD+ERff/LevWqyPH8+p23gPW5NF2f2xHYTtYb0Lr9oEbGPKgEkbscYOaAPEvg7pH7QfjTwpeXfiPxT4B8PX8Ot6tYw2p8F3zedZ2+oXFvaXOf7X/wCW9tHDPjt52K6r/hXnxk/6KN8P/wDwiL7/AOW9c9+wV8WvF3jnwp4i8P8AxEm1WTx/4Ru7aHWPtccCQyefZwzJJaiO2tmNsWaRQZItweOVdz7M173QB5L/AMK8+Mn/AEUb4f8A/hEX3/y3o/4V58ZP+ijfD/8A8Ii+/wDlvXrVFAHkv/CvPjJ/0Ub4f/8AhEX3/wAt6P8AhXnxk/6KN8P/APwiL7/5b161RQB5L/wrz4yf9FG+H/8A4RF9/wDLeuT+HWlftCeJfFvjqz1nxR4B0jT9A1yOw0O6Pgu+P9t2badZXDXIH9r8YuZ7mDH/AE7Z713/AO15rfiPwt+zN431nwnrcfh7XtC0a61S2vHsUvApt4mlKeW52ncE25Ocbs4OK8K+Mnx8+KN14P8AHvifwx4r0rQIfhZ4DsfFMunXOiR3cXiC6eyu7yZJpCweKJhDDGpiKsuZj8xKbAD2L/hXnxk/6KN8P/8AwiL7/wCW9H/CvPjJ/wBFG+H/AP4RF9/8t69Q0PU/7a0SzvNhj+1wJNsJzt3KDj9atUAeS/8ACvPjJ/0Ub4f/APhEX3/y3o/4V58ZP+ijfD//AMIi+/8AlvXrVFAHkv8Awrz4yf8ARRvh/wD+ERff/Lej/hXnxk/6KN8P/wDwiL7/AOW9etVx3x/fXIPgz4jn8Oa0PD+s2djJdW98bNLvyTGpcjy3+UlgpXJzjOcHGKAPK/h7pP7QfiPxf45s9X8U+AdJ07QdaisdEuz4Lvj/AG1aNp1lcNcgf2vxtuZ7mDH/AE7Z711f/CvPjJ/0Ub4f/wDhEX3/AMt6+f8A9pb9qj4pfCP4feHfiXM3iiT4c2vgbTte15vDFlaPdw3Hl3NzfzOtzZTRmJYI4sDz4QpPzEBw6/a1rdR3trHNE6yRSqHRlOQykZBBoA8p/wCFefGT/oo3w/8A/CIvv/lvR/wrz4yf9FG+H/8A4RF9/wDLevWqKAPJf+FefGT/AKKN8P8A/wAIi+/+W9H/AArz4yf9FG+H/wD4RF9/8t69aooA8l/4V58ZP+ijfD//AMIi+/8AlvXKaPpP7Qd78bvEOhXPinwDb+GNO0TTL7T9Z/4Qu+xf3k89+l1bY/tfjyY7e0fPf7V7V7N8UbW9u/AWoiw8Rr4RmRFmfWGt4phYwo6vK22b92Mxq43OCq7txDbcH5a+AXxs+L/7Tmj+F9IbxVB4I1KbQdW106pH4eikl1m3XV5bTSpXgmLJGslpEs8oiOHadDFIseNwB6x4k/Z++I3xFbSLTxN4/wDCl1o2na1putTQad4TurW4nayvIbyNFlk1KZVDSQICTG3yk4wcEe2V55+yV8X739oD9l34eeONTtrWz1Lxb4dsdWu4LbPkRTTQJI4j3EnZuY4yScYyTXodABTZU8yJlB25BGR2p1FAHxR8K/2afiL8Lvi74emuPCWpahp/gf4heOPGralZX9hjxBa63cXklpaQrJcJIJEXUF8zzxGg+wHazZjy7Sv2ZfiJDrlr4SfwjdCzt/jHN4+Pixr+y+xf2e2uahq4jVBMbrzfKuY7XaYQMu/PljJ+1aKAPmb9u39gvxD+2z4l+Hsx8faZ4a0r4ZeNdK8e6Par4dlu55NQsBJ5aTy/bEV4GMrEqkaP0w/Unv8A/hXnxk/6KN8P/wDwiL7/AOW9etUUAeS/8K8+Mn/RRvh//wCERff/AC3o/wCFefGT/oo3w/8A/CIvv/lvXrVFAHkv/CvPjJ/0Ub4f/wDhEX3/AMt6P+FefGT/AKKN8P8A/wAIi+/+W9etUUAeS/8ACvPjJ/0Ub4f/APhEX3/y3rz79oFv2k/h1H4NPhHWvAXiw614ostK1gL4Mv0/sjTpfM8++ONX5Ee1OP8Aar6br5m/bl8cfGLwD4ysdV8EDWJvBGk+Hr2/1i20S3hfVbm6jeNo1h86xuo3/crOBHmMs7R/NjNAHf8A/CvPjJ/0Ub4f/wDhEX3/AMt6P+FefGT/AKKN8P8A/wAIi+/+W9eh+APFdr488CaLrljK09lrNhBfW8rFS0kcsaurHZlckMD8vHpxWvQB5L/wrz4yf9FG+H//AIRF9/8ALej/AIV58ZP+ijfD/wD8Ii+/+W9etUUAeS/8K8+Mn/RRvh//AOERff8Ay3o/4V58ZP8Aoo3w/wD/AAiL7/5b161RQB88fHvS/wBoX4e/A/xjr3hPxP4B8VeKNF0S9v8ASNFXwXfIdWvIreSSC2DDV+PMkVEz/tV1cfw9+MrRgn4i/D8Ejkf8IRfcf+Veq7fELxN4S/a08RaTf6wNU8LN4QPiCy0xLCOKSwkinETKJR80m/k/NwMgAcZPCfsQftD+PPiF8Ro9E8Zatpeuw+Ifh1oHxBs5bWwFo+ly6hJdpcWXykiSBPJiMTN+8/1m9n+XAB6L/wAK8+Mn/RRvh/8A+ERff/Lej/hXnxk/6KN8P/8AwiL7/wCW9etUUAeS/wDCvPjJ/wBFG+H/AP4RF9/8t6P+FefGT/oo3w//APCIvv8A5b161RQB5L/wrz4yf9FG+H//AIRF9/8ALeue+LXh74+eD/hZ4k1bw/4w8A69r2maVdXem6YPBV8p1G5jhd4oM/2vxvcKuf8Aar3uvLR4m8S6N+2LbaHPriXnhfXvC97qlvpv2GOM6fNa3Gnw7hMPnff9qlJDcDCgDgkgFWH4ffGZ4lLfEX4fqxAJH/CEX3B/8G9O/wCFefGT/oo3w/8A/CIvv/lvXCfsG/Gzx14o8V+KfBPxTm1ZvHuh6ZpmtTLNBbxae9tdtdIrWgW2t5sB7aRZFlWTYRGBIxLY+laAPJf+FefGT/oo3w//APCIvv8A5b0f8K8+Mn/RRvh//wCERff/AC3r1qigDyX/AIV58ZP+ijfD/wD8Ii+/+W9H/CvPjJ/0Ub4f/wDhEX3/AMt69aooA8kf4e/GVUOPiN8PyccD/hCL7n/yr1yfwD0v9oX4hfAzwbr3izxR4B8K+Kdb0Oyv9Y0VvBd850i8lgR57UsdX58uRmTP+zXMftl/Gz4tfBX9o34X6b4A1aw8Ux+OvFun2Wr+GJ9F85dB8PboYr3UfNgP2hXWVhiaQeQom2soZAXP2eP2p/HHjH9ozwfZ6zqGn33hf4oaf4uvrLThYrBP4eOjata2luqyKcyrLBcky+ZkiVAUKqSlAHrPwX+Aev8Agb4y+LfHPijxRpviHWfFGj6Vofl6do8mm29rBYTahMh2yXNwzOzajLk7gMImBnJPqtFFABXjX7YHw58QeMLr4Xa74f0eXxE/gDxtB4gvdKgnghnvbb7De2beUZ3jiLxtdpMA7rkQnB3bQfZaKAPjfXf2bviBrX7BP/Cu08M6hF4jTxJH422PfWX2eRI/FcOuf2TvE5/fPbl7cHHkbo3zIEKlvWv2SfhV4o8FWvxb1jV7NvDt58RfGt34i0vT7x4rqTSoTYWVnH5wglaMs72bzlY5ek4BYNux7dRQB8/+Bv2afir4A8VeMtXs/iZ4KkufG+rR6zfLN4KvCkU0djaWIWPGqghfKs4j8xY7mbnBAHTf8K8+Mn/RRvh//wCERff/AC3r1qigDyX/AIV58ZP+ijfD/wD8Ii+/+W9H/CvPjJ/0Ub4f/wDhEX3/AMt69aooA8l/4V58ZP8Aoo3w/wD/AAiL7/5b0f8ACvPjJ/0Ub4f/APhEX3/y3r1qigDyX/hXnxk/6KN8P/8AwiL7/wCW9Yvhnwv8d9U8Q+Ire98a+ALKz029jg0+f/hCr4/2hCbaCRpf+QvxiV5Y/wDtlXulfNH7JHxf+JE37QPifwX8UTrB1O4gv9b0KRLWGLR5dNj1OSCNIj9mhn+0RwyWfmqXnX96rb13qCAd7/wrz4yf9FG+H/8A4RF9/wDLej/hXnxk/wCijfD/AP8ACIvv/lvXrVFAHkv/AArz4yf9FG+H/wD4RF9/8t6P+FefGT/oo3w//wDCIvv/AJb161RQB5L/AMK8+Mn/AEUb4f8A/hEX3/y3o/4V58ZP+ijfD/8A8Ii+/wDlvXrVUvEVneajoV5Bp96unX00Lpb3TQCcW8hUhX2EgNtODgnnGKAPDdM0P4/3Xxg1rRp/FvgGHw7Y6PYXtlq3/CFX2Ly6mmvUuLfH9r8eUkFs+e/2n2rpf+FefGT/AKKN8P8A/wAIi+/+W9fPPjf9rP4p23w10ux0nxNpdt4i0jwf428W3urXmkRSR6w+hajFZ21s8SlVjilE26Ux7XGwbGXJNfY3w58Xf8LA+Hug68IGtRrenW9+IWbcYfNjWTaT3xux+FAHn/8Awrz4yf8ARRvh/wD+ERff/Lej/hXnxk/6KN8P/wDwiL7/AOW9etUUAeS/8K8+Mn/RRvh//wCERff/AC3o/wCFefGT/oo3w/8A/CIvv/lvXrVFAHkv/CvPjJ/0Ub4f/wDhEX3/AMt6xbTwv8d5viJqGmyeNfAEej2+nWtzb3//AAhV9/pE8ktwssOP7X/gWOFv+21e16zbXN5o93DZ3IsryWF0guGiEogkKkK5QkBsHBxkZxivi34nftDfGTwn8BdI8WWup6prGkeDdV8ZQ+MrzR9Ntk1O/tdJ1Se1tmhje1ntxIYrd2ZCIg5HEigGgD6B/wCFefGT/oo3w/8A/CIvv/lvR/wrz4yf9FG+H/8A4RF9/wDLevU9N1GHV9Ogu7aVJ7e6jWaKRGDLIjAFWBHBBBHIqegDyX/hXnxk/wCijfD/AP8ACIvv/lvR/wAK8+Mn/RRvh/8A+ERff/LevWqKAPJf+FefGT/oo3w//wDCIvv/AJb0f8K8+Mn/AEUb4f8A/hEX3/y3r1qsL4laNr/iHwTe2fhjXLXw3rkuz7NqNzp39oRW2JFL5g8yPfuQMv3xgsDzjBAPHNW0P4/2fxf0LRrfxb4Bn8O3+k6heX2rf8IVfYsbqGayS3t8f2vz5yT3LZ7fZveq37QX7KfxQ/aR+A3jX4ea58TfBttovjvQb7w9qE1l4Lu0uYre7t3gkaIvqrKHCyEqWVhnGQRxXn2j/tIfEjxJ4p0/wJpvjK1uY/EHxJvvCul+Nf7Jt5JZrGy0BtQuGWNR9lkkF/FNbb1XAWKVWUSoWr2f9g79pDUP2qv2ZPDXi7V7G2sNYu7G1GoLbZ+zS3LWkEsrwgklYy0p2gkkADJNAHsMSeXEq9doAzTqKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqrrWkw6/o93YXHni3vYXt5TDO8EgV1KnbIhV0bB4ZSGB5BBFWqKAOP+EnwI8NfBCDURoFtqPn6xMk99ealq13q17dsiBE33N3LLMyqowql9q5OAMmuwoooAKKKKACiivHP+ChPj/WvhZ+w98VPEfhy7u7HXdF8N3l3YXFrt8+KZYyVKbiF3Z6ZIGe4oA734w/CPRPjx8NtV8JeJE1KbQtbh+z3sVhqt1pk00ZI3J59rJHMqt0YK4DKSpyCQfPNW/wCCfPwr1/SLGwvtJ8RXllY6amjvDP4u1iRdSskaVktr0G6/02IefMoW680BJXTGwla898C/HPx78Ok8O2CfDPxzb63468QJoVnbfEPxTaW0UezTdV1B5UlsrnVTwtgEK7Uz58ZydjBcaD/gqrfa98DNT+JGj/Dyxn8KeFdAs9e8RC98UC1v7dZbF76WOziFs8d3shTCMZYhK5wNoBagD7DRBEgVQFVRgADgClr4w/a2/au8ceOP2VPEviTwnpEfh7TdI+I+jeGtNvoPEs9tquozWvjWw0u6hliS3At4J9lyhPnSFonAaPDso7bxz+3R4x+Ht7rWnX3wzsZtR8MapFba3c2Gt3t9pelWUunm8jvJJYNNe5wWVoiPsuxCAzSAGgD6ZoqromrRa9otpfW8kM0F5Ak8UkL745FZQwKtgZUg8HHIq1QAVg/Ez4b6X8XfAuo+HNa/tL+ytVi8m5FhqdzptwyZBIWe2kjmTOMHa4yCQcgkVvUUAeLan/wT9+GGueCNO8M39l4v1Hw5pmm/2OmlXnjfXLiyubPL5guYXuylyhWR0InD5jIjOUAUezwwrbwrHGqoiAKqqMBQOgAp1FABRRRQAUUUUAcj8dfgZ4Z/aU+FGr+CPGVjc6l4Z11Y47+1g1C5sGuESVJQplt5I5QpZF3KHAddysCrMp5fxB+xb4D8UaFo9her4yk/sGG4tbS8TxrrUWo+RO6vLDLeLdi4miZkQ+XLIyjYuAMCvVqKAM7wj4S0zwD4U03Q9FsbbS9H0a1isbGztoxHDaQRoEjjRRwFVQAB6CtGiigAooooAKKKKACiiigAooooAKKKKACuF+Lf7Onhr43XcMuvSeKh5MDW3laX4q1TSIJo2JJWWK0uIklzkj51bg46cV3VFAFTQtDs/DGiWem6dbQ2Wn6fAltbW8KBI4IkUKiKBwFCgAD0FW6KKACiiigAoor5Q/bD+JXjPSv2p/Bfh3w/o/xJ8T6Ze6FrF7dab4PvbK0mjkhm0dI55Wub6yBjUXMy4WRzmX7hxlQD2TWf2SvBmvfHJfiNP/wly+K0jigE0HjDV7ez8qN0dYvscd0tr5ZZFLJ5W1zncG3Nmz8E/wBljwJ+zvqGoXfhHRJNPutTtrexmmn1C5vpEtLcyG3tImuJJDDbRGaUxwR7Yk819qDca8MsP+Cn7+Hta/4qnwKdP8PXOreKNG0670zWv7T1CeTQtXGmytNamCMRiX/WDZLLt+4xyVY19H/4KharqHxB8PeB5vh3p8XjfxjFoF3osMfiYzaS1tq9nrN5C1zdi0DwyJHod4GRYJAzPbhWYOxQA+vaK+QfiR+0x8Qfg1+1t4hvtT0OwvNE0f4c6TqmtaTB4qnaz0wNrOowvcWoa0AnuGhVCQ0cOfKCGTAU16l8IP2uLnx18X7/AMHeJdBsfBOsLd3MWl6ffX91/aGq28T3AFxHHJZxQSI0cAk/0eecKr/MysMEA9sooooAK808X/sleDfHPxltPH1+fGC+J7CEW8Etn4y1iytY4t8TmP7JDdJbFGaGIupjw+wbg3Nel0UAcJ8JP2bfCPwR1rU9T0K01V9V1iGG1u9Q1bW77Wb2WCEyNFCJ7yaWRYkaWVljVggMjHGSa7uiigAooooAKKKKAPK9S/Yx8B6n8ctT+I/l+LrTxdrJszfXNj4z1mzt7pbRdtvG9rDdLbmJfmPl+XsYySMykyOW0vAv7LHgT4b/ABSv/GekaI8PiPUFu0a5mv7m5S0W7nW5u1toZZGitVnnRJZRAiCR0Vn3EA16FRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVw/gL9nXwt8N/HN94l06HWrjW9Qikt2utU16/wBVNvFJIJXigF1NItvGzqhKQhFPlpkfIuO4ooAKKKKACiiigAqrrejxeINHurG4a5SC8heCRre5ktpQrKVOySNldGweGVgwOCCCAatV+aeif8FMPHP7KH7Nnwb8V+Ifhj8RfEeq/GDxH4W8GQ3ni3xRY2OnXlxqlrPK2oWxt7m/cRhoQTHJb2xKzLwCpQAH1wP+CbvwhfwPD4cn0PxDf6TBLfSLHfeL9Zu5XS9KteW7zS3TSPbXDIrS2zMYZGUFkJ5r3G3t47O3SKJEiiiUIiIuFRRwAB2FfHvi/wD4KrX3hLTvGKN8PLObVvhnpfiDWvFkA8S7LaG00eWBJfsExtc3csiTqyo6QBWBR3U4zbtP2/b79qDwB8fovBHh240bR/hQNd8N6nrWoas9jqsepWltcES2lqkLbotyxFZXnibLNhcx8gH11RXzT4A/az8c6Z8JbuG/+Hn9q+KvD+heH9TW1sNbuNR+3WuoM0PnzOlmZxLF5FzJJHFDcErGNhctge1/BD4p23xq+Fmk+JbSTTpI9RRw4sbiWeGGWOR4pYg0sUMm5JEdGV4kZWVlZQQRQB1dFFFAEGp6fHq2m3FrKZliuYmicwzPDIFYEHa6EMh54ZSCDyCDXi+nf8E7/hfpng2Xw8lv46k0S5u729ubK4+IHiCeK9kvH8y6Ewe9PnRyuWZo5NyEySHbl3z7fRQBHa2sdjaxwQxpDDCoSONF2qigYAAHAAFSUUUAFFFFABXO/Ff4W6T8avAF/wCGddOrjStS8vzzper3ek3X7uRZV2XNpLFPH8yLnY67hlTlWIPRUUAeN6L+wR8MvD/wn0zwTa6d4mXw9odzHd6SknjDWJbrR5I4Gt0+yXTXRuLZfJd49kMiKVkcEEM2fTfAfgLRvhf4N0zw94e0200fRNGtYrGxs7WMJFbQxIscaKPRUVQPYCteigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACud+LXwp0D46fDLXfB3imw/tTw54lspNO1Kz8+SD7TBIpV03xsrrkHqrAjsa6KigD5i8W/8EjPgr4h0XRdGtvDP2Dw9aa9Hrmqaf/aN/L/axi0/UbOKPzDcB4th1B5NynnZtI5BXqvGH/BNr4LePfEPhLVdW8Gfar/wNZWOnaHL/a9+n2GCyLNbJhZgH2Fjy4Ytn5ia9zooA8b1r9gD4R+IfHPiDxJeeEvO1rxTeWeoapc/2per9qntL21vrd9omCrsubK2fCgA+XtIKsymf42fsJfCr9oq81G48ZeFv7Yl1WaK4um/tO8t/NeOEwIcRSqBiMleMA9TzzXrtFAENhYxaXYw20C7IbeNYo1yTtVRgDJ56CpqKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8p+P/AOxH8MP2o/EGk6p468M/25f6FHPFYy/2jd23kLP5JlGIZUDbvs8P3gcbOMZOfVqKAPBf2X/+CeHgH9mHx54k8YafZfbPGfifVtavrvVvOuY82+o6rLqItvJaZ4v3W6KPzAoL+Tuwu4rU2i/8E1vgp4e+FOt+CLPwX5PhjxFfW+o6jZf2vft9ongx5T+YZzIu3aOFYA45Br3SigDyfQP2H/hf4X8PXmlWPhjyLDUNGXw/cRf2ldt5lit1cXYhyZSR+/up33A7vnxnaFAsfC/9jP4bfBj4lav4v8NeG/7N8Ra9Obi/u/7QupvPkJmJOySVkXmeXhVA+f2GPUKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACvhv9pv/ggt8IPjR4F8BeHvCcP/AAgWm+EvHOj+LtRj33uqf23bafHcx/YMy3atB5i3LfvlJZcfdbPH3JRQB4bqP/BNz4Lat4H8I+G7jwZ5mi+BLm4u9Ct/7Xvh9hluJlnmbcJtz7pFDYkLAYwABxW/40/Yq+GXxC+KMvjPWPDX2vxLNplxo73n9o3cebSdJ0lj2LKE+Zbmcbtu4b+CMLj1OigDzjxv+yR8PfiP4f1PS9Z8P/bLDWNNsNIvIvt1zH51rYyvLax5SQEbHkc7gQzbsMWAArp/hX8LdC+Cfw80rwp4Ysf7M0DQ4BbWVr50k3kxgk43yMztyTyzE10FFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/Z)"
      ],
      "metadata": {
        "id": "Cd_6OKFnEnvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gemini Solución**"
      ],
      "metadata": {
        "id": "Cm1Lbf8kIPoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de las Gráficas**\n",
        "\n",
        "Las gráficas presentadas muestran la evolución de la precisión (accuracy) en los conjuntos de entrenamiento y validación a lo largo de las épocas de entrenamiento para tres modelos de redes neuronales diferentes.\n",
        "\n",
        "*Eje X:* Representa el número de épocas, es decir, las iteraciones completas del conjunto de entrenamiento durante el proceso de aprendizaje.\n",
        "*Eje Y:* Representa la precisión, que es una métrica que indica qué proporción de las predicciones del modelo son correctas.\n",
        "\n",
        "**Comportamiento de los Modelos:**\n",
        "\n",
        "+ Modelo 1: La precisión en el conjunto de entrenamiento aumenta rápidamente en las primeras épocas y luego se estabiliza en un valor alto, mientras que la precisión en el conjunto de validación aumenta inicialmente pero luego comienza a disminuir ligeramente. Esto sugiere que el modelo podría estar comenzando a sobreajustarse a los datos de entrenamiento.\n",
        "\n",
        "+ Modelo 2: Este modelo muestra una mejora gradual en la precisión tanto en el conjunto de entrenamiento como en el de validación. Sin embargo, la precisión en el conjunto de validación no alcanza el nivel de la precisión en el conjunto de entrenamiento, lo que indica que el modelo podría beneficiarse de un ajuste fino o de más datos de entrenamiento.\n",
        "\n",
        "+ Modelo 3: El comportamiento de este modelo es similar al del Modelo 1, con un rápido aumento inicial de la precisión en el conjunto de entrenamiento seguido de una ligera disminución en la precisión de validación. Esto también sugiere un posible sobreajuste.\n",
        "\n",
        "**¿Qué modelo elegirías?**\n",
        "\n",
        "La elección del mejor modelo dependerá del objetivo específico del problema y de los criterios de evaluación. Sin embargo, basándonos en las gráficas proporcionadas, podemos hacer las siguientes observaciones:\n",
        "\n",
        "*Modelo 2:* Parece ser el candidato más prometedor. Su comportamiento es más estable y no muestra signos claros de sobreajuste. Sin embargo, podría beneficiarse de un ajuste fino de los hiperparámetros o de más datos de entrenamiento para mejorar su rendimiento.\n",
        "\n",
        "*Modelos 1 y 3:* Ambos modelos muestran signos de sobreajuste, lo que sugiere que están aprendiendo demasiado los detalles específicos de los datos de entrenamiento y pueden tener dificultades para generalizar a nuevos datos.\n",
        "\n",
        "Consideraciones adicionales:\n",
        "\n",
        "*Complejidad del modelo:* Un modelo más complejo (con más capas o neuronas) puede ser capaz de aprender patrones más complejos, pero también es más propenso al sobreajuste.\n",
        "\n",
        "*Cantidad de datos:* Una mayor cantidad de datos de entrenamiento puede ayudar a reducir el riesgo de sobreajuste y mejorar la generalización del modelo.\n",
        "\n",
        "*Técnicas de regularización:* Técnicas como el dropout, la regularización L1/L2 o la early stopping pueden ayudar a prevenir el sobreajuste y mejorar el rendimiento del modelo.\n",
        "\n",
        "*Métricas de evaluación:* Además de la precisión, es importante considerar otras métricas como la precisión, el recall, el F1-score, etc., especialmente en problemas de clasificación desbalanceada.\n",
        "\n",
        "**Recomendaciones:**\n",
        "\n",
        "*Ajuste fino del Modelo 2:* Experimentar con diferentes valores de hiperparámetros (tasa de aprendizaje, tamaño del lote, etc.) para mejorar su rendimiento.\n",
        "\n",
        "*Regularización de los Modelos 1 y 3:* Aplicar técnicas de regularización para reducir el sobreajuste.\n",
        "\n",
        "*Recopilación de más datos:* Si es posible, obtener más datos de entrenamiento para mejorar la generalización de todos los modelos.\n",
        "\n",
        "C*omparación con otras métricas:* Evaluar los modelos utilizando diferentes métricas para obtener una visión más completa de su rendimiento.\n",
        "\n",
        "**En conclusión, el Modelo 2 parece ser la opción más prometedora en base a la información proporcionada. Sin embargo, es importante realizar un análisis más profundo y considerar otros factores antes de tomar una decisión final.**"
      ],
      "metadata": {
        "id": "x0u-sXXLIWwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Otra Solución: **"
      ],
      "metadata": {
        "id": "ybiG2u4VN0yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Detectas algún comportamiento llamativo?**\n",
        "\n",
        "Con respecto al primer modelo, se puede observar que la accuracy para el conjunto de datos de\n",
        "entrenamiento es 1, pero no converge para el conjunto de validación, indicando así que el\n",
        "modelo está experimentando un sobreajuste.\n",
        "En cambio, pasando al segundo modelo, la accuracy no alcanza el 1 en los datos de\n",
        "entrenamiento, y sí que se aprecia una convergencia para el conjunto de datos de validación.\n",
        "Por último, con respecto al tercer modelo, la accuracy es 1 en el conjunto de datos de\n",
        "entrenamiento, pero no converge en el conjunto de validación, de esta forma, se puede concluir\n",
        "que también experimenta un sobreajuste.\n",
        "\n",
        "**¿Qué modelo elegirías?**\n",
        "\n",
        "En base a lo que se ha mencionado en la pregunta anterior, elegiría el segundo modelo, ya que\n",
        "presenta una mayor probabilidad de obtener mejores resultados para un conjunto de datos\n",
        "distinto al de entrenamiento, al ser el único que no presenta sobreajuste."
      ],
      "metadata": {
        "id": "kP5-aAVxN9GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ota Solución (otra versión)**"
      ],
      "metadata": {
        "id": "ah_YL_HEOHRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si miramos el comportamiento general de estas gráficas vemos que son característcas cuando un modelo presenta overfitting. Por un lado el accuracy de los datos de entrenamiento aumenta linealmente con los epochs, hasta alcanzar casi el 100%, mientras que el accuracy de validación se mantiene alrededor del 85% y de manera constante a lo largo de las epochs.\n",
        "\n",
        "Yo me quedaría con la segunda gráfica ya que es preferible ver que las curvas de entrenamiento y validación sigan trayectorias similares y converjan a valores altos de precisión. Si ambas curvas son cercanas y tienen valores altos, es probable que el modelo este bien generalizado."
      ],
      "metadata": {
        "id": "8l2lqYnROM6Y"
      }
    }
  ]
}